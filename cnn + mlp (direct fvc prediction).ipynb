{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:12:45.226444Z",
     "iopub.status.busy": "2020-10-30T15:12:45.225573Z",
     "iopub.status.idle": "2020-10-30T15:13:00.103952Z",
     "shell.execute_reply": "2020-10-30T15:13:00.104582Z"
    },
    "papermill": {
     "duration": 14.915465,
     "end_time": "2020-10-30T15:13:00.104772",
     "exception": false,
     "start_time": "2020-10-30T15:12:45.189307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/efficientnet\r\n",
      "  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-h009bvqe\r\n",
      "Collecting keras_applications<=1.0.8,>=1.0.7\r\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 50 kB 806 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.1) (0.16.2)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (2.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.18.5)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (3.2.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (2.4)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (7.2.0)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (2.8.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (1.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.14.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (1.2.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.1) (4.4.2)\r\n",
      "Building wheels for collected packages: efficientnet\r\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.1-py3-none-any.whl size=18420 sha256=017354ce48eef9079cfb47adc0267ce33e7d062d9834dfe783e6bffb075c78e4\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uflklnys/wheels/11/69/85/814d64d694c96db0eef17b718042d644a1e54f113920481920\r\n",
      "Successfully built efficientnet\r\n",
      "Installing collected packages: keras-applications, efficientnet\r\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:00.210076Z",
     "iopub.status.busy": "2020-10-30T15:13:00.206051Z",
     "iopub.status.idle": "2020-10-30T15:13:09.438145Z",
     "shell.execute_reply": "2020-10-30T15:13:09.438744Z"
    },
    "papermill": {
     "duration": 9.29653,
     "end_time": "2020-10-30T15:13:09.438948",
     "exception": false,
     "start_time": "2020-10-30T15:13:00.142418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAABICAYAAADLcuPOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACJElEQVR4nO3bsWqTYRiG4ffT1gxutUKdtLubno24/qehx+HqcQgubh0dHByFFlFURKWp+Lm4CMEYyMOX/FzXFvIPz0uHOyS09d4LALbt2ugBAMyTwAAQITAARAgMABECA0CEwAAQcbDugdbaVFVTVdXhYvHg6M5JfNQoB4vD0ROirt9Y++fea7euPo6ekHN5NXpB1PLrr9ETon4u5/tZ/uLH9/q8vGyr3mub/B/Myem9/vjpk60N2zVHp8ejJ0TN/b5H589HT4jpb9+PnhB1/vLb6AlRF+9ujp4QM716UW++fFoZmPlmFYChBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIgQGAAiBAaACIEBIEJgAIhovfd/P9DaVFXTn5f3q+p1etRAx1X1YfSIkDnfVuW+fee+/XW393571RtrA/PXw62d9d4fbm3WjpnzfXO+rcp9+8598+QrMgAiBAaAiE0D8yyyYnfM+b4531blvn3nvhna6DcYAPhfviIDIEJgAIgQGAAiBAaACIEBIOI3qVJbtUCORLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Regular Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm \n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "import math\n",
    "import cv2\n",
    "import pydicom\n",
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import matplotlib.image as mpimg\n",
    "from tabulate import tabulate\n",
    "import missingno as msno \n",
    "from IPython.display import display_html\n",
    "from PIL import Image\n",
    "import gc\n",
    "from skimage.transform import resize\n",
    "import copy\n",
    "import re\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Segmentation\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "init_notebook_mode(connected=True) \n",
    "\n",
    "# Model imports\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import (\n",
    "                                    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D,\n",
    "                                    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate , Lambda\n",
    "                                    )\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.models as M\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.applications as tfa\n",
    "import efficientnet.tfkeras as efn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "custom_colors = ['#74a09e','#86c1b2','#98e2c6','#f3c969','#f2a553', '#d96548', '#c14953']\n",
    "sns.palplot(sns.color_palette(custom_colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069076,
     "end_time": "2020-10-30T15:13:09.584520",
     "exception": false,
     "start_time": "2020-10-30T15:13:09.515444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "defining number of epochs in training (i think its the number of epoch(num rounds of looping through the entire dataset) for training train data from each fold)\n",
    "defining batch_size (how many training examples to feed into network before updating the weights and internal nodes)\n",
    "LR: learning rate\n",
    "model_class allow us to define which efficientnet model we want to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:09.708232Z",
     "iopub.status.busy": "2020-10-30T15:13:09.707127Z",
     "iopub.status.idle": "2020-10-30T15:13:09.712070Z",
     "shell.execute_reply": "2020-10-30T15:13:09.712907Z"
    },
    "papermill": {
     "duration": 0.071732,
     "end_time": "2020-10-30T15:13:09.713138",
     "exception": false,
     "start_time": "2020-10-30T15:13:09.641406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "NFOLD = 5\n",
    "LR = 0.003\n",
    "SAVE_BEST = True\n",
    "MODEL_CLASS = 'b1'\n",
    "path = '../input/osic-pulmonary-fibrosis-progression/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.098693,
     "end_time": "2020-10-30T15:13:09.870080",
     "exception": false,
     "start_time": "2020-10-30T15:13:09.771387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Splitting data into train and test set (our own private test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.000689Z",
     "iopub.status.busy": "2020-10-30T15:13:09.993936Z",
     "iopub.status.idle": "2020-10-30T15:13:10.024724Z",
     "shell.execute_reply": "2020-10-30T15:13:10.026029Z"
    },
    "papermill": {
     "duration": 0.099753,
     "end_time": "2020-10-30T15:13:10.026239",
     "exception": false,
     "start_time": "2020-10-30T15:13:09.926486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reading in data\n",
    "all_data = pd.read_csv(f'{path}/train.csv')\n",
    "\n",
    "all_data.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "\n",
    "unique_patients = all_data.Patient.unique()\n",
    "train_ids, test_ids = train_test_split(unique_patients, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train = all_data[all_data['Patient'].isin(train_ids)]\n",
    "test = all_data[all_data['Patient'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.158866Z",
     "iopub.status.busy": "2020-10-30T15:13:10.157681Z",
     "iopub.status.idle": "2020-10-30T15:13:10.163168Z",
     "shell.execute_reply": "2020-10-30T15:13:10.164207Z"
    },
    "papermill": {
     "duration": 0.084601,
     "end_time": "2020-10-30T15:13:10.164412",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.079811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_baseline_week(df):    \n",
    "    # make a copy to not change original df    \n",
    "    _df = df.copy()\n",
    "    # ensure all Weeks values are INT and not accidentaly saved as string\n",
    "    _df['Weeks'] = _df['Weeks'].astype(int)\n",
    "    _df['min_week'] = _df['Weeks']\n",
    "    _df[\"min_week\"] = _df.groupby('Patient')['Weeks'].transform('min')\n",
    "    _df['baselined_week'] = _df['Weeks'] - _df['min_week']\n",
    "    \n",
    "    return pd.DataFrame(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.272799Z",
     "iopub.status.busy": "2020-10-30T15:13:10.271425Z",
     "iopub.status.idle": "2020-10-30T15:13:10.275813Z",
     "shell.execute_reply": "2020-10-30T15:13:10.276528Z"
    },
    "papermill": {
     "duration": 0.060668,
     "end_time": "2020-10-30T15:13:10.276696",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.216028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_baseline_FVC_new(df):\n",
    "    _df = (\n",
    "        df\n",
    "        .loc[df.Weeks == df.min_week][['Patient','FVC']]\n",
    "        .rename({'FVC': 'base_FVC'}, axis=1)\n",
    "        .groupby('Patient')\n",
    "        .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_new = df.merge(_df, on = 'Patient', how = 'left') \n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.392673Z",
     "iopub.status.busy": "2020-10-30T15:13:10.387836Z",
     "iopub.status.idle": "2020-10-30T15:13:10.394363Z",
     "shell.execute_reply": "2020-10-30T15:13:10.393536Z"
    },
    "papermill": {
     "duration": 0.068274,
     "end_time": "2020-10-30T15:13:10.394577",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.326303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def own_OneHotColumnCreator(df, columns):\n",
    "    \"\"\"OneHot Encodes categorical features. Adds a column for each unique value per column\"\"\"\n",
    "    for col in cat_attribs:\n",
    "        for value in df[col].unique():\n",
    "            df[value] = (df[col] == value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.485038Z",
     "iopub.status.busy": "2020-10-30T15:13:10.483333Z",
     "iopub.status.idle": "2020-10-30T15:13:10.488263Z",
     "shell.execute_reply": "2020-10-30T15:13:10.488964Z"
    },
    "papermill": {
     "duration": 0.0571,
     "end_time": "2020-10-30T15:13:10.489166",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.432066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define which attributes shall not be transformed, are numeric or categorical\n",
    "no_transform_attribs = ['Patient', 'Weeks', 'min_week', 'FVC']\n",
    "num_attribs = ['Percent', 'Age']\n",
    "cat_attribs = ['Sex', 'SmokingStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.596536Z",
     "iopub.status.busy": "2020-10-30T15:13:10.595614Z",
     "iopub.status.idle": "2020-10-30T15:13:10.658610Z",
     "shell.execute_reply": "2020-10-30T15:13:10.659982Z"
    },
    "papermill": {
     "duration": 0.122569,
     "end_time": "2020-10-30T15:13:10.660177",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.537608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = get_baseline_week(train)\n",
    "train = get_baseline_FVC_new(train)\n",
    "test = get_baseline_week(test)\n",
    "test = get_baseline_FVC_new(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.789497Z",
     "iopub.status.busy": "2020-10-30T15:13:10.788705Z",
     "iopub.status.idle": "2020-10-30T15:13:10.808505Z",
     "shell.execute_reply": "2020-10-30T15:13:10.809223Z"
    },
    "papermill": {
     "duration": 0.099304,
     "end_time": "2020-10-30T15:13:10.809413",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.710109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_attribs_scld = [s + '_scld' for s in num_attribs]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train[num_attribs_scld] = min_max_scaler.fit_transform(train[num_attribs])\n",
    "test[num_attribs_scld] = min_max_scaler.fit_transform(test[num_attribs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:10.900367Z",
     "iopub.status.busy": "2020-10-30T15:13:10.891217Z",
     "iopub.status.idle": "2020-10-30T15:13:10.903357Z",
     "shell.execute_reply": "2020-10-30T15:13:10.902753Z"
    },
    "papermill": {
     "duration": 0.056803,
     "end_time": "2020-10-30T15:13:10.903478",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.846675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "own_OneHotColumnCreator(train, cat_attribs)\n",
    "own_OneHotColumnCreator(test, cat_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:11.003667Z",
     "iopub.status.busy": "2020-10-30T15:13:11.002814Z",
     "iopub.status.idle": "2020-10-30T15:13:11.022713Z",
     "shell.execute_reply": "2020-10-30T15:13:11.023345Z"
    },
    "papermill": {
     "duration": 0.083051,
     "end_time": "2020-10-30T15:13:11.023513",
     "exception": false,
     "start_time": "2020-10-30T15:13:10.940462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>min_week</th>\n",
       "      <th>baselined_week</th>\n",
       "      <th>base_FVC</th>\n",
       "      <th>Percent_scld</th>\n",
       "      <th>Age_scld</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Ex-smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>2315</td>\n",
       "      <td>0.202489</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>9</td>\n",
       "      <td>2315</td>\n",
       "      <td>0.181129</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>11</td>\n",
       "      <td>2315</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>13</td>\n",
       "      <td>2315</td>\n",
       "      <td>0.166325</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-4</td>\n",
       "      <td>15</td>\n",
       "      <td>2315</td>\n",
       "      <td>0.150464</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>13</td>\n",
       "      <td>2712</td>\n",
       "      <td>66.594637</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.272591</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>19</td>\n",
       "      <td>2978</td>\n",
       "      <td>73.126412</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.327486</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>31</td>\n",
       "      <td>2908</td>\n",
       "      <td>71.407524</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.313040</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>43</td>\n",
       "      <td>2975</td>\n",
       "      <td>73.052745</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.326867</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>59</td>\n",
       "      <td>2774</td>\n",
       "      <td>68.117081</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.285386</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1223 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Patient  Weeks   FVC    Percent  Age   Sex  \\\n",
       "0     ID00007637202177411956430     -4  2315  58.253649   79  Male   \n",
       "1     ID00007637202177411956430      5  2214  55.712129   79  Male   \n",
       "2     ID00007637202177411956430      7  2061  51.862104   79  Male   \n",
       "3     ID00007637202177411956430      9  2144  53.950679   79  Male   \n",
       "4     ID00007637202177411956430     11  2069  52.063412   79  Male   \n",
       "...                         ...    ...   ...        ...  ...   ...   \n",
       "1218  ID00426637202313170790466     13  2712  66.594637   73  Male   \n",
       "1219  ID00426637202313170790466     19  2978  73.126412   73  Male   \n",
       "1220  ID00426637202313170790466     31  2908  71.407524   73  Male   \n",
       "1221  ID00426637202313170790466     43  2975  73.052745   73  Male   \n",
       "1222  ID00426637202313170790466     59  2774  68.117081   73  Male   \n",
       "\n",
       "     SmokingStatus  min_week  baselined_week  base_FVC  Percent_scld  \\\n",
       "0        Ex-smoker        -4               0      2315      0.202489   \n",
       "1        Ex-smoker        -4               9      2315      0.181129   \n",
       "2        Ex-smoker        -4              11      2315      0.148772   \n",
       "3        Ex-smoker        -4              13      2315      0.166325   \n",
       "4        Ex-smoker        -4              15      2315      0.150464   \n",
       "...            ...       ...             ...       ...           ...   \n",
       "1218  Never smoked         0              13      2925      0.272591   \n",
       "1219  Never smoked         0              19      2925      0.327486   \n",
       "1220  Never smoked         0              31      2925      0.313040   \n",
       "1221  Never smoked         0              43      2925      0.326867   \n",
       "1222  Never smoked         0              59      2925      0.285386   \n",
       "\n",
       "      Age_scld  Male  Female  Ex-smoker  Never smoked  Currently smokes  \n",
       "0     0.789474     1       0          1             0                 0  \n",
       "1     0.789474     1       0          1             0                 0  \n",
       "2     0.789474     1       0          1             0                 0  \n",
       "3     0.789474     1       0          1             0                 0  \n",
       "4     0.789474     1       0          1             0                 0  \n",
       "...        ...   ...     ...        ...           ...               ...  \n",
       "1218  0.631579     1       0          0             1                 0  \n",
       "1219  0.631579     1       0          0             1                 0  \n",
       "1220  0.631579     1       0          0             1                 0  \n",
       "1221  0.631579     1       0          0             1                 0  \n",
       "1222  0.631579     1       0          0             1                 0  \n",
       "\n",
       "[1223 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042645,
     "end_time": "2020-10-30T15:13:11.109308",
     "exception": false,
     "start_time": "2020-10-30T15:13:11.066663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "get_tab allows us to frame each patients metadata (age, sex, smoking status) into a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:11.197640Z",
     "iopub.status.busy": "2020-10-30T15:13:11.196582Z",
     "iopub.status.idle": "2020-10-30T15:13:11.199951Z",
     "shell.execute_reply": "2020-10-30T15:13:11.199375Z"
    },
    "papermill": {
     "duration": 0.048793,
     "end_time": "2020-10-30T15:13:11.200073",
     "exception": false,
     "start_time": "2020-10-30T15:13:11.151280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tab_scaled(df): #getting scaled variables #input only one patient's df #get columns needed --> return the entire df with only desired columns\n",
    "    #df_elements = df1.sample(n=1)\n",
    "    df['bias'] = 0 #adding a bias term\n",
    "    df1 = df[['bias', 'baselined_week', 'base_FVC', 'Percent_scld', 'Age_scld', 'Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes', 'FVC']]\n",
    "    lis = df1.loc[:].values.tolist()\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:11.286789Z",
     "iopub.status.busy": "2020-10-30T15:13:11.285726Z",
     "iopub.status.idle": "2020-10-30T15:13:11.703010Z",
     "shell.execute_reply": "2020-10-30T15:13:11.702377Z"
    },
    "papermill": {
     "duration": 0.464009,
     "end_time": "2020-10-30T15:13:11.703138",
     "exception": false,
     "start_time": "2020-10-30T15:13:11.239129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88de7d907f0a4690b9ef433d17d89270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#A = {} # The gradient\n",
    "TAB = {} # Tabular data for each patient\n",
    "P = [] # Patient IDs\n",
    "for i, p in tqdm(enumerate(train.Patient.unique())):\n",
    "    sub = train.loc[train.Patient == p, :] #get only the part of df belonging to patient p\n",
    "    patient_arr = get_tab_scaled(sub) #get only the part of data we want; 2D array with every row of pdata\n",
    "    TAB[p] = patient_arr #add the entire patient_arr (2D) to patient id in dictionary\n",
    "    P.append(p) #add the patientID into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:11.788651Z",
     "iopub.status.busy": "2020-10-30T15:13:11.787580Z",
     "iopub.status.idle": "2020-10-30T15:13:11.794188Z",
     "shell.execute_reply": "2020-10-30T15:13:11.794804Z"
    },
    "papermill": {
     "duration": 0.052037,
     "end_time": "2020-10-30T15:13:11.794969",
     "exception": false,
     "start_time": "2020-10-30T15:13:11.742932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    d = pydicom.dcmread(path)\n",
    "    return cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:11.891473Z",
     "iopub.status.busy": "2020-10-30T15:13:11.890485Z",
     "iopub.status.idle": "2020-10-30T15:13:11.893589Z",
     "shell.execute_reply": "2020-10-30T15:13:11.894249Z"
    },
    "papermill": {
     "duration": 0.059861,
     "end_time": "2020-10-30T15:13:11.894385",
     "exception": false,
     "start_time": "2020-10-30T15:13:11.834524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, tab, batch_size=BATCH_SIZE):\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000 #1000 batches per epoch\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        tab = [] \n",
    "        f = []\n",
    "        keys = np.random.choice(self.keys, size = self.batch_size)\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0]\n",
    "                img = get_img(f'../input/osic-pulmonary-fibrosis-progression/train/{k}/{i}')\n",
    "                x.append(img)\n",
    "                meta = self.tab[k]\n",
    "                to_append_meta = random.choice(meta)\n",
    "                tab.append(to_append_meta[:-1]) #append meta data\n",
    "                f.append(to_append_meta[-1]) #append fvc of same patient\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,f,tab = np.array(x), np.array(f), np.array(tab)\n",
    "        x = np.expand_dims(x, axis=-1)\n",
    "        return [x, tab] , f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:11.992594Z",
     "iopub.status.busy": "2020-10-30T15:13:11.991537Z",
     "iopub.status.idle": "2020-10-30T15:13:11.994703Z",
     "shell.execute_reply": "2020-10-30T15:13:11.994166Z"
    },
    "papermill": {
     "duration": 0.060851,
     "end_time": "2020-10-30T15:13:11.994814",
     "exception": false,
     "start_time": "2020-10-30T15:13:11.933963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_efficientnet(model, shape):\n",
    "    '''\n",
    "    From https://github.com/qubvel/efficientnet\n",
    "    EfficientNet is a CNN architecture achieving state of the art accuracy.\n",
    "    b0 is the simplest model, b7 is the most complex.\n",
    "    '''\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False), # We use a b1 efficientnet\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape) # 512 x 512 input shape\n",
    "    base = get_efficientnet(model_class, shape) # A b1 pre-trained efficientnet is used\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(10,))\n",
    "    x2 = tf.keras.layers.GaussianNoise(0.2)(inp2)\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:13:12.091412Z",
     "iopub.status.busy": "2020-10-30T15:13:12.090402Z",
     "iopub.status.idle": "2020-10-30T17:24:05.881113Z",
     "shell.execute_reply": "2020-10-30T17:24:05.880463Z"
    },
    "papermill": {
     "duration": 7853.848067,
     "end_time": "2020-10-30T17:24:05.882437",
     "exception": false,
     "start_time": "2020-10-30T15:13:12.034370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "####### Fold 0 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 7089042.5000\n",
      "Epoch 00001: val_loss improved from inf to 6658098.50000, saving model to fold-0.h5\n",
      "32/32 [==============================] - 19s 602ms/step - loss: 7089042.5000 - val_loss: 6658098.5000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 6152898.5000\n",
      "Epoch 00002: val_loss did not improve from 6658098.50000\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 6152898.5000 - val_loss: 9447896064.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4849973.5000\n",
      "Epoch 00003: val_loss did not improve from 6658098.50000\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 4849973.5000 - val_loss: 407384850432.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3740127.7500\n",
      "Epoch 00004: val_loss did not improve from 6658098.50000\n",
      "32/32 [==============================] - 15s 465ms/step - loss: 3740127.7500 - val_loss: 8121009152.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3147786.5000\n",
      "Epoch 00005: val_loss did not improve from 6658098.50000\n",
      "32/32 [==============================] - 15s 473ms/step - loss: 3147786.5000 - val_loss: 99701712.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2666424.2500\n",
      "Epoch 00006: val_loss did not improve from 6658098.50000\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 2666424.2500 - val_loss: 16132407.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2716654.7500\n",
      "Epoch 00007: val_loss did not improve from 6658098.50000\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 2716654.7500 - val_loss: 7303378.5000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2758723.2500\n",
      "Epoch 00008: val_loss improved from 6658098.50000 to 3327006.25000, saving model to fold-0.h5\n",
      "32/32 [==============================] - 16s 492ms/step - loss: 2758723.2500 - val_loss: 3327006.2500\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1925632.2500\n",
      "Epoch 00009: val_loss did not improve from 3327006.25000\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 1925632.2500 - val_loss: 58518304.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1476660.3750\n",
      "Epoch 00010: val_loss improved from 3327006.25000 to 1661086.62500, saving model to fold-0.h5\n",
      "32/32 [==============================] - 16s 492ms/step - loss: 1476660.3750 - val_loss: 1661086.6250\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1541123.5000\n",
      "Epoch 00011: val_loss improved from 1661086.62500 to 1150337.12500, saving model to fold-0.h5\n",
      "32/32 [==============================] - 16s 499ms/step - loss: 1541123.5000 - val_loss: 1150337.1250\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1432209.1250\n",
      "Epoch 00012: val_loss improved from 1150337.12500 to 878310.37500, saving model to fold-0.h5\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 1432209.1250 - val_loss: 878310.3750\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1141755.8750\n",
      "Epoch 00013: val_loss did not improve from 878310.37500\n",
      "32/32 [==============================] - 15s 468ms/step - loss: 1141755.8750 - val_loss: 958949.7500\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1010245.7500\n",
      "Epoch 00014: val_loss improved from 878310.37500 to 344798.31250, saving model to fold-0.h5\n",
      "32/32 [==============================] - 16s 490ms/step - loss: 1010245.7500 - val_loss: 344798.3125\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 953774.0000\n",
      "Epoch 00015: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 953774.0000 - val_loss: 511267.9375\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 866975.6250\n",
      "Epoch 00016: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 866975.6250 - val_loss: 1974551.5000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 867524.3750\n",
      "Epoch 00017: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 867524.3750 - val_loss: 1382838.1250\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 679990.4375\n",
      "Epoch 00018: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 679990.4375 - val_loss: 578219.5625\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 923060.1250\n",
      "Epoch 00019: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 923060.1250 - val_loss: 1039274.2500\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 650289.7500\n",
      "Epoch 00020: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 650289.7500 - val_loss: 622101.4375\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 672164.0000\n",
      "Epoch 00021: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 480ms/step - loss: 672164.0000 - val_loss: 462620.4062\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 615149.1250\n",
      "Epoch 00022: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 615149.1250 - val_loss: 666230.3750\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 913754.5000\n",
      "Epoch 00023: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 913754.5000 - val_loss: 473670.6875\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 750507.8750\n",
      "Epoch 00024: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 750507.8750 - val_loss: 2499977.5000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 653025.7500\n",
      "Epoch 00025: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 653025.7500 - val_loss: 4213493.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 823667.1875\n",
      "Epoch 00026: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 823667.1875 - val_loss: 769128.8750\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 608146.8125\n",
      "Epoch 00027: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 608146.8125 - val_loss: 630495.6875\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 696096.9375\n",
      "Epoch 00028: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 696096.9375 - val_loss: 528722.2500\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 749821.3750\n",
      "Epoch 00029: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 749821.3750 - val_loss: 540239.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 688187.0000\n",
      "Epoch 00030: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 688187.0000 - val_loss: 776783.2500\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 709564.6250\n",
      "Epoch 00031: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 709564.6250 - val_loss: 776212.0625\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 697383.6250\n",
      "Epoch 00032: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 697383.6250 - val_loss: 951065.6875\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 583040.0625\n",
      "Epoch 00033: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 583040.0625 - val_loss: 661741.5625\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 670743.1875\n",
      "Epoch 00034: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 670743.1875 - val_loss: 572980.6250\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 684041.0625\n",
      "Epoch 00035: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 684041.0625 - val_loss: 574940.7500\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 655063.6250\n",
      "Epoch 00036: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 655063.6250 - val_loss: 430935.4062\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 789453.6875\n",
      "Epoch 00037: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 789453.6875 - val_loss: 475796.0312\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 755467.0625\n",
      "Epoch 00038: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 755467.0625 - val_loss: 558703.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 689327.6875\n",
      "Epoch 00039: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 689327.6875 - val_loss: 615209.0625\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 559833.6875\n",
      "Epoch 00040: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 559833.6875 - val_loss: 452329.8125\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 831805.7500\n",
      "Epoch 00041: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 831805.7500 - val_loss: 578885.1875\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 582091.9375\n",
      "Epoch 00042: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 582091.9375 - val_loss: 526172.7500\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 744553.3125\n",
      "Epoch 00043: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 744553.3125 - val_loss: 519213.1875\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 646399.6875\n",
      "Epoch 00044: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 646399.6875 - val_loss: 460177.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 778638.4375\n",
      "Epoch 00045: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 778638.4375 - val_loss: 481098.7812\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 620927.0000\n",
      "Epoch 00046: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 620927.0000 - val_loss: 387171.1562\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 590081.5625\n",
      "Epoch 00047: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 590081.5625 - val_loss: 560185.3750\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 622555.9375\n",
      "Epoch 00048: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 622555.9375 - val_loss: 561147.3125\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 661677.1875\n",
      "Epoch 00049: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 661677.1875 - val_loss: 1228739.6250\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 820294.7500\n",
      "Epoch 00050: val_loss did not improve from 344798.31250\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.002250000019557774.\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 820294.7500 - val_loss: 520610.3438\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 702841.2500\n",
      "Epoch 00051: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 702841.2500 - val_loss: 531468.8750\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 746474.0625\n",
      "Epoch 00052: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 746474.0625 - val_loss: 504269.7500\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 548624.3750\n",
      "Epoch 00053: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 548624.3750 - val_loss: 507627.8438\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 599839.1250\n",
      "Epoch 00054: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 599839.1250 - val_loss: 538352.4375\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 686478.9375\n",
      "Epoch 00055: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 686478.9375 - val_loss: 568694.4375\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 689876.1250\n",
      "Epoch 00056: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 689876.1250 - val_loss: 381076.2812\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 687886.5000\n",
      "Epoch 00057: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 687886.5000 - val_loss: 550695.6250\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 593185.2500\n",
      "Epoch 00058: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 593185.2500 - val_loss: 561451.4375\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 715974.8750\n",
      "Epoch 00059: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 715974.8750 - val_loss: 562525.6875\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 637557.8125\n",
      "Epoch 00060: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 637557.8125 - val_loss: 565242.6250\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 684358.3125\n",
      "Epoch 00061: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 684358.3125 - val_loss: 557674.1250\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 811702.3750\n",
      "Epoch 00062: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 811702.3750 - val_loss: 517598.5000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 701208.4375\n",
      "Epoch 00063: val_loss did not improve from 344798.31250\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0016874999273568392.\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 701208.4375 - val_loss: 614482.5000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 739680.1250\n",
      "Epoch 00064: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 739680.1250 - val_loss: 525197.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 718298.0000\n",
      "Epoch 00065: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 718298.0000 - val_loss: 600716.1875\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 598658.3750\n",
      "Epoch 00066: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 598658.3750 - val_loss: 563778.1250\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 691016.8125\n",
      "Epoch 00067: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 691016.8125 - val_loss: 534493.3125\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 740283.0625\n",
      "Epoch 00068: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 740283.0625 - val_loss: 512705.5625\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 609781.4375\n",
      "Epoch 00069: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 609781.4375 - val_loss: 482033.8125\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 658098.9375\n",
      "Epoch 00070: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 658098.9375 - val_loss: 442036.0938\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 745375.3125\n",
      "Epoch 00071: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 745375.3125 - val_loss: 496981.3125\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 571188.4375\n",
      "Epoch 00072: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 571188.4375 - val_loss: 513640.1875\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 794590.8750\n",
      "Epoch 00073: val_loss did not improve from 344798.31250\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0012656249455176294.\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 794590.8750 - val_loss: 429808.7188\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 553484.8750\n",
      "Epoch 00074: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 553484.8750 - val_loss: 592936.3750\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 549649.3750\n",
      "Epoch 00075: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 549649.3750 - val_loss: 641931.5000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 684065.8750\n",
      "Epoch 00076: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 684065.8750 - val_loss: 387067.8125\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 658848.1875\n",
      "Epoch 00077: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 658848.1875 - val_loss: 486898.4062\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 544586.2500\n",
      "Epoch 00078: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 544586.2500 - val_loss: 699679.1250\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 748074.5000\n",
      "Epoch 00079: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 748074.5000 - val_loss: 519128.2188\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 617235.8750\n",
      "Epoch 00080: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 617235.8750 - val_loss: 528017.6250\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 643390.6250\n",
      "Epoch 00081: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 643390.6250 - val_loss: 501786.4688\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 624148.5625\n",
      "Epoch 00082: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 624148.5625 - val_loss: 419600.9375\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 723320.0000\n",
      "Epoch 00083: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 723320.0000 - val_loss: 531209.3125\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 601311.6875\n",
      "Epoch 00084: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 601311.6875 - val_loss: 451496.6562\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 537420.8125\n",
      "Epoch 00085: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 537420.8125 - val_loss: 627419.3125\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 641344.1250\n",
      "Epoch 00086: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 641344.1250 - val_loss: 544499.5000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 598004.6250\n",
      "Epoch 00087: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 598004.6250 - val_loss: 466704.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 660371.8125\n",
      "Epoch 00088: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 660371.8125 - val_loss: 678094.6875\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 666973.2500\n",
      "Epoch 00089: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 666973.2500 - val_loss: 484033.4062\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 598459.6875\n",
      "Epoch 00090: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 598459.6875 - val_loss: 577469.6875\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 758775.9375\n",
      "Epoch 00091: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 758775.9375 - val_loss: 570288.4375\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 704942.0000\n",
      "Epoch 00092: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 704942.0000 - val_loss: 546750.2500\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 519062.0312\n",
      "Epoch 00093: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 519062.0312 - val_loss: 460374.1562\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 670902.5625\n",
      "Epoch 00094: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 670902.5625 - val_loss: 460103.0938\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 626439.9375\n",
      "Epoch 00095: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 626439.9375 - val_loss: 383518.4062\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 576836.5625\n",
      "Epoch 00096: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 576836.5625 - val_loss: 362330.0312\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 670781.7500\n",
      "Epoch 00097: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 670781.7500 - val_loss: 451485.6250\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 705502.6250\n",
      "Epoch 00098: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 705502.6250 - val_loss: 473267.4375\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 600364.1875\n",
      "Epoch 00099: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 600364.1875 - val_loss: 587592.1250\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 631801.0625\n",
      "Epoch 00100: val_loss did not improve from 344798.31250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 631801.0625 - val_loss: 424598.0625\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 1 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 6728526.0000\n",
      "Epoch 00001: val_loss improved from inf to 4040605.50000, saving model to fold-1.h5\n",
      "32/32 [==============================] - 19s 605ms/step - loss: 6728526.0000 - val_loss: 4040605.5000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 6244401.0000\n",
      "Epoch 00002: val_loss did not improve from 4040605.50000\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 6244401.0000 - val_loss: 761736640.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4418226.0000\n",
      "Epoch 00003: val_loss did not improve from 4040605.50000\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 4418226.0000 - val_loss: 813283520.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3916594.5000\n",
      "Epoch 00004: val_loss did not improve from 4040605.50000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 3916594.5000 - val_loss: 2251738316800.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3554749.7500\n",
      "Epoch 00005: val_loss improved from 4040605.50000 to 3419418.50000, saving model to fold-1.h5\n",
      "32/32 [==============================] - 16s 489ms/step - loss: 3554749.7500 - val_loss: 3419418.5000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3100364.5000\n",
      "Epoch 00006: val_loss improved from 3419418.50000 to 933552.25000, saving model to fold-1.h5\n",
      "32/32 [==============================] - 15s 480ms/step - loss: 3100364.5000 - val_loss: 933552.2500\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3092187.0000\n",
      "Epoch 00007: val_loss improved from 933552.25000 to 825176.12500, saving model to fold-1.h5\n",
      "32/32 [==============================] - 15s 477ms/step - loss: 3092187.0000 - val_loss: 825176.1250\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2028954.2500\n",
      "Epoch 00008: val_loss did not improve from 825176.12500\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 2028954.2500 - val_loss: 847580.6875\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1798592.3750\n",
      "Epoch 00009: val_loss did not improve from 825176.12500\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 1798592.3750 - val_loss: 885510.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1933381.1250\n",
      "Epoch 00010: val_loss did not improve from 825176.12500\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 1933381.1250 - val_loss: 1063001.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1281785.8750\n",
      "Epoch 00011: val_loss did not improve from 825176.12500\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 1281785.8750 - val_loss: 2542278.2500\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1335260.3750\n",
      "Epoch 00012: val_loss did not improve from 825176.12500\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1335260.3750 - val_loss: 1168049.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1009018.7500\n",
      "Epoch 00013: val_loss did not improve from 825176.12500\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 1009018.7500 - val_loss: 847698.0625\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1014279.9375\n",
      "Epoch 00014: val_loss improved from 825176.12500 to 499239.09375, saving model to fold-1.h5\n",
      "32/32 [==============================] - 16s 490ms/step - loss: 1014279.9375 - val_loss: 499239.0938\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 887029.8750\n",
      "Epoch 00015: val_loss did not improve from 499239.09375\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 887029.8750 - val_loss: 643559.8125\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 722394.9375\n",
      "Epoch 00016: val_loss did not improve from 499239.09375\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 722394.9375 - val_loss: 558970.3125\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 835639.1250\n",
      "Epoch 00017: val_loss improved from 499239.09375 to 434122.62500, saving model to fold-1.h5\n",
      "32/32 [==============================] - 15s 484ms/step - loss: 835639.1250 - val_loss: 434122.6250\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 686813.5625\n",
      "Epoch 00018: val_loss did not improve from 434122.62500\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 686813.5625 - val_loss: 690912.8750\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 839532.8750\n",
      "Epoch 00019: val_loss did not improve from 434122.62500\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 839532.8750 - val_loss: 477852.3125\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 762136.5000\n",
      "Epoch 00020: val_loss did not improve from 434122.62500\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 762136.5000 - val_loss: 484022.2188\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 846571.5625\n",
      "Epoch 00021: val_loss improved from 434122.62500 to 322710.28125, saving model to fold-1.h5\n",
      "32/32 [==============================] - 16s 493ms/step - loss: 846571.5625 - val_loss: 322710.2812\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 764688.9375\n",
      "Epoch 00022: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 764688.9375 - val_loss: 572626.2500\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 837800.4375\n",
      "Epoch 00023: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 837800.4375 - val_loss: 441623.3750\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 716612.6250\n",
      "Epoch 00024: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 716612.6250 - val_loss: 375641.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 642394.9375\n",
      "Epoch 00025: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 642394.9375 - val_loss: 634107.4375\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 637850.8750\n",
      "Epoch 00026: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 637850.8750 - val_loss: 812729.6250\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 777793.6250\n",
      "Epoch 00027: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 777793.6250 - val_loss: 565659.5625\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 503613.7500\n",
      "Epoch 00028: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 503613.7500 - val_loss: 620786.2500\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 688494.7500\n",
      "Epoch 00029: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 688494.7500 - val_loss: 706415.2500\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 635372.5000\n",
      "Epoch 00030: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 635372.5000 - val_loss: 570615.5000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 703693.6875\n",
      "Epoch 00031: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 703693.6875 - val_loss: 534829.3750\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 605786.8125\n",
      "Epoch 00032: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 605786.8125 - val_loss: 401390.3750\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 618264.2500\n",
      "Epoch 00033: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 618264.2500 - val_loss: 593785.2500\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 653823.5625\n",
      "Epoch 00034: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 653823.5625 - val_loss: 623378.8750\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 597129.1250\n",
      "Epoch 00035: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 597129.1250 - val_loss: 387381.8750\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 742236.5000\n",
      "Epoch 00036: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 742236.5000 - val_loss: 500157.5625\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 809874.4375\n",
      "Epoch 00037: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 809874.4375 - val_loss: 601124.6250\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 865971.0000\n",
      "Epoch 00038: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.002250000019557774.\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 865971.0000 - val_loss: 579011.6250\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 606579.1875\n",
      "Epoch 00039: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 606579.1875 - val_loss: 365538.3125\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 693958.1875\n",
      "Epoch 00040: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 693958.1875 - val_loss: 449740.8750\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 802218.3750\n",
      "Epoch 00041: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 802218.3750 - val_loss: 501145.6250\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 683650.0000\n",
      "Epoch 00042: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 683650.0000 - val_loss: 474889.7500\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 750028.3750\n",
      "Epoch 00043: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 750028.3750 - val_loss: 476945.7812\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 800611.5000\n",
      "Epoch 00044: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 800611.5000 - val_loss: 544509.6875\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 575002.3750\n",
      "Epoch 00045: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 575002.3750 - val_loss: 472473.8125\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 810484.9375\n",
      "Epoch 00046: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 810484.9375 - val_loss: 474222.0625\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 688634.2500\n",
      "Epoch 00047: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 688634.2500 - val_loss: 506196.1875\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 810190.8125\n",
      "Epoch 00048: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0016874999273568392.\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 810190.8125 - val_loss: 1030924.0625\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 692825.8125\n",
      "Epoch 00049: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 692825.8125 - val_loss: 500816.2812\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 700307.1875\n",
      "Epoch 00050: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 700307.1875 - val_loss: 452700.9062\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 594819.0000\n",
      "Epoch 00051: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 594819.0000 - val_loss: 629490.0625\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 847512.6875\n",
      "Epoch 00052: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 847512.6875 - val_loss: 676638.6875\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 720087.5000\n",
      "Epoch 00053: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 720087.5000 - val_loss: 376549.6250\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 662767.1875\n",
      "Epoch 00054: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 662767.1875 - val_loss: 492766.5625\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 559257.6250\n",
      "Epoch 00055: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 559257.6250 - val_loss: 471943.8438\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 752038.5625\n",
      "Epoch 00056: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 752038.5625 - val_loss: 551613.1875\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 628722.0000\n",
      "Epoch 00057: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 628722.0000 - val_loss: 574483.1250\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 799587.4375\n",
      "Epoch 00058: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0012656249455176294.\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 799587.4375 - val_loss: 478175.0625\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 635657.2500\n",
      "Epoch 00059: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 635657.2500 - val_loss: 530548.4375\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 647913.7500\n",
      "Epoch 00060: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 647913.7500 - val_loss: 600790.3125\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 749886.0000\n",
      "Epoch 00061: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 749886.0000 - val_loss: 531107.6250\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 673782.7500\n",
      "Epoch 00062: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 673782.7500 - val_loss: 569327.7500\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 631364.7500\n",
      "Epoch 00063: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 631364.7500 - val_loss: 530646.3125\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 629898.7500\n",
      "Epoch 00064: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 629898.7500 - val_loss: 524473.8125\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 794581.0000\n",
      "Epoch 00065: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 794581.0000 - val_loss: 455695.0625\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 597088.3750\n",
      "Epoch 00066: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 597088.3750 - val_loss: 433336.7188\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 703002.9375\n",
      "Epoch 00067: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 703002.9375 - val_loss: 438216.3438\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 642602.7500\n",
      "Epoch 00068: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0009492187527939677.\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 642602.7500 - val_loss: 576935.2500\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 731348.1250\n",
      "Epoch 00069: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 731348.1250 - val_loss: 554779.3750\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 833830.1250\n",
      "Epoch 00070: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 833830.1250 - val_loss: 552259.1875\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 639158.1875\n",
      "Epoch 00071: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 639158.1875 - val_loss: 420053.1250\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 782679.5000\n",
      "Epoch 00072: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 782679.5000 - val_loss: 473910.0938\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 604482.3125\n",
      "Epoch 00073: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 453ms/step - loss: 604482.3125 - val_loss: 472294.5000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 724703.5625\n",
      "Epoch 00074: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 724703.5625 - val_loss: 424113.4062\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 629458.3750\n",
      "Epoch 00075: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 629458.3750 - val_loss: 459993.5000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 628818.2500\n",
      "Epoch 00076: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 628818.2500 - val_loss: 357472.6875\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 575439.6875\n",
      "Epoch 00077: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 575439.6875 - val_loss: 633682.2500\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 700803.1250\n",
      "Epoch 00078: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0007119140645954758.\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 700803.1250 - val_loss: 517939.2500\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 735057.8750\n",
      "Epoch 00079: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 735057.8750 - val_loss: 544414.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 665963.8750\n",
      "Epoch 00080: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 665963.8750 - val_loss: 562272.1875\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 578225.1875\n",
      "Epoch 00081: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 578225.1875 - val_loss: 513158.9688\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 788306.9375\n",
      "Epoch 00082: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 788306.9375 - val_loss: 533864.8750\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 799369.5000\n",
      "Epoch 00083: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 799369.5000 - val_loss: 418074.1562\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 697465.3750\n",
      "Epoch 00084: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 697465.3750 - val_loss: 522162.4375\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 725017.6875\n",
      "Epoch 00085: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 725017.6875 - val_loss: 536087.5000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 664563.6250\n",
      "Epoch 00086: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 664563.6250 - val_loss: 415914.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 662859.2500\n",
      "Epoch 00087: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 662859.2500 - val_loss: 504772.7188\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 695032.0625\n",
      "Epoch 00088: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.000533935526618734.\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 695032.0625 - val_loss: 415308.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 606420.0625\n",
      "Epoch 00089: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 606420.0625 - val_loss: 449980.3125\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 711744.4375\n",
      "Epoch 00090: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 711744.4375 - val_loss: 449838.4375\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 652982.5625\n",
      "Epoch 00091: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 652982.5625 - val_loss: 400004.6250\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 724873.3125\n",
      "Epoch 00092: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 724873.3125 - val_loss: 480307.5625\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 703837.8125\n",
      "Epoch 00093: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 703837.8125 - val_loss: 478461.2188\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 600944.3125\n",
      "Epoch 00094: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 600944.3125 - val_loss: 485057.6875\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 666639.0000\n",
      "Epoch 00095: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 666639.0000 - val_loss: 420957.4375\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 659667.5000\n",
      "Epoch 00096: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 659667.5000 - val_loss: 544165.5000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 680204.4375\n",
      "Epoch 00097: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 680204.4375 - val_loss: 434879.9062\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 695510.3750\n",
      "Epoch 00098: val_loss did not improve from 322710.28125\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00040045162313617766.\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 695510.3750 - val_loss: 456524.8125\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 642696.5000\n",
      "Epoch 00099: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 642696.5000 - val_loss: 517647.2500\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 618551.9375\n",
      "Epoch 00100: val_loss did not improve from 322710.28125\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 618551.9375 - val_loss: 459152.0625\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 2 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 7936116.0000\n",
      "Epoch 00001: val_loss improved from inf to 8196184.00000, saving model to fold-2.h5\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 7936116.0000 - val_loss: 8196184.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 6135864.5000\n",
      "Epoch 00002: val_loss did not improve from 8196184.00000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 6135864.5000 - val_loss: 19477334.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4963774.0000\n",
      "Epoch 00003: val_loss did not improve from 8196184.00000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 4963774.0000 - val_loss: 81037688.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4268916.0000\n",
      "Epoch 00004: val_loss did not improve from 8196184.00000\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 4268916.0000 - val_loss: 960370304.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3556503.7500\n",
      "Epoch 00005: val_loss improved from 8196184.00000 to 3012690.50000, saving model to fold-2.h5\n",
      "32/32 [==============================] - 16s 487ms/step - loss: 3556503.7500 - val_loss: 3012690.5000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2991733.2500\n",
      "Epoch 00006: val_loss did not improve from 3012690.50000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 2991733.2500 - val_loss: 4164493056.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2344764.7500\n",
      "Epoch 00007: val_loss improved from 3012690.50000 to 848182.87500, saving model to fold-2.h5\n",
      "32/32 [==============================] - 15s 480ms/step - loss: 2344764.7500 - val_loss: 848182.8750\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1729604.0000\n",
      "Epoch 00008: val_loss improved from 848182.87500 to 781721.81250, saving model to fold-2.h5\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 1729604.0000 - val_loss: 781721.8125\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1669447.6250\n",
      "Epoch 00009: val_loss did not improve from 781721.81250\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1669447.6250 - val_loss: 1795555.6250\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1675101.5000\n",
      "Epoch 00010: val_loss did not improve from 781721.81250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1675101.5000 - val_loss: 1086543.6250\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1385478.8750\n",
      "Epoch 00011: val_loss did not improve from 781721.81250\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 1385478.8750 - val_loss: 1082528.3750\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1354645.3750\n",
      "Epoch 00012: val_loss improved from 781721.81250 to 770607.37500, saving model to fold-2.h5\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 1354645.3750 - val_loss: 770607.3750\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1232566.2500\n",
      "Epoch 00013: val_loss improved from 770607.37500 to 488965.15625, saving model to fold-2.h5\n",
      "32/32 [==============================] - 16s 506ms/step - loss: 1232566.2500 - val_loss: 488965.1562\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 991019.4375 \n",
      "Epoch 00014: val_loss did not improve from 488965.15625\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 991019.4375 - val_loss: 697509.5625\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 893180.9375\n",
      "Epoch 00015: val_loss did not improve from 488965.15625\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 893180.9375 - val_loss: 988067.3125\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 907835.1250\n",
      "Epoch 00016: val_loss did not improve from 488965.15625\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 907835.1250 - val_loss: 609650.7500\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 863363.7500\n",
      "Epoch 00017: val_loss did not improve from 488965.15625\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 863363.7500 - val_loss: 993375.1875\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 633079.4375\n",
      "Epoch 00018: val_loss improved from 488965.15625 to 471019.37500, saving model to fold-2.h5\n",
      "32/32 [==============================] - 15s 482ms/step - loss: 633079.4375 - val_loss: 471019.3750\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 689503.7500\n",
      "Epoch 00019: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 689503.7500 - val_loss: 827286.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 632853.5625\n",
      "Epoch 00020: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 632853.5625 - val_loss: 804763.5000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 668943.8125\n",
      "Epoch 00021: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 668943.8125 - val_loss: 1168547.7500\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 543918.5625\n",
      "Epoch 00022: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 543918.5625 - val_loss: 971234.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 598803.5625\n",
      "Epoch 00023: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 598803.5625 - val_loss: 766193.5000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 638112.3125\n",
      "Epoch 00024: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 638112.3125 - val_loss: 942045.4375\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 513362.2812\n",
      "Epoch 00025: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 513362.2812 - val_loss: 745867.9375\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 625305.0000\n",
      "Epoch 00026: val_loss did not improve from 471019.37500\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 625305.0000 - val_loss: 827359.9375\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 781399.6875\n",
      "Epoch 00027: val_loss improved from 471019.37500 to 464728.06250, saving model to fold-2.h5\n",
      "32/32 [==============================] - 16s 488ms/step - loss: 781399.6875 - val_loss: 464728.0625\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 666210.5000\n",
      "Epoch 00028: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 666210.5000 - val_loss: 805192.7500\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 689773.2500\n",
      "Epoch 00029: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 689773.2500 - val_loss: 699417.5000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 644382.4375\n",
      "Epoch 00030: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 644382.4375 - val_loss: 907404.6250\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 638549.0625\n",
      "Epoch 00031: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 638549.0625 - val_loss: 800378.8125\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 548562.2500\n",
      "Epoch 00032: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 548562.2500 - val_loss: 1051437.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 554140.0000\n",
      "Epoch 00033: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 554140.0000 - val_loss: 668147.7500\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 683053.9375\n",
      "Epoch 00034: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 683053.9375 - val_loss: 1029127.5625\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 587961.3125\n",
      "Epoch 00035: val_loss did not improve from 464728.06250\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.002250000019557774.\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 587961.3125 - val_loss: 1187258.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 674885.2500\n",
      "Epoch 00036: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 674885.2500 - val_loss: 980429.3750\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 752950.5625\n",
      "Epoch 00037: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 752950.5625 - val_loss: 619620.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 664253.1250\n",
      "Epoch 00038: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 664253.1250 - val_loss: 638231.3125\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 537645.6875\n",
      "Epoch 00039: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 537645.6875 - val_loss: 940462.8750\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 535598.6875\n",
      "Epoch 00040: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 535598.6875 - val_loss: 933163.1875\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 586006.5625\n",
      "Epoch 00041: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 586006.5625 - val_loss: 926330.6250\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 533717.1875\n",
      "Epoch 00042: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 533717.1875 - val_loss: 902796.8750\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 578030.3125\n",
      "Epoch 00043: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 578030.3125 - val_loss: 884563.8750\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 629527.6250\n",
      "Epoch 00044: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 453ms/step - loss: 629527.6250 - val_loss: 758900.2500\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 556004.8125\n",
      "Epoch 00045: val_loss did not improve from 464728.06250\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0016874999273568392.\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 556004.8125 - val_loss: 1089501.3750\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 573339.9375\n",
      "Epoch 00046: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 573339.9375 - val_loss: 926225.2500\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 573073.3125\n",
      "Epoch 00047: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 573073.3125 - val_loss: 600625.4375\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 591071.6875\n",
      "Epoch 00048: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 591071.6875 - val_loss: 610030.3125\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 685215.4375\n",
      "Epoch 00049: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 476ms/step - loss: 685215.4375 - val_loss: 787172.0625\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 598131.8750\n",
      "Epoch 00050: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 598131.8750 - val_loss: 1012726.8125\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 556387.5625\n",
      "Epoch 00051: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 556387.5625 - val_loss: 755089.5000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 555334.6875\n",
      "Epoch 00052: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 555334.6875 - val_loss: 537799.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 557143.6250\n",
      "Epoch 00053: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 557143.6250 - val_loss: 881245.3750\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 570699.1250\n",
      "Epoch 00054: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 570699.1250 - val_loss: 803940.2500\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 540924.0625\n",
      "Epoch 00055: val_loss did not improve from 464728.06250\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0012656249455176294.\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 540924.0625 - val_loss: 671205.6250\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 634740.1250\n",
      "Epoch 00056: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 634740.1250 - val_loss: 750891.1250\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 648225.5625\n",
      "Epoch 00057: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 648225.5625 - val_loss: 726763.6250\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 623546.0625\n",
      "Epoch 00058: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 623546.0625 - val_loss: 742633.1875\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 530736.5625\n",
      "Epoch 00059: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 530736.5625 - val_loss: 623613.4375\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 600752.1875\n",
      "Epoch 00060: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 600752.1875 - val_loss: 688007.5625\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 605046.6875\n",
      "Epoch 00061: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 605046.6875 - val_loss: 670828.3125\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 507372.5938\n",
      "Epoch 00062: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 507372.5938 - val_loss: 761939.4375\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 560901.1250\n",
      "Epoch 00063: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 560901.1250 - val_loss: 725866.3125\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 547752.1875\n",
      "Epoch 00064: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 547752.1875 - val_loss: 1238483.1250\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 647407.0625\n",
      "Epoch 00065: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 647407.0625 - val_loss: 1070714.6250\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 518291.5312\n",
      "Epoch 00066: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 518291.5312 - val_loss: 812855.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 512775.9688\n",
      "Epoch 00067: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 512775.9688 - val_loss: 822270.1875\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 615952.3750\n",
      "Epoch 00068: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 615952.3750 - val_loss: 546126.6250\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 597301.1875\n",
      "Epoch 00069: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 597301.1875 - val_loss: 790330.6250\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 612297.4375\n",
      "Epoch 00070: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 612297.4375 - val_loss: 785968.5625\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 527600.3750\n",
      "Epoch 00071: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 527600.3750 - val_loss: 729901.5000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 580513.9375\n",
      "Epoch 00072: val_loss did not improve from 464728.06250\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0009492187527939677.\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 580513.9375 - val_loss: 1107815.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 512886.4375\n",
      "Epoch 00073: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 472ms/step - loss: 512886.4375 - val_loss: 1321751.8750\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 632987.9375\n",
      "Epoch 00074: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 632987.9375 - val_loss: 801193.1250\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 555391.3125\n",
      "Epoch 00075: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 555391.3125 - val_loss: 929287.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 540746.2500\n",
      "Epoch 00076: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 540746.2500 - val_loss: 941015.6250\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 618025.8125\n",
      "Epoch 00077: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 618025.8125 - val_loss: 648874.6875\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 693629.2500\n",
      "Epoch 00078: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 693629.2500 - val_loss: 846031.5000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 477200.8750\n",
      "Epoch 00079: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 477200.8750 - val_loss: 885046.6875\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 569032.3750\n",
      "Epoch 00080: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 569032.3750 - val_loss: 710558.0625\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 571635.0000\n",
      "Epoch 00081: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 571635.0000 - val_loss: 734818.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 514503.8438\n",
      "Epoch 00082: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 514503.8438 - val_loss: 894181.2500\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 475805.0625\n",
      "Epoch 00083: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 475805.0625 - val_loss: 641382.2500\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 542832.4375\n",
      "Epoch 00084: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 542832.4375 - val_loss: 925184.4375\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 511279.9375\n",
      "Epoch 00085: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 511279.9375 - val_loss: 920755.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 575140.6875\n",
      "Epoch 00086: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 575140.6875 - val_loss: 806672.9375\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 554440.4375\n",
      "Epoch 00087: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 554440.4375 - val_loss: 853890.5625\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 566967.6250\n",
      "Epoch 00088: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 566967.6250 - val_loss: 789651.8125\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 548697.5625\n",
      "Epoch 00089: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 548697.5625 - val_loss: 744365.8125\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 619098.7500\n",
      "Epoch 00090: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 619098.7500 - val_loss: 786945.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 613286.0000\n",
      "Epoch 00091: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 613286.0000 - val_loss: 476343.4688\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 621778.1250\n",
      "Epoch 00092: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 621778.1250 - val_loss: 745575.2500\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 567791.1250\n",
      "Epoch 00093: val_loss did not improve from 464728.06250\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0007119140645954758.\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 567791.1250 - val_loss: 805200.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 625675.5625\n",
      "Epoch 00094: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 15s 453ms/step - loss: 625675.5625 - val_loss: 705568.4375\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 579561.8750\n",
      "Epoch 00095: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 579561.8750 - val_loss: 881500.3125\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 580691.5000\n",
      "Epoch 00096: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 580691.5000 - val_loss: 800621.3750\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 595592.6875\n",
      "Epoch 00097: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 595592.6875 - val_loss: 646633.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 616473.2500\n",
      "Epoch 00098: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 616473.2500 - val_loss: 946344.4375\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 546379.7500\n",
      "Epoch 00099: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 546379.7500 - val_loss: 745854.8125\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 585913.4375\n",
      "Epoch 00100: val_loss did not improve from 464728.06250\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 585913.4375 - val_loss: 1018134.4375\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 3 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 8176782.0000\n",
      "Epoch 00001: val_loss improved from inf to 1373581824.00000, saving model to fold-3.h5\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 8176782.0000 - val_loss: 1373581824.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 6315255.5000\n",
      "Epoch 00002: val_loss improved from 1373581824.00000 to 3105016.75000, saving model to fold-3.h5\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 6315255.5000 - val_loss: 3105016.7500\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4945396.0000\n",
      "Epoch 00003: val_loss improved from 3105016.75000 to 2406735.00000, saving model to fold-3.h5\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 4945396.0000 - val_loss: 2406735.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4394344.5000\n",
      "Epoch 00004: val_loss did not improve from 2406735.00000\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 4394344.5000 - val_loss: 2708688.5000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3507650.0000\n",
      "Epoch 00005: val_loss did not improve from 2406735.00000\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 3507650.0000 - val_loss: 2897170.5000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3710533.7500\n",
      "Epoch 00006: val_loss improved from 2406735.00000 to 1517098.12500, saving model to fold-3.h5\n",
      "32/32 [==============================] - 16s 488ms/step - loss: 3710533.7500 - val_loss: 1517098.1250\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2034474.7500\n",
      "Epoch 00007: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 2034474.7500 - val_loss: 73387080.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2374801.2500\n",
      "Epoch 00008: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 2374801.2500 - val_loss: 9221340.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2223118.7500\n",
      "Epoch 00009: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 2223118.7500 - val_loss: 298464256.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1543895.5000\n",
      "Epoch 00010: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 1543895.5000 - val_loss: 1832833.2500\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1496329.1250\n",
      "Epoch 00011: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 1496329.1250 - val_loss: 110636240.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1052127.5000\n",
      "Epoch 00012: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1052127.5000 - val_loss: 8106836.5000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1232614.3750\n",
      "Epoch 00013: val_loss did not improve from 1517098.12500\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 1232614.3750 - val_loss: 9336265.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1138740.7500\n",
      "Epoch 00014: val_loss improved from 1517098.12500 to 1167698.62500, saving model to fold-3.h5\n",
      "32/32 [==============================] - 16s 492ms/step - loss: 1138740.7500 - val_loss: 1167698.6250\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 958090.0000\n",
      "Epoch 00015: val_loss improved from 1167698.62500 to 519744.15625, saving model to fold-3.h5\n",
      "32/32 [==============================] - 15s 480ms/step - loss: 958090.0000 - val_loss: 519744.1562\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 803473.3750\n",
      "Epoch 00016: val_loss did not improve from 519744.15625\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 803473.3750 - val_loss: 803172.8750\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 839158.5625\n",
      "Epoch 00017: val_loss did not improve from 519744.15625\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 839158.5625 - val_loss: 556016.5000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 804482.6250\n",
      "Epoch 00018: val_loss did not improve from 519744.15625\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 804482.6250 - val_loss: 595610.3750\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 772933.6250\n",
      "Epoch 00019: val_loss did not improve from 519744.15625\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 772933.6250 - val_loss: 907091.5625\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 743682.8125\n",
      "Epoch 00020: val_loss improved from 519744.15625 to 493346.00000, saving model to fold-3.h5\n",
      "32/32 [==============================] - 16s 486ms/step - loss: 743682.8125 - val_loss: 493346.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 657184.5000\n",
      "Epoch 00021: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 657184.5000 - val_loss: 763438.8750\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 620510.2500\n",
      "Epoch 00022: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 620510.2500 - val_loss: 2088413.1250\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 547675.6875\n",
      "Epoch 00023: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 547675.6875 - val_loss: 1556815.8750\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 607967.0625\n",
      "Epoch 00024: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 607967.0625 - val_loss: 730358.1875\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 718168.6875\n",
      "Epoch 00025: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 718168.6875 - val_loss: 770317.2500\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 654565.3125\n",
      "Epoch 00026: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 654565.3125 - val_loss: 808172.2500\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 708898.8125\n",
      "Epoch 00027: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 708898.8125 - val_loss: 1168811.3750\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 638324.4375\n",
      "Epoch 00028: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 638324.4375 - val_loss: 682975.5000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 556531.4375\n",
      "Epoch 00029: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 556531.4375 - val_loss: 952427.5625\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 627217.5000\n",
      "Epoch 00030: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 627217.5000 - val_loss: 745709.4375\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 688552.1250\n",
      "Epoch 00031: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 688552.1250 - val_loss: 678817.1250\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 720862.6250\n",
      "Epoch 00032: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 720862.6250 - val_loss: 687616.5000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 635452.5000\n",
      "Epoch 00033: val_loss did not improve from 493346.00000\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.002250000019557774.\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 635452.5000 - val_loss: 648778.1875\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 568110.5000\n",
      "Epoch 00034: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 568110.5000 - val_loss: 756126.8125\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 594372.5000\n",
      "Epoch 00035: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 594372.5000 - val_loss: 599570.3750\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 729226.1875\n",
      "Epoch 00036: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 729226.1875 - val_loss: 815686.1250\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 751913.0000\n",
      "Epoch 00037: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 751913.0000 - val_loss: 855335.3750\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 599615.9375\n",
      "Epoch 00038: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 599615.9375 - val_loss: 653987.6250\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 516829.7500\n",
      "Epoch 00039: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 516829.7500 - val_loss: 702315.6875\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 667987.8125\n",
      "Epoch 00040: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 667987.8125 - val_loss: 625415.3125\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 777494.1250\n",
      "Epoch 00041: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 777494.1250 - val_loss: 572256.0625\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 608006.1250\n",
      "Epoch 00042: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 608006.1250 - val_loss: 687502.6875\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 662430.1250\n",
      "Epoch 00043: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 662430.1250 - val_loss: 735600.0625\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 711811.0625\n",
      "Epoch 00044: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 711811.0625 - val_loss: 764663.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 718852.5000\n",
      "Epoch 00045: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 718852.5000 - val_loss: 730034.5000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 670740.6250\n",
      "Epoch 00046: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 670740.6250 - val_loss: 691917.8125\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 634997.1250\n",
      "Epoch 00047: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 634997.1250 - val_loss: 617747.0625\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 699116.5000\n",
      "Epoch 00048: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 699116.5000 - val_loss: 659997.3125\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 725244.8125\n",
      "Epoch 00049: val_loss did not improve from 493346.00000\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0016874999273568392.\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 725244.8125 - val_loss: 655945.0625\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 650273.8750\n",
      "Epoch 00050: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 650273.8750 - val_loss: 739104.6875\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 722875.6875\n",
      "Epoch 00051: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 722875.6875 - val_loss: 646430.3125\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 594982.5625\n",
      "Epoch 00052: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 594982.5625 - val_loss: 760071.3125\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 603838.1250\n",
      "Epoch 00053: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 603838.1250 - val_loss: 914185.9375\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 605698.6250\n",
      "Epoch 00054: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 605698.6250 - val_loss: 828172.1875\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 709865.3125\n",
      "Epoch 00055: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 709865.3125 - val_loss: 638252.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 615174.3750\n",
      "Epoch 00056: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 615174.3750 - val_loss: 721243.5000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 614616.6875\n",
      "Epoch 00057: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 614616.6875 - val_loss: 732155.8750\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 602872.1875\n",
      "Epoch 00058: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 602872.1875 - val_loss: 651948.8750\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 523268.7500\n",
      "Epoch 00059: val_loss did not improve from 493346.00000\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0012656249455176294.\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 523268.7500 - val_loss: 855601.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 562519.0000\n",
      "Epoch 00060: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 562519.0000 - val_loss: 712619.2500\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 661300.2500\n",
      "Epoch 00061: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 661300.2500 - val_loss: 905167.2500\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 616432.5625\n",
      "Epoch 00062: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 616432.5625 - val_loss: 807611.0625\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 658315.3125\n",
      "Epoch 00063: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 658315.3125 - val_loss: 837723.9375\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 569882.8750\n",
      "Epoch 00064: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 569882.8750 - val_loss: 683011.8125\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 640646.3125\n",
      "Epoch 00065: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 640646.3125 - val_loss: 818362.1250\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 550555.6875\n",
      "Epoch 00066: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 550555.6875 - val_loss: 713800.7500\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 640403.1250\n",
      "Epoch 00067: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 640403.1250 - val_loss: 774415.5625\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 494458.5625\n",
      "Epoch 00068: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 494458.5625 - val_loss: 588007.5625\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 507299.1875\n",
      "Epoch 00069: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 507299.1875 - val_loss: 726796.2500\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 574379.2500\n",
      "Epoch 00070: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 574379.2500 - val_loss: 812842.4375\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 718750.9375\n",
      "Epoch 00071: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 718750.9375 - val_loss: 903887.2500\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 689867.2500\n",
      "Epoch 00072: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 689867.2500 - val_loss: 683506.8125\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 661024.8750\n",
      "Epoch 00073: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 661024.8750 - val_loss: 825588.6250\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 453161.7812\n",
      "Epoch 00074: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 453161.7812 - val_loss: 841170.6875\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 707004.2500\n",
      "Epoch 00075: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 707004.2500 - val_loss: 744495.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 706204.5000\n",
      "Epoch 00076: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 706204.5000 - val_loss: 880573.0625\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 726136.2500\n",
      "Epoch 00077: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 726136.2500 - val_loss: 898287.1250\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 513902.5625\n",
      "Epoch 00078: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 513902.5625 - val_loss: 873071.6875\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 651126.9375\n",
      "Epoch 00079: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 651126.9375 - val_loss: 813662.1875\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 503036.9688\n",
      "Epoch 00080: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 503036.9688 - val_loss: 887064.5000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 680782.3750\n",
      "Epoch 00081: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 680782.3750 - val_loss: 607005.5625\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 553591.9375\n",
      "Epoch 00082: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 553591.9375 - val_loss: 655409.9375\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 695887.0625\n",
      "Epoch 00083: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 695887.0625 - val_loss: 696357.1250\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 596012.0625\n",
      "Epoch 00084: val_loss did not improve from 493346.00000\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0009492187527939677.\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 596012.0625 - val_loss: 709893.0625\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 612861.4375\n",
      "Epoch 00085: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 612861.4375 - val_loss: 670544.0625\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 604326.5625\n",
      "Epoch 00086: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 604326.5625 - val_loss: 705446.3750\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 601322.1250\n",
      "Epoch 00087: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 601322.1250 - val_loss: 698803.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 563579.3750\n",
      "Epoch 00088: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 563579.3750 - val_loss: 759463.7500\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 606829.6875\n",
      "Epoch 00089: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 606829.6875 - val_loss: 787624.8750\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 731258.9375\n",
      "Epoch 00090: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 453ms/step - loss: 731258.9375 - val_loss: 756739.5000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 653679.0000\n",
      "Epoch 00091: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 653679.0000 - val_loss: 711094.6250\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 694490.2500\n",
      "Epoch 00092: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 694490.2500 - val_loss: 719428.9375\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 575684.6250\n",
      "Epoch 00093: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 575684.6250 - val_loss: 704684.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 525947.3125\n",
      "Epoch 00094: val_loss did not improve from 493346.00000\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0007119140645954758.\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 525947.3125 - val_loss: 596499.5000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 648521.5625\n",
      "Epoch 00095: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 648521.5625 - val_loss: 574351.6250\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 523967.3438\n",
      "Epoch 00096: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 523967.3438 - val_loss: 520399.6875\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 584016.7500\n",
      "Epoch 00097: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 584016.7500 - val_loss: 811067.8125\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 691579.3750\n",
      "Epoch 00098: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 691579.3750 - val_loss: 641831.0625\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 612991.5625\n",
      "Epoch 00099: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 612991.5625 - val_loss: 622475.3750\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 649300.6250\n",
      "Epoch 00100: val_loss did not improve from 493346.00000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 649300.6250 - val_loss: 639546.2500\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 4 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 8167114.5000\n",
      "Epoch 00001: val_loss improved from inf to 22264596.00000, saving model to fold-4.h5\n",
      "32/32 [==============================] - 17s 541ms/step - loss: 8167114.5000 - val_loss: 22264596.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 7255845.5000\n",
      "Epoch 00002: val_loss did not improve from 22264596.00000\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 7255845.5000 - val_loss: 150749648.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 6570005.0000\n",
      "Epoch 00003: val_loss did not improve from 22264596.00000\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 6570005.0000 - val_loss: 49016788.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4726196.0000\n",
      "Epoch 00004: val_loss improved from 22264596.00000 to 1510281.12500, saving model to fold-4.h5\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 4726196.0000 - val_loss: 1510281.1250\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3234484.7500\n",
      "Epoch 00005: val_loss did not improve from 1510281.12500\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 3234484.7500 - val_loss: 3125071.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2720439.0000\n",
      "Epoch 00006: val_loss did not improve from 1510281.12500\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 2720439.0000 - val_loss: 1781018.6250\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2676265.0000\n",
      "Epoch 00007: val_loss did not improve from 1510281.12500\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 2676265.0000 - val_loss: 2155785.5000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2281210.0000\n",
      "Epoch 00008: val_loss improved from 1510281.12500 to 1105607.87500, saving model to fold-4.h5\n",
      "32/32 [==============================] - 16s 510ms/step - loss: 2281210.0000 - val_loss: 1105607.8750\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2179502.7500\n",
      "Epoch 00009: val_loss did not improve from 1105607.87500\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 2179502.7500 - val_loss: 2494679.7500\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1663286.6250\n",
      "Epoch 00010: val_loss did not improve from 1105607.87500\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 1663286.6250 - val_loss: 2554094.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1460027.5000\n",
      "Epoch 00011: val_loss did not improve from 1105607.87500\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 1460027.5000 - val_loss: 2783968.5000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1380505.6250\n",
      "Epoch 00012: val_loss improved from 1105607.87500 to 479686.28125, saving model to fold-4.h5\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 1380505.6250 - val_loss: 479686.2812\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1126456.8750\n",
      "Epoch 00013: val_loss improved from 479686.28125 to 440655.18750, saving model to fold-4.h5\n",
      "32/32 [==============================] - 16s 498ms/step - loss: 1126456.8750 - val_loss: 440655.1875\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1194977.5000\n",
      "Epoch 00014: val_loss did not improve from 440655.18750\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 1194977.5000 - val_loss: 456440.8125\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 869268.8750\n",
      "Epoch 00015: val_loss did not improve from 440655.18750\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 869268.8750 - val_loss: 522142.6875\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 1003422.7500\n",
      "Epoch 00016: val_loss did not improve from 440655.18750\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1003422.7500 - val_loss: 448679.4062\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 980391.2500\n",
      "Epoch 00017: val_loss improved from 440655.18750 to 350948.43750, saving model to fold-4.h5\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 980391.2500 - val_loss: 350948.4375\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 650220.8125\n",
      "Epoch 00018: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 650220.8125 - val_loss: 589726.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 685473.8125\n",
      "Epoch 00019: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 685473.8125 - val_loss: 568398.9375\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 760293.4375\n",
      "Epoch 00020: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 760293.4375 - val_loss: 479888.8438\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 560112.8750\n",
      "Epoch 00021: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 560112.8750 - val_loss: 490857.0938\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 795253.2500\n",
      "Epoch 00022: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 795253.2500 - val_loss: 605337.3750\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 646541.7500\n",
      "Epoch 00023: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 646541.7500 - val_loss: 548295.9375\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 621005.6250\n",
      "Epoch 00024: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 621005.6250 - val_loss: 366858.7812\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 668521.2500\n",
      "Epoch 00025: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 668521.2500 - val_loss: 605877.7500\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 839370.2500\n",
      "Epoch 00026: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 839370.2500 - val_loss: 644628.0625\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 698326.6250\n",
      "Epoch 00027: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 698326.6250 - val_loss: 568047.6250\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 748767.2500\n",
      "Epoch 00028: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 748767.2500 - val_loss: 613246.7500\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 548812.2500\n",
      "Epoch 00029: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 548812.2500 - val_loss: 637699.2500\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 691285.3750\n",
      "Epoch 00030: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 691285.3750 - val_loss: 674431.6250\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 693000.3750\n",
      "Epoch 00031: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 693000.3750 - val_loss: 551559.2500\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 629660.0000\n",
      "Epoch 00032: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 629660.0000 - val_loss: 655084.3750\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 644137.1250\n",
      "Epoch 00033: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 644137.1250 - val_loss: 563112.3750\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 698033.0000\n",
      "Epoch 00034: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 698033.0000 - val_loss: 638874.8125\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 565984.8125\n",
      "Epoch 00035: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 565984.8125 - val_loss: 585179.6250\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 611980.0000\n",
      "Epoch 00036: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 611980.0000 - val_loss: 554369.0625\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 753146.4375\n",
      "Epoch 00037: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 753146.4375 - val_loss: 566567.3125\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 648483.1875\n",
      "Epoch 00038: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 648483.1875 - val_loss: 544072.5000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 682749.5000\n",
      "Epoch 00039: val_loss did not improve from 350948.43750\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.002250000019557774.\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 682749.5000 - val_loss: 576902.3750\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 881723.0625\n",
      "Epoch 00040: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 881723.0625 - val_loss: 436753.6250\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 560369.8125\n",
      "Epoch 00041: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 465ms/step - loss: 560369.8125 - val_loss: 634490.7500\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 705660.8125\n",
      "Epoch 00042: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 705660.8125 - val_loss: 645181.7500\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 581513.0000\n",
      "Epoch 00043: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 581513.0000 - val_loss: 497051.1562\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 658911.6250\n",
      "Epoch 00044: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 658911.6250 - val_loss: 449598.3750\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 508719.5938\n",
      "Epoch 00045: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 508719.5938 - val_loss: 618572.8750\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 747963.5625\n",
      "Epoch 00046: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 747963.5625 - val_loss: 651346.8750\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 769366.8750\n",
      "Epoch 00047: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 769366.8750 - val_loss: 707290.3125\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 657567.0000\n",
      "Epoch 00048: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 657567.0000 - val_loss: 580906.1875\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 665247.7500\n",
      "Epoch 00049: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 665247.7500 - val_loss: 631824.7500\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 587015.3750\n",
      "Epoch 00050: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 587015.3750 - val_loss: 626980.3125\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 650111.0000\n",
      "Epoch 00051: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 650111.0000 - val_loss: 652444.1250\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 663796.9375\n",
      "Epoch 00052: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 663796.9375 - val_loss: 500337.6250\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 724302.9375\n",
      "Epoch 00053: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 724302.9375 - val_loss: 597382.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 811498.1250\n",
      "Epoch 00054: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 811498.1250 - val_loss: 693642.4375\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 526627.3750\n",
      "Epoch 00055: val_loss did not improve from 350948.43750\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0016874999273568392.\n",
      "32/32 [==============================] - 15s 481ms/step - loss: 526627.3750 - val_loss: 580215.1875\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 680740.6250\n",
      "Epoch 00056: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 680740.6250 - val_loss: 501532.8750\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 659394.5625\n",
      "Epoch 00057: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 659394.5625 - val_loss: 668386.7500\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 544563.5000\n",
      "Epoch 00058: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 544563.5000 - val_loss: 588876.8125\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 637320.5000\n",
      "Epoch 00059: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 637320.5000 - val_loss: 528171.1250\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 572091.8750\n",
      "Epoch 00060: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 572091.8750 - val_loss: 656141.6250\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 596136.1250\n",
      "Epoch 00061: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 596136.1250 - val_loss: 744351.6250\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 582785.1250\n",
      "Epoch 00062: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 582785.1250 - val_loss: 537506.0625\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 470708.9062\n",
      "Epoch 00063: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 470708.9062 - val_loss: 603452.8125\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 590681.5625\n",
      "Epoch 00064: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 590681.5625 - val_loss: 712355.5000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 575280.5625\n",
      "Epoch 00065: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 575280.5625 - val_loss: 673899.6250\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 588809.9375\n",
      "Epoch 00066: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 588809.9375 - val_loss: 510289.2812\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 717157.9375\n",
      "Epoch 00067: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 717157.9375 - val_loss: 605274.0625\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 649970.9375\n",
      "Epoch 00068: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 649970.9375 - val_loss: 599023.6875\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 661196.5625\n",
      "Epoch 00069: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 661196.5625 - val_loss: 691345.1250\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 627562.0000\n",
      "Epoch 00070: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 627562.0000 - val_loss: 594004.8125\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 627551.2500\n",
      "Epoch 00071: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 453ms/step - loss: 627551.2500 - val_loss: 596483.2500\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 627752.9375\n",
      "Epoch 00072: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 627752.9375 - val_loss: 571723.5000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 522636.7500\n",
      "Epoch 00073: val_loss did not improve from 350948.43750\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0012656249455176294.\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 522636.7500 - val_loss: 546650.1250\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 506743.5312\n",
      "Epoch 00074: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 506743.5312 - val_loss: 764795.3750\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 603918.0000\n",
      "Epoch 00075: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 603918.0000 - val_loss: 686058.1875\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 565906.8750\n",
      "Epoch 00076: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 565906.8750 - val_loss: 640163.0625\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 547434.1875\n",
      "Epoch 00077: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 25s 789ms/step - loss: 547434.1875 - val_loss: 766728.2500\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 636495.8750\n",
      "Epoch 00078: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 472ms/step - loss: 636495.8750 - val_loss: 510515.8438\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 602259.9375\n",
      "Epoch 00079: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 602259.9375 - val_loss: 568186.9375\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 637632.1875\n",
      "Epoch 00080: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 637632.1875 - val_loss: 694219.5000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 570632.8750\n",
      "Epoch 00081: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 570632.8750 - val_loss: 545711.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 670755.0000\n",
      "Epoch 00082: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 670755.0000 - val_loss: 680944.9375\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 685125.9375\n",
      "Epoch 00083: val_loss did not improve from 350948.43750\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0009492187527939677.\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 685125.9375 - val_loss: 607323.1875\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 590001.4375\n",
      "Epoch 00084: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 590001.4375 - val_loss: 541911.3125\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 629002.5625\n",
      "Epoch 00085: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 629002.5625 - val_loss: 627812.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 641074.7500\n",
      "Epoch 00086: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 641074.7500 - val_loss: 679527.0625\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 602929.6875\n",
      "Epoch 00087: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 602929.6875 - val_loss: 563713.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 495537.5938\n",
      "Epoch 00088: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 495537.5938 - val_loss: 606893.7500\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 642552.0000\n",
      "Epoch 00089: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 642552.0000 - val_loss: 767314.8750\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 552372.3125\n",
      "Epoch 00090: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 552372.3125 - val_loss: 597297.6250\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 535368.0000\n",
      "Epoch 00091: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 535368.0000 - val_loss: 570705.2500\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 614632.3750\n",
      "Epoch 00092: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 614632.3750 - val_loss: 490024.3750\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 589325.0000\n",
      "Epoch 00093: val_loss did not improve from 350948.43750\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0007119140645954758.\n",
      "32/32 [==============================] - 15s 454ms/step - loss: 589325.0000 - val_loss: 528129.4375\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 652138.6875\n",
      "Epoch 00094: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 652138.6875 - val_loss: 605018.6250\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 559032.3750\n",
      "Epoch 00095: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 559032.3750 - val_loss: 497822.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 567853.2500\n",
      "Epoch 00096: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 567853.2500 - val_loss: 433119.5625\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 575341.5625\n",
      "Epoch 00097: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 575341.5625 - val_loss: 602186.4375\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 570342.7500\n",
      "Epoch 00098: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 570342.7500 - val_loss: 473632.1875\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 541949.0000\n",
      "Epoch 00099: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 541949.0000 - val_loss: 679358.3750\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 530256.2500\n",
      "Epoch 00100: val_loss did not improve from 350948.43750\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 530256.2500 - val_loss: 480599.3438\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=NFOLD, random_state=42,shuffle=False)\n",
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(P)):\n",
    "    print('#####################')\n",
    "    print('####### Fold %i ######'%fold)\n",
    "    print('#####################')\n",
    "    print('Training...')\n",
    "    \n",
    "    er = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", #val_loss\n",
    "        min_delta=1e-3,\n",
    "        patience=50,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    cpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='fold-%i.h5'%fold,\n",
    "        monitor='val_loss', \n",
    "        verbose=1, \n",
    "        save_best_only=SAVE_BEST,\n",
    "        mode='auto'\n",
    "    )\n",
    "\n",
    "    rlp = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', #val_loss\n",
    "        factor=0.75,\n",
    "        patience=10, \n",
    "        verbose=1, \n",
    "        min_lr=1e-8\n",
    "    )\n",
    "    model = build_model(model_class=MODEL_CLASS)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mse\") \n",
    "    history = model.fit_generator(IGenerator(keys=P[tr_idx], \n",
    "                                   tab = TAB), \n",
    "                        steps_per_epoch = 32,\n",
    "                        validation_data=IGenerator(keys=P[val_idx], \n",
    "                                   tab = TAB),\n",
    "                        validation_steps = 16, \n",
    "                        callbacks = [cpt, rlp], \n",
    "                        epochs=EPOCHS)\n",
    "    folds_history.append(history.history)\n",
    "    print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:24:19.822690Z",
     "iopub.status.busy": "2020-10-30T17:24:19.821521Z",
     "iopub.status.idle": "2020-10-30T17:24:19.833543Z",
     "shell.execute_reply": "2020-10-30T17:24:19.835533Z"
    },
    "papermill": {
     "duration": 7.185563,
     "end_time": "2020-10-30T17:24:19.835781",
     "exception": false,
     "start_time": "2020-10-30T17:24:12.650218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 344798.3125\n",
      "344798.3125\n"
     ]
    }
   ],
   "source": [
    "min_array = []\n",
    "for i in range(1):\n",
    "    min_array.append(min(folds_history[i]['val_loss']))\n",
    "    print(i, min(folds_history[i]['val_loss']))\n",
    "print(min(min_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:24:33.900633Z",
     "iopub.status.busy": "2020-10-30T17:24:33.899451Z",
     "iopub.status.idle": "2020-10-30T17:24:33.917848Z",
     "shell.execute_reply": "2020-10-30T17:24:33.918851Z"
    },
    "papermill": {
     "duration": 6.979484,
     "end_time": "2020-10-30T17:24:33.919163",
     "exception": false,
     "start_time": "2020-10-30T17:24:26.939679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean CV MAE is: 395306.21875\n"
     ]
    }
   ],
   "source": [
    "# We pick the best model (weights) based on cross validation score.\n",
    "if SAVE_BEST:\n",
    "    mean_val_loss = np.mean([np.min(h['val_loss']) for h in folds_history])\n",
    "else:\n",
    "    mean_val_loss = np.mean([h['val_loss'][-1] for h in folds_history])\n",
    "print('Our mean CV MAE is: ' + str(mean_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.346966,
     "end_time": "2020-10-30T17:24:49.476222",
     "exception": false,
     "start_time": "2020-10-30T17:24:42.129256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "min_fold finds out which fold gives the least validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:25:03.372257Z",
     "iopub.status.busy": "2020-10-30T17:25:03.371479Z",
     "iopub.status.idle": "2020-10-30T17:25:03.377439Z",
     "shell.execute_reply": "2020-10-30T17:25:03.376847Z"
    },
    "papermill": {
     "duration": 7.039653,
     "end_time": "2020-10-30T17:25:03.377564",
     "exception": false,
     "start_time": "2020-10-30T17:24:56.337911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_fold = np.argmin([np.min(h['val_loss']) for h in folds_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:25:17.911990Z",
     "iopub.status.busy": "2020-10-30T17:25:17.909837Z",
     "iopub.status.idle": "2020-10-30T17:25:17.912776Z",
     "shell.execute_reply": "2020-10-30T17:25:17.913353Z"
    },
    "papermill": {
     "duration": 6.849139,
     "end_time": "2020-10-30T17:25:17.913501",
     "exception": false,
     "start_time": "2020-10-30T17:25:11.064362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#min_fold = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.094222,
     "end_time": "2020-10-30T17:25:32.251845",
     "exception": false,
     "start_time": "2020-10-30T17:25:25.157623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "building model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:25:48.025774Z",
     "iopub.status.busy": "2020-10-30T17:25:48.019480Z",
     "iopub.status.idle": "2020-10-30T17:26:44.314580Z",
     "shell.execute_reply": "2020-10-30T17:26:44.313568Z"
    },
    "papermill": {
     "duration": 64.266391,
     "end_time": "2020-10-30T17:26:44.314708",
     "exception": false,
     "start_time": "2020-10-30T17:25:40.048317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_pred_model(shape=(512, 512, 1), model_class=None, fold=None):\n",
    "    inp = Input(shape=shape) # 512 x 512 input shape\n",
    "    base = get_efficientnet(model_class, shape) # A b1 pre-trained efficientnet is used\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(10,)) #change the num of nodes when we add new features\n",
    "    x2 = tf.keras.layers.GaussianNoise(0.2)(inp2)\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    \n",
    "    # Take from kaggle  working output\n",
    "    weights = [w for w in os.listdir('./') if str(fold) in w][0] #use dir of './' if using training above, else can just use my trained weights in input\n",
    "    model.load_weights('./' + weights) #use dir of './' if using training above, e\n",
    "    #weights = [w for w in os.listdir('../input/predict-fvc-direct-100epochs/') if str(fold) in w][0] #use dir of './' if using training above, else can just use my trained weights in input\n",
    "    #model.load_weights('../input/predict-fvc-direct-100epochs/' + weights) #use dir of './' if using training above, else can just use my trained weights in input\n",
    "    return model\n",
    "models = [build_pred_model(shape=(512, 512, 1), model_class='b1', fold=min_fold)]\n",
    "#uncomment the above to build model from the weights trained above, else can use the below code for building model\n",
    "#models = [build_pred_model(shape=(512, 512, 1), model_class='b1', fold=min_fold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:26:59.119311Z",
     "iopub.status.busy": "2020-10-30T17:26:59.118238Z",
     "iopub.status.idle": "2020-10-30T17:26:59.121756Z",
     "shell.execute_reply": "2020-10-30T17:26:59.121190Z"
    },
    "papermill": {
     "duration": 6.919077,
     "end_time": "2020-10-30T17:26:59.121872",
     "exception": false,
     "start_time": "2020-10-30T17:26:52.202795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_test_data(test_id, test):\n",
    "    final_test_data = []\n",
    "    sub = test.loc[test.Patient == test_id, :]\n",
    "    sub['bias'] = 0\n",
    "    sub['mean_percent_scld'] = sub['Percent_scld'].mean()\n",
    "    selected_sub = sub[['bias', 'baselined_week', 'base_FVC', 'mean_percent_scld', 'Age_scld', 'Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes']]\n",
    "    #get first row \n",
    "    selected_sub.reindex()\n",
    "    first = selected_sub.iloc[0].values.tolist()\n",
    "    for week in range(0, 146):\n",
    "        to_append = copy.deepcopy(first)\n",
    "        to_append[1] = week\n",
    "        final_test_data.append(to_append)\n",
    "    return final_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2020-10-30T17:27:13.445046Z",
     "iopub.status.busy": "2020-10-30T17:27:13.437428Z",
     "iopub.status.idle": "2020-10-30T17:28:48.753155Z",
     "shell.execute_reply": "2020-10-30T17:28:48.753881Z"
    },
    "papermill": {
     "duration": 102.50786,
     "end_time": "2020-10-30T17:28:48.754131",
     "exception": false,
     "start_time": "2020-10-30T17:27:06.246271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2437.406 ]\n",
      " [2430.0708]\n",
      " [2435.531 ]\n",
      " [2470.1152]\n",
      " [2446.9492]\n",
      " [2432.4507]\n",
      " [2433.0454]\n",
      " [2479.3652]\n",
      " [2453.0056]\n",
      " [2453.6003]\n",
      " [2484.449 ]\n",
      " [2481.4026]\n",
      " [2436.6152]\n",
      " [2481.9426]\n",
      " [2437.8052]\n",
      " [2483.1326]\n",
      " [2454.0884]\n",
      " [2432.151 ]\n",
      " [2484.0774]\n",
      " [2468.458 ]\n",
      " [2469.0527]\n",
      " [2486.7021]\n",
      " [2450.4949]\n",
      " [2436.3142]\n",
      " [2489.4795]\n",
      " [2490.0745]\n",
      " [2484.7283]\n",
      " [2453.4697]\n",
      " [2439.2888]\n",
      " [2485.6973]\n",
      " [2461.4124]\n",
      " [2447.9194]\n",
      " [2476.1924]\n",
      " [2457.0396]\n",
      " [2489.488 ]\n",
      " [2465.3926]\n",
      " [2427.726 ]\n",
      " [2490.4568]\n",
      " [2452.084 ]\n",
      " [2491.5334]\n",
      " [2498.6562]\n",
      " [2497.7612]\n",
      " [2447.6182]\n",
      " [2499.7913]\n",
      " [2494.5083]\n",
      " [2449.403 ]\n",
      " [2501.5762]\n",
      " [2497.2224]\n",
      " [2472.1216]\n",
      " [2472.7166]\n",
      " [2451.7844]\n",
      " [2452.3794]\n",
      " [2460.4136]\n",
      " [2461.0083]\n",
      " [2454.7578]\n",
      " [2467.0635]\n",
      " [2508.518 ]\n",
      " [2455.949 ]\n",
      " [2478.0713]\n",
      " [2464.5781]\n",
      " [2504.9568]\n",
      " [2458.3289]\n",
      " [2443.1948]\n",
      " [2481.046 ]\n",
      " [2472.4182]\n",
      " [2512.0403]\n",
      " [2487.513 ]\n",
      " [2518.3616]\n",
      " [2514.665 ]\n",
      " [2509.4956]\n",
      " [2520.1462]\n",
      " [2486.811 ]\n",
      " [2491.0828]\n",
      " [2511.8755]\n",
      " [2488.5962]\n",
      " [2482.0276]\n",
      " [2488.7803]\n",
      " [2515.071 ]\n",
      " [2475.8823]\n",
      " [2495.2473]\n",
      " [2470.2266]\n",
      " [2523.0496]\n",
      " [2497.032 ]\n",
      " [2506.5352]\n",
      " [2487.3823]\n",
      " [2507.725 ]\n",
      " [2519.6099]\n",
      " [2474.3914]\n",
      " [2527.5566]\n",
      " [2522.2107]\n",
      " [2510.6997]\n",
      " [2498.7104]\n",
      " [2492.1418]\n",
      " [2461.6384]\n",
      " [2525.1853]\n",
      " [2478.5574]\n",
      " [2501.685 ]\n",
      " [2479.7473]\n",
      " [2531.6738]\n",
      " [2507.1462]\n",
      " [2528.7551]\n",
      " [2535.2913]\n",
      " [2505.255 ]\n",
      " [2534.6487]\n",
      " [2531.135 ]\n",
      " [2530.8005]\n",
      " [2537.9233]\n",
      " [2537.8684]\n",
      " [2532.5854]\n",
      " [2539.0583]\n",
      " [2540.3032]\n",
      " [2472.3477]\n",
      " [2534.965 ]\n",
      " [2489.86  ]\n",
      " [2536.155 ]\n",
      " [2511.984 ]\n",
      " [2517.2605]\n",
      " [2543.8179]\n",
      " [2514.774 ]\n",
      " [2514.3638]\n",
      " [2539.8384]\n",
      " [2494.6199]\n",
      " [2541.0283]\n",
      " [2495.216 ]\n",
      " [2508.1155]\n",
      " [2543.629 ]\n",
      " [2549.1726]\n",
      " [2505.0352]\n",
      " [2545.4138]\n",
      " [2550.9573]\n",
      " [2545.7878]\n",
      " [2553.14  ]\n",
      " [2547.7937]\n",
      " [2513.4702]\n",
      " [2554.9246]\n",
      " [2528.5647]\n",
      " [2554.282 ]\n",
      " [2504.1392]\n",
      " [2504.7341]\n",
      " [2556.907 ]\n",
      " [2489.6013]\n",
      " [2552.3323]\n",
      " [2558.692 ]\n",
      " [2558.4468]\n",
      " [2554.933 ]\n",
      " [2561.1267]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2548.2183]\n",
      " [2598.0674]\n",
      " [2605.8745]\n",
      " [2554.9336]\n",
      " [2562.2021]\n",
      " [2599.5488]\n",
      " [2603.4463]\n",
      " [2604.9172]\n",
      " [2595.8267]\n",
      " [2558.1006]\n",
      " [2591.5806]\n",
      " [2603.1187]\n",
      " [2580.8062]\n",
      " [2609.8435]\n",
      " [2609.007 ]\n",
      " [2603.6982]\n",
      " [2596.41  ]\n",
      " [2566.3003]\n",
      " [2606.7075]\n",
      " [2616.5168]\n",
      " [2598.525 ]\n",
      " [2580.7385]\n",
      " [2612.983 ]\n",
      " [2573.0183]\n",
      " [2611.438 ]\n",
      " [2560.8276]\n",
      " [2614.5906]\n",
      " [2611.7202]\n",
      " [2615.6025]\n",
      " [2596.1536]\n",
      " [2615.3203]\n",
      " [2593.478 ]\n",
      " [2585.228 ]\n",
      " [2621.7424]\n",
      " [2605.5435]\n",
      " [2604.4353]\n",
      " [2620.393 ]\n",
      " [2598.8215]\n",
      " [2619.6697]\n",
      " [2624.9954]\n",
      " [2624.7798]\n",
      " [2623.8545]\n",
      " [2593.0193]\n",
      " [2617.8833]\n",
      " [2571.9463]\n",
      " [2627.499 ]\n",
      " [2624.9055]\n",
      " [2629.398 ]\n",
      " [2632.6702]\n",
      " [2624.8093]\n",
      " [2634.9607]\n",
      " [2627.4019]\n",
      " [2623.9614]\n",
      " [2632.0642]\n",
      " [2631.56  ]\n",
      " [2615.541 ]\n",
      " [2581.9568]\n",
      " [2626.3828]\n",
      " [2631.569 ]\n",
      " [2634.3823]\n",
      " [2607.7993]\n",
      " [2611.3267]\n",
      " [2639.9768]\n",
      " [2591.2632]\n",
      " [2632.9917]\n",
      " [2636.1445]\n",
      " [2638.7515]\n",
      " [2640.029 ]\n",
      " [2640.7463]\n",
      " [2635.8262]\n",
      " [2640.3071]\n",
      " [2591.8079]\n",
      " [2595.583 ]\n",
      " [2638.1658]\n",
      " [2636.327 ]\n",
      " [2645.371 ]\n",
      " [2646.3975]\n",
      " [2647.3774]\n",
      " [2599.1528]\n",
      " [2647.5332]\n",
      " [2593.5503]\n",
      " [2651.3923]\n",
      " [2647.4465]\n",
      " [2635.478 ]\n",
      " [2643.    ]\n",
      " [2651.4602]\n",
      " [2655.6633]\n",
      " [2656.4702]\n",
      " [2599.9465]\n",
      " [2655.992 ]\n",
      " [2657.0388]\n",
      " [2654.0251]\n",
      " [2628.4023]\n",
      " [2652.39  ]\n",
      " [2656.6035]\n",
      " [2657.7017]\n",
      " [2645.5925]\n",
      " [2643.64  ]\n",
      " [2662.803 ]\n",
      " [2654.8862]\n",
      " [2616.4941]\n",
      " [2660.8167]\n",
      " [2609.3245]\n",
      " [2647.3772]\n",
      " [2621.725 ]\n",
      " [2667.1794]\n",
      " [2659.2603]\n",
      " [2660.7192]\n",
      " [2658.8787]\n",
      " [2663.794 ]\n",
      " [2665.3293]\n",
      " [2617.9255]\n",
      " [2667.5347]\n",
      " [2668.13  ]\n",
      " [2655.306 ]\n",
      " [2619.139 ]\n",
      " [2666.0764]\n",
      " [2667.0823]\n",
      " [2656.835 ]\n",
      " [2654.4504]\n",
      " [2630.729 ]\n",
      " [2672.8894]\n",
      " [2664.364 ]\n",
      " [2651.1655]\n",
      " [2673.0269]\n",
      " [2679.0176]\n",
      " [2674.1963]\n",
      " [2675.2463]\n",
      " [2643.4167]\n",
      " [2663.1118]\n",
      " [2678.022 ]\n",
      " [2681.432 ]\n",
      " [2663.694 ]\n",
      " [2684.3418]\n",
      " [2665.3552]\n",
      " [2667.3877]\n",
      " [2676.9126]\n",
      " [2672.4553]\n",
      " [2679.263 ]\n",
      " [2668.6282]\n",
      " [2679.8613]\n",
      " [2678.157 ]\n",
      " [2675.5508]\n",
      " [2666.5674]\n",
      " [2685.5674]\n",
      " [2632.1191]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2556.3176]\n",
      " [2567.1067]\n",
      " [2544.7024]\n",
      " [2565.5886]\n",
      " [2638.949 ]\n",
      " [2558.568 ]\n",
      " [2607.0667]\n",
      " [2568.0056]\n",
      " [2568.5637]\n",
      " [2618.4045]\n",
      " [2563.0696]\n",
      " [2644.5015]\n",
      " [2553.2046]\n",
      " [2548.3176]\n",
      " [2653.1873]\n",
      " [2637.214 ]\n",
      " [2578.2888]\n",
      " [2566.9272]\n",
      " [2561.6587]\n",
      " [2643.8293]\n",
      " [2569.6252]\n",
      " [2649.0632]\n",
      " [2644.567 ]\n",
      " [2591.7988]\n",
      " [2560.5007]\n",
      " [2602.4814]\n",
      " [2573.7495]\n",
      " [2645.8147]\n",
      " [2561.9382]\n",
      " [2662.3325]\n",
      " [2662.9275]\n",
      " [2581.1238]\n",
      " [2661.7424]\n",
      " [2582.7566]\n",
      " [2618.302 ]\n",
      " [2588.382 ]\n",
      " [2585.238 ]\n",
      " [2585.9473]\n",
      " [2580.5237]\n",
      " [2590.7617]\n",
      " [2660.7173]\n",
      " [2603.0103]\n",
      " [2570.139 ]\n",
      " [2663.9717]\n",
      " [2668.2544]\n",
      " [2655.0627]\n",
      " [2587.4302]\n",
      " [2585.156 ]\n",
      " [2569.381 ]\n",
      " [2581.309 ]\n",
      " [2674.9822]\n",
      " [2582.8643]\n",
      " [2587.3076]\n",
      " [2651.7788]\n",
      " [2632.2737]\n",
      " [2581.2517]\n",
      " [2594.9512]\n",
      " [2665.3906]\n",
      " [2577.9607]\n",
      " [2617.2537]\n",
      " [2660.8032]\n",
      " [2593.3816]\n",
      " [2588.241 ]\n",
      " [2637.693 ]\n",
      " [2598.0217]\n",
      " [2582.1255]\n",
      " [2617.2415]\n",
      " [2678.5312]\n",
      " [2584.3887]\n",
      " [2584.5645]\n",
      " [2605.5603]\n",
      " [2684.037 ]\n",
      " [2681.3525]\n",
      " [2590.677 ]\n",
      " [2686.2715]\n",
      " [2608.4204]\n",
      " [2645.6123]\n",
      " [2673.5137]\n",
      " [2659.4568]\n",
      " [2644.9421]\n",
      " [2690.8328]\n",
      " [2636.9697]\n",
      " [2681.4546]\n",
      " [2681.1768]\n",
      " [2647.917 ]\n",
      " [2613.8086]\n",
      " [2626.65  ]\n",
      " [2690.131 ]\n",
      " [2634.3154]\n",
      " [2697.7222]\n",
      " [2636.3467]\n",
      " [2699.3755]\n",
      " [2685.689 ]\n",
      " [2601.396 ]\n",
      " [2597.4587]\n",
      " [2608.0447]\n",
      " [2693.0159]\n",
      " [2602.9558]\n",
      " [2698.0784]\n",
      " [2615.887 ]\n",
      " [2617.4397]\n",
      " [2621.8264]\n",
      " [2676.9348]\n",
      " [2681.5266]\n",
      " [2663.9775]\n",
      " [2662.3486]\n",
      " [2703.0173]\n",
      " [2640.665 ]\n",
      " [2701.9194]\n",
      " [2608.6633]\n",
      " [2654.2234]\n",
      " [2613.6462]\n",
      " [2622.164 ]\n",
      " [2631.0896]\n",
      " [2699.3027]\n",
      " [2632.3374]\n",
      " [2707.3848]\n",
      " [2669.8108]\n",
      " [2633.8452]\n",
      " [2634.2283]\n",
      " [2630.9412]\n",
      " [2710.3035]\n",
      " [2648.0684]\n",
      " [2709.7485]\n",
      " [2630.5874]\n",
      " [2620.5913]\n",
      " [2637.8008]\n",
      " [2628.7402]\n",
      " [2640.0884]\n",
      " [2654.7234]\n",
      " [2684.5486]\n",
      " [2658.657 ]\n",
      " [2660.6853]\n",
      " [2628.0603]\n",
      " [2643.5142]\n",
      " [2627.564 ]\n",
      " [2715.1333]\n",
      " [2645.3076]\n",
      " [2718.6729]\n",
      " [2639.6853]\n",
      " [2626.8125]\n",
      " [2715.1733]\n",
      " [2627.717 ]\n",
      " [2631.3003]\n",
      " [2634.7043]\n",
      " [2717.7466]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2775.1816]\n",
      " [2771.4783]\n",
      " [2779.8708]\n",
      " [2782.2654]\n",
      " [2750.6113]\n",
      " [2777.5872]\n",
      " [2786.7998]\n",
      " [2776.0845]\n",
      " [2722.4973]\n",
      " [2789.0151]\n",
      " [2785.2563]\n",
      " [2733.441 ]\n",
      " [2728.5337]\n",
      " [2788.49  ]\n",
      " [2790.9053]\n",
      " [2770.5908]\n",
      " [2754.7646]\n",
      " [2771.7808]\n",
      " [2788.9648]\n",
      " [2775.6768]\n",
      " [2791.3267]\n",
      " [2793.777 ]\n",
      " [2728.603 ]\n",
      " [2754.6482]\n",
      " [2764.1382]\n",
      " [2740.7356]\n",
      " [2734.1938]\n",
      " [2795.4604]\n",
      " [2796.114 ]\n",
      " [2797.151 ]\n",
      " [2799.7305]\n",
      " [2796.656 ]\n",
      " [2797.52  ]\n",
      " [2794.7646]\n",
      " [2788.1575]\n",
      " [2800.6497]\n",
      " [2772.9116]\n",
      " [2787.752 ]\n",
      " [2800.507 ]\n",
      " [2772.4653]\n",
      " [2802.0762]\n",
      " [2808.8928]\n",
      " [2798.6877]\n",
      " [2807.7388]\n",
      " [2790.0059]\n",
      " [2811.192 ]\n",
      " [2772.6133]\n",
      " [2771.0627]\n",
      " [2805.78  ]\n",
      " [2811.5955]\n",
      " [2749.1821]\n",
      " [2809.128 ]\n",
      " [2811.5352]\n",
      " [2763.1455]\n",
      " [2759.024 ]\n",
      " [2762.913 ]\n",
      " [2752.752 ]\n",
      " [2779.1582]\n",
      " [2766.1206]\n",
      " [2817.4932]\n",
      " [2816.178 ]\n",
      " [2804.0464]\n",
      " [2815.3867]\n",
      " [2815.8486]\n",
      " [2817.9744]\n",
      " [2761.3801]\n",
      " [2821.6318]\n",
      " [2824.2466]\n",
      " [2772.0698]\n",
      " [2804.8796]\n",
      " [2805.3408]\n",
      " [2820.6   ]\n",
      " [2820.4543]\n",
      " [2781.7295]\n",
      " [2797.4258]\n",
      " [2828.769 ]\n",
      " [2824.512 ]\n",
      " [2825.7087]\n",
      " [2825.0874]\n",
      " [2821.6135]\n",
      " [2777.7869]\n",
      " [2829.6555]\n",
      " [2828.2415]\n",
      " [2778.7961]\n",
      " [2831.2593]\n",
      " [2828.5085]\n",
      " [2768.3335]\n",
      " [2830.0168]\n",
      " [2830.834 ]\n",
      " [2831.3516]\n",
      " [2838.1477]\n",
      " [2816.8438]\n",
      " [2837.9656]\n",
      " [2839.75  ]\n",
      " [2796.0288]\n",
      " [2790.726 ]\n",
      " [2819.8186]\n",
      " [2781.8794]\n",
      " [2812.424 ]\n",
      " [2838.9465]\n",
      " [2834.3125]\n",
      " [2809.3525]\n",
      " [2812.1787]\n",
      " [2839.647 ]\n",
      " [2844.945 ]\n",
      " [2841.7117]\n",
      " [2843.4297]\n",
      " [2825.3267]\n",
      " [2790.117 ]\n",
      " [2821.9   ]\n",
      " [2843.7231]\n",
      " [2804.204 ]\n",
      " [2851.0542]\n",
      " [2850.5645]\n",
      " [2839.7449]\n",
      " [2846.3186]\n",
      " [2852.3494]\n",
      " [2844.7407]\n",
      " [2844.0002]\n",
      " [2849.012 ]\n",
      " [2835.0886]\n",
      " [2806.1948]\n",
      " [2850.2021]\n",
      " [2845.955 ]\n",
      " [2857.435 ]\n",
      " [2852.5818]\n",
      " [2856.5647]\n",
      " [2855.4565]\n",
      " [2855.553 ]\n",
      " [2855.081 ]\n",
      " [2854.9617]\n",
      " [2856.1516]\n",
      " [2863.11  ]\n",
      " [2859.6902]\n",
      " [2853.34  ]\n",
      " [2860.3535]\n",
      " [2855.2876]\n",
      " [2864.5786]\n",
      " [2864.9482]\n",
      " [2856.275 ]\n",
      " [2866.6282]\n",
      " [2862.3704]\n",
      " [2865.9478]\n",
      " [2864.486 ]\n",
      " [2870.058 ]\n",
      " [2864.6006]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2711.0244]\n",
      " [2706.9556]\n",
      " [2675.3843]\n",
      " [2689.6143]\n",
      " [2712.6726]\n",
      " [2701.7515]\n",
      " [2713.3054]\n",
      " [2712.0835]\n",
      " [2711.688 ]\n",
      " [2716.3792]\n",
      " [2689.6826]\n",
      " [2717.569 ]\n",
      " [2711.593 ]\n",
      " [2719.2458]\n",
      " [2711.2007]\n",
      " [2717.8093]\n",
      " [2712.3906]\n",
      " [2717.0425]\n",
      " [2717.0698]\n",
      " [2676.1377]\n",
      " [2707.7795]\n",
      " [2720.504 ]\n",
      " [2724.6003]\n",
      " [2686.524 ]\n",
      " [2680.1445]\n",
      " [2713.6506]\n",
      " [2696.058 ]\n",
      " [2690.2583]\n",
      " [2723.0193]\n",
      " [2727.1953]\n",
      " [2705.8367]\n",
      " [2725.322 ]\n",
      " [2717.8152]\n",
      " [2731.145 ]\n",
      " [2719.0051]\n",
      " [2731.8481]\n",
      " [2719.452 ]\n",
      " [2728.8914]\n",
      " [2728.5083]\n",
      " [2708.1013]\n",
      " [2693.8774]\n",
      " [2730.7537]\n",
      " [2705.5774]\n",
      " [2699.743 ]\n",
      " [2726.0464]\n",
      " [2737.0657]\n",
      " [2737.3096]\n",
      " [2737.6455]\n",
      " [2733.03  ]\n",
      " [2725.0334]\n",
      " [2716.003 ]\n",
      " [2715.241 ]\n",
      " [2737.1882]\n",
      " [2743.0498]\n",
      " [2739.0562]\n",
      " [2734.5112]\n",
      " [2737.92  ]\n",
      " [2742.7976]\n",
      " [2737.379 ]\n",
      " [2729.7622]\n",
      " [2736.2136]\n",
      " [2712.9138]\n",
      " [2746.829 ]\n",
      " [2707.5615]\n",
      " [2709.8745]\n",
      " [2734.5527]\n",
      " [2741.3252]\n",
      " [2731.6   ]\n",
      " [2750.1926]\n",
      " [2752.9275]\n",
      " [2714.4868]\n",
      " [2730.0713]\n",
      " [2715.6768]\n",
      " [2735.17  ]\n",
      " [2755.5437]\n",
      " [2754.7527]\n",
      " [2728.9497]\n",
      " [2756.4265]\n",
      " [2734.3347]\n",
      " [2752.9016]\n",
      " [2759.472 ]\n",
      " [2755.041 ]\n",
      " [2757.6936]\n",
      " [2758.2769]\n",
      " [2749.8445]\n",
      " [2755.1736]\n",
      " [2761.108 ]\n",
      " [2723.5583]\n",
      " [2764.2317]\n",
      " [2757.4045]\n",
      " [2765.4214]\n",
      " [2733.4724]\n",
      " [2759.1895]\n",
      " [2743.3186]\n",
      " [2740.824 ]\n",
      " [2763.708 ]\n",
      " [2731.31  ]\n",
      " [2767.4465]\n",
      " [2732.5   ]\n",
      " [2759.4172]\n",
      " [2747.4236]\n",
      " [2768.9756]\n",
      " [2761.202 ]\n",
      " [2765.9006]\n",
      " [2769.885 ]\n",
      " [2769.3484]\n",
      " [2770.9841]\n",
      " [2773.7913]\n",
      " [2764.9854]\n",
      " [2770.0762]\n",
      " [2769.9172]\n",
      " [2775.776 ]\n",
      " [2739.4749]\n",
      " [2777.9185]\n",
      " [2774.6746]\n",
      " [2778.5874]\n",
      " [2763.6748]\n",
      " [2780.8105]\n",
      " [2739.0356]\n",
      " [2771.5298]\n",
      " [2775.8481]\n",
      " [2782.2825]\n",
      " [2753.1738]\n",
      " [2784.691 ]\n",
      " [2746.6143]\n",
      " [2746.1667]\n",
      " [2785.989 ]\n",
      " [2780.1797]\n",
      " [2785.105 ]\n",
      " [2775.5261]\n",
      " [2781.8162]\n",
      " [2783.8394]\n",
      " [2752.6938]\n",
      " [2780.9175]\n",
      " [2760.7239]\n",
      " [2784.7913]\n",
      " [2785.5164]\n",
      " [2793.0203]\n",
      " [2784.162 ]\n",
      " [2781.4756]\n",
      " [2792.2444]\n",
      " [2784.619 ]\n",
      " [2794.4253]\n",
      " [2768.8118]\n",
      " [2790.8994]\n",
      " [2782.1492]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2441.8499]\n",
      " [2437.2698]\n",
      " [2443.0398]\n",
      " [2449.9277]\n",
      " [2417.9556]\n",
      " [2432.5046]\n",
      " [2446.3386]\n",
      " [2463.458 ]\n",
      " [2420.2642]\n",
      " [2420.8594]\n",
      " [2442.6243]\n",
      " [2426.6506]\n",
      " [2459.9534]\n",
      " [2467.0276]\n",
      " [2428.4407]\n",
      " [2450.7742]\n",
      " [2457.4902]\n",
      " [2439.644 ]\n",
      " [2471.725 ]\n",
      " [2426.88  ]\n",
      " [2459.87  ]\n",
      " [2460.637 ]\n",
      " [2432.7925]\n",
      " [2472.9773]\n",
      " [2467.0928]\n",
      " [2467.0117]\n",
      " [2476.4846]\n",
      " [2435.767 ]\n",
      " [2436.765 ]\n",
      " [2446.7834]\n",
      " [2465.8196]\n",
      " [2466.5864]\n",
      " [2461.4246]\n",
      " [2471.7715]\n",
      " [2449.7583]\n",
      " [2463.2092]\n",
      " [2473.5564]\n",
      " [2474.1514]\n",
      " [2474.7463]\n",
      " [2465.589 ]\n",
      " [2460.473 ]\n",
      " [2483.6865]\n",
      " [2444.6914]\n",
      " [2468.3523]\n",
      " [2441.6826]\n",
      " [2487.7888]\n",
      " [2479.5059]\n",
      " [2488.9785]\n",
      " [2458.0876]\n",
      " [2449.259 ]\n",
      " [2477.8906]\n",
      " [2483.1567]\n",
      " [2491.9534]\n",
      " [2492.5483]\n",
      " [2461.6575]\n",
      " [2475.1086]\n",
      " [2492.6108]\n",
      " [2481.8833]\n",
      " [2454.211 ]\n",
      " [2476.9521]\n",
      " [2472.372 ]\n",
      " [2451.7969]\n",
      " [2484.8582]\n",
      " [2489.0745]\n",
      " [2458.547 ]\n",
      " [2490.2644]\n",
      " [2487.41  ]\n",
      " [2499.1553]\n",
      " [2460.9268]\n",
      " [2477.7268]\n",
      " [2484.033 ]\n",
      " [2484.0916]\n",
      " [2503.8525]\n",
      " [2485.8176]\n",
      " [2486.4128]\n",
      " [2487.0076]\n",
      " [2497.3545]\n",
      " [2461.3872]\n",
      " [2461.9822]\n",
      " [2489.3875]\n",
      " [2495.7393]\n",
      " [2507.4846]\n",
      " [2469.256 ]\n",
      " [2469.085 ]\n",
      " [2502.1143]\n",
      " [2511.587 ]\n",
      " [2470.8696]\n",
      " [2467.2656]\n",
      " [2481.886 ]\n",
      " [2482.481 ]\n",
      " [2506.3599]\n",
      " [2502.1118]\n",
      " [2475.2058]\n",
      " [2470.9065]\n",
      " [2508.7397]\n",
      " [2498.3706]\n",
      " [2472.6912]\n",
      " [2517.004 ]\n",
      " [2478.0093]\n",
      " [2518.1938]\n",
      " [2479.6067]\n",
      " [2489.6204]\n",
      " [2490.2153]\n",
      " [2520.5737]\n",
      " [2477.38  ]\n",
      " [2510.4412]\n",
      " [2483.1765]\n",
      " [2516.474 ]\n",
      " [2500.93  ]\n",
      " [2480.355 ]\n",
      " [2524.7383]\n",
      " [2508.426 ]\n",
      " [2518.2273]\n",
      " [2515.3728]\n",
      " [2528.8406]\n",
      " [2505.0947]\n",
      " [2521.8289]\n",
      " [2521.2021]\n",
      " [2518.3477]\n",
      " [2486.3042]\n",
      " [2513.7805]\n",
      " [2492.4595]\n",
      " [2520.5554]\n",
      " [2515.5657]\n",
      " [2525.9126]\n",
      " [2516.2192]\n",
      " [2517.7336]\n",
      " [2523.7024]\n",
      " [2496.624 ]\n",
      " [2524.7202]\n",
      " [2519.194 ]\n",
      " [2519.789 ]\n",
      " [2494.1096]\n",
      " [2530.7214]\n",
      " [2531.8623]\n",
      " [2528.462 ]\n",
      " [2522.7637]\n",
      " [2523.8948]\n",
      " [2497.6794]\n",
      " [2525.468 ]\n",
      " [2535.432 ]\n",
      " [2499.4644]\n",
      " [2532.4546]\n",
      " [2527.4646]\n",
      " [2533.8164]\n",
      " [2537.8608]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2590.0825]\n",
      " [2559.725 ]\n",
      " [2587.9739]\n",
      " [2594.8066]\n",
      " [2577.714 ]\n",
      " [2596.581 ]\n",
      " [2601.077 ]\n",
      " [2563.2947]\n",
      " [2587.7798]\n",
      " [2598.961 ]\n",
      " [2581.284 ]\n",
      " [2600.5164]\n",
      " [2593.2373]\n",
      " [2593.8323]\n",
      " [2599.2964]\n",
      " [2568.0544]\n",
      " [2603.9224]\n",
      " [2596.2122]\n",
      " [2596.8071]\n",
      " [2590.5925]\n",
      " [2594.9192]\n",
      " [2595.5142]\n",
      " [2599.5107]\n",
      " [2577.0344]\n",
      " [2611.7861]\n",
      " [2578.2244]\n",
      " [2609.0752]\n",
      " [2595.3523]\n",
      " [2609.4788]\n",
      " [2592.5881]\n",
      " [2610.8704]\n",
      " [2604.8655]\n",
      " [2602.0586]\n",
      " [2614.0366]\n",
      " [2614.6313]\n",
      " [2574.3032]\n",
      " [2615.3904]\n",
      " [2612.096 ]\n",
      " [2594.6313]\n",
      " [2613.2856]\n",
      " [2585.0862]\n",
      " [2577.8728]\n",
      " [2617.8083]\n",
      " [2618.403 ]\n",
      " [2579.6577]\n",
      " [2620.233 ]\n",
      " [2620.828 ]\n",
      " [2620.9846]\n",
      " [2600.5808]\n",
      " [2619.2354]\n",
      " [2591.036 ]\n",
      " [2616.4407]\n",
      " [2624.9097]\n",
      " [2606.867 ]\n",
      " [2626.5303]\n",
      " [2612.011 ]\n",
      " [2619.4153]\n",
      " [2626.7327]\n",
      " [2606.5305]\n",
      " [2626.0693]\n",
      " [2629.3037]\n",
      " [2623.076 ]\n",
      " [2596.0173]\n",
      " [2600.8328]\n",
      " [2630.8972]\n",
      " [2610.695 ]\n",
      " [2618.5554]\n",
      " [2633.4683]\n",
      " [2599.587 ]\n",
      " [2635.024 ]\n",
      " [2631.7295]\n",
      " [2625.262 ]\n",
      " [2604.1248]\n",
      " [2633.5142]\n",
      " [2603.1567]\n",
      " [2603.7517]\n",
      " [2635.299 ]\n",
      " [2632.2334]\n",
      " [2644.2612]\n",
      " [2640.608 ]\n",
      " [2630.6165]\n",
      " [2607.3215]\n",
      " [2635.2083]\n",
      " [2612.7317]\n",
      " [2613.327 ]\n",
      " [2611.8591]\n",
      " [2644.7725]\n",
      " [2642.728 ]\n",
      " [2627.6904]\n",
      " [2647.354 ]\n",
      " [2651.4006]\n",
      " [2617.4915]\n",
      " [2641.5198]\n",
      " [2614.461 ]\n",
      " [2650.3286]\n",
      " [2639.5408]\n",
      " [2651.5186]\n",
      " [2644.4944]\n",
      " [2619.5935]\n",
      " [2622.2512]\n",
      " [2657.35  ]\n",
      " [2623.4412]\n",
      " [2653.7073]\n",
      " [2636.6147]\n",
      " [2625.2258]\n",
      " [2652.553 ]\n",
      " [2656.5251]\n",
      " [2657.2666]\n",
      " [2655.2222]\n",
      " [2658.4565]\n",
      " [2651.543 ]\n",
      " [2663.5474]\n",
      " [2645.9236]\n",
      " [2653.6519]\n",
      " [2643.1592]\n",
      " [2654.5178]\n",
      " [2630.303 ]\n",
      " [2632.9602]\n",
      " [2664.6074]\n",
      " [2653.8196]\n",
      " [2665.3665]\n",
      " [2635.34  ]\n",
      " [2666.191 ]\n",
      " [2667.582 ]\n",
      " [2627.2542]\n",
      " [2653.658 ]\n",
      " [2650.2986]\n",
      " [2636.8474]\n",
      " [2662.5762]\n",
      " [2667.7163]\n",
      " [2674.8516]\n",
      " [2653.2734]\n",
      " [2657.8225]\n",
      " [2665.551 ]\n",
      " [2673.3306]\n",
      " [2673.779 ]\n",
      " [2674.8857]\n",
      " [2679.3635]\n",
      " [2675.7104]\n",
      " [2676.1587]\n",
      " [2674.2607]\n",
      " [2673.9714]\n",
      " [2663.7722]\n",
      " [2638.5583]\n",
      " [2639.153 ]\n",
      " [2684.123 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2442.4324]\n",
      " [2449.5225]\n",
      " [2471.9536]\n",
      " [2452.2407]\n",
      " [2442.7104]\n",
      " [2442.0159]\n",
      " [2474.2732]\n",
      " [2474.8682]\n",
      " [2475.5608]\n",
      " [2479.0264]\n",
      " [2473.85  ]\n",
      " [2450.6296]\n",
      " [2480.0024]\n",
      " [2482.286 ]\n",
      " [2468.9097]\n",
      " [2482.6104]\n",
      " [2483.913 ]\n",
      " [2457.6982]\n",
      " [2459.1206]\n",
      " [2488.6846]\n",
      " [2481.551 ]\n",
      " [2458.988 ]\n",
      " [2466.0232]\n",
      " [2484.4763]\n",
      " [2459.5933]\n",
      " [2481.5247]\n",
      " [2482.0627]\n",
      " [2456.3992]\n",
      " [2459.104 ]\n",
      " [2482.8098]\n",
      " [2487.2231]\n",
      " [2467.403 ]\n",
      " [2484.963 ]\n",
      " [2495.0806]\n",
      " [2466.7224]\n",
      " [2459.8645]\n",
      " [2489.2632]\n",
      " [2494.4636]\n",
      " [2490.9417]\n",
      " [2469.921 ]\n",
      " [2471.9255]\n",
      " [2498.9343]\n",
      " [2473.4   ]\n",
      " [2475.617 ]\n",
      " [2500.6348]\n",
      " [2494.0308]\n",
      " [2467.453 ]\n",
      " [2500.8257]\n",
      " [2502.244 ]\n",
      " [2478.0605]\n",
      " [2502.0176]\n",
      " [2478.2222]\n",
      " [2497.8428]\n",
      " [2470.5737]\n",
      " [2499.832 ]\n",
      " [2479.323 ]\n",
      " [2471.1304]\n",
      " [2503.2866]\n",
      " [2508.705 ]\n",
      " [2509.6538]\n",
      " [2502.823 ]\n",
      " [2482.8423]\n",
      " [2485.2988]\n",
      " [2499.8481]\n",
      " [2512.1562]\n",
      " [2512.1575]\n",
      " [2492.2012]\n",
      " [2483.2986]\n",
      " [2503.6582]\n",
      " [2509.4082]\n",
      " [2489.7742]\n",
      " [2500.1624]\n",
      " [2489.54  ]\n",
      " [2482.7632]\n",
      " [2481.8396]\n",
      " [2510.8887]\n",
      " [2505.7969]\n",
      " [2521.9258]\n",
      " [2519.6797]\n",
      " [2520.2634]\n",
      " [2497.817 ]\n",
      " [2516.748 ]\n",
      " [2521.681 ]\n",
      " [2517.086 ]\n",
      " [2489.4304]\n",
      " [2499.479 ]\n",
      " [2506.318 ]\n",
      " [2520.173 ]\n",
      " [2492.6914]\n",
      " [2527.1538]\n",
      " [2524.5732]\n",
      " [2515.475 ]\n",
      " [2523.5361]\n",
      " [2510.483 ]\n",
      " [2517.26  ]\n",
      " [2532.2048]\n",
      " [2531.7253]\n",
      " [2502.2283]\n",
      " [2504.8794]\n",
      " [2498.3547]\n",
      " [2534.902 ]\n",
      " [2525.1653]\n",
      " [2527.3362]\n",
      " [2506.5947]\n",
      " [2534.6191]\n",
      " [2530.6143]\n",
      " [2525.4312]\n",
      " [2534.322 ]\n",
      " [2504.5857]\n",
      " [2532.6948]\n",
      " [2513.857 ]\n",
      " [2538.9346]\n",
      " [2539.2966]\n",
      " [2539.1968]\n",
      " [2505.778 ]\n",
      " [2530.7227]\n",
      " [2530.677 ]\n",
      " [2539.461 ]\n",
      " [2538.561 ]\n",
      " [2544.4712]\n",
      " [2517.6436]\n",
      " [2541.299 ]\n",
      " [2531.0024]\n",
      " [2512.8423]\n",
      " [2548.2793]\n",
      " [2537.1084]\n",
      " [2540.8884]\n",
      " [2542.6853]\n",
      " [2526.9983]\n",
      " [2547.175 ]\n",
      " [2527.0566]\n",
      " [2550.6008]\n",
      " [2524.7195]\n",
      " [2548.8264]\n",
      " [2550.1497]\n",
      " [2529.2468]\n",
      " [2544.6758]\n",
      " [2551.232 ]\n",
      " [2556.645 ]\n",
      " [2553.105 ]\n",
      " [2548.3684]\n",
      " [2558.673 ]\n",
      " [2559.2578]\n",
      " [2534.661 ]\n",
      " [2552.7996]\n",
      " [2557.893 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2502.4058]\n",
      " [2502.8079]\n",
      " [2552.119 ]\n",
      " [2506.3044]\n",
      " [2498.7788]\n",
      " [2495.4932]\n",
      " [2505.9756]\n",
      " [2555.0938]\n",
      " [2591.8416]\n",
      " [2510.002 ]\n",
      " [2504.9187]\n",
      " [2508.9502]\n",
      " [2510.732 ]\n",
      " [2499.075 ]\n",
      " [2500.9028]\n",
      " [2505.9666]\n",
      " [2601.232 ]\n",
      " [2514.6338]\n",
      " [2515.383 ]\n",
      " [2503.0808]\n",
      " [2508.9414]\n",
      " [2504.1282]\n",
      " [2517.032 ]\n",
      " [2518.3577]\n",
      " [2512.9075]\n",
      " [2518.394 ]\n",
      " [2607.1812]\n",
      " [2614.1162]\n",
      " [2515.2874]\n",
      " [2612.1934]\n",
      " [2588.6099]\n",
      " [2593.6914]\n",
      " [2610.751 ]\n",
      " [2616.398 ]\n",
      " [2510.8232]\n",
      " [2591.5847]\n",
      " [2512.759 ]\n",
      " [2526.6606]\n",
      " [2515.0486]\n",
      " [2619.9678]\n",
      " [2618.7378]\n",
      " [2619.3328]\n",
      " [2528.5806]\n",
      " [2524.552 ]\n",
      " [2613.26  ]\n",
      " [2531.2927]\n",
      " [2519.1448]\n",
      " [2525.6138]\n",
      " [2520.662 ]\n",
      " [2521.257 ]\n",
      " [2627.8   ]\n",
      " [2522.9163]\n",
      " [2523.5908]\n",
      " [2582.4617]\n",
      " [2530.7563]\n",
      " [2533.6006]\n",
      " [2524.9453]\n",
      " [2526.0166]\n",
      " [2533.4734]\n",
      " [2527.7554]\n",
      " [2527.3313]\n",
      " [2574.492 ]\n",
      " [2534.0674]\n",
      " [2540.41  ]\n",
      " [2542.7246]\n",
      " [2530.0127]\n",
      " [2637.3193]\n",
      " [2540.74  ]\n",
      " [2533.0305]\n",
      " [2541.93  ]\n",
      " [2564.856 ]\n",
      " [2534.895 ]\n",
      " [2539.2358]\n",
      " [2536.0847]\n",
      " [2547.9695]\n",
      " [2548.1418]\n",
      " [2544.1826]\n",
      " [2549.7544]\n",
      " [2538.925 ]\n",
      " [2622.2495]\n",
      " [2540.115 ]\n",
      " [2552.8389]\n",
      " [2547.415 ]\n",
      " [2541.158 ]\n",
      " [2630.5212]\n",
      " [2543.0898]\n",
      " [2549.795 ]\n",
      " [2544.2795]\n",
      " [2644.0684]\n",
      " [2545.5247]\n",
      " [2551.1968]\n",
      " [2605.07  ]\n",
      " [2605.665 ]\n",
      " [2560.0046]\n",
      " [2553.106 ]\n",
      " [2559.4485]\n",
      " [2561.7898]\n",
      " [2548.3057]\n",
      " [2559.1836]\n",
      " [2650.6128]\n",
      " [2597.695 ]\n",
      " [2551.7183]\n",
      " [2583.8945]\n",
      " [2559.9092]\n",
      " [2564.3242]\n",
      " [2657.41  ]\n",
      " [2555.7183]\n",
      " [2568.18  ]\n",
      " [2561.9062]\n",
      " [2567.2559]\n",
      " [2557.8855]\n",
      " [2570.7827]\n",
      " [2570.2275]\n",
      " [2566.199 ]\n",
      " [2559.4526]\n",
      " [2591.629 ]\n",
      " [2607.2144]\n",
      " [2573.1301]\n",
      " [2593.414 ]\n",
      " [2646.0479]\n",
      " [2563.0286]\n",
      " [2622.9187]\n",
      " [2659.6667]\n",
      " [2570.3596]\n",
      " [2575.9873]\n",
      " [2576.818 ]\n",
      " [2577.1772]\n",
      " [2580.079 ]\n",
      " [2672.9185]\n",
      " [2579.198 ]\n",
      " [2574.995 ]\n",
      " [2581.4595]\n",
      " [2580.747 ]\n",
      " [2571.5696]\n",
      " [2654.9722]\n",
      " [2577.9697]\n",
      " [2604.123 ]\n",
      " [2586.1829]\n",
      " [2573.7378]\n",
      " [2585.1475]\n",
      " [2582.263 ]\n",
      " [2586.1016]\n",
      " [2676.1958]\n",
      " [2577.7317]\n",
      " [2582.0728]\n",
      " [2583.3108]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2691.4136]\n",
      " [2692.5024]\n",
      " [2696.8037]\n",
      " [2632.8926]\n",
      " [2693.985 ]\n",
      " [2640.5908]\n",
      " [2698.399 ]\n",
      " [2699.8828]\n",
      " [2662.1912]\n",
      " [2649.6206]\n",
      " [2651.7358]\n",
      " [2692.8745]\n",
      " [2702.9382]\n",
      " [2690.5527]\n",
      " [2701.8962]\n",
      " [2695.2542]\n",
      " [2667.294 ]\n",
      " [2682.072 ]\n",
      " [2678.1785]\n",
      " [2664.619 ]\n",
      " [2706.7283]\n",
      " [2697.2334]\n",
      " [2708.8071]\n",
      " [2644.5022]\n",
      " [2697.517 ]\n",
      " [2706.3071]\n",
      " [2706.7961]\n",
      " [2702.3938]\n",
      " [2712.1572]\n",
      " [2676.756 ]\n",
      " [2675.2803]\n",
      " [2649.3013]\n",
      " [2663.3044]\n",
      " [2702.8718]\n",
      " [2696.0098]\n",
      " [2713.4448]\n",
      " [2666.5396]\n",
      " [2717.7556]\n",
      " [2708.9382]\n",
      " [2718.9214]\n",
      " [2710.1282]\n",
      " [2720.192 ]\n",
      " [2666.663 ]\n",
      " [2698.0237]\n",
      " [2667.744 ]\n",
      " [2661.4575]\n",
      " [2715.9092]\n",
      " [2716.5042]\n",
      " [2674.3438]\n",
      " [2724.871 ]\n",
      " [2725.49  ]\n",
      " [2684.8496]\n",
      " [2690.4402]\n",
      " [2666.2173]\n",
      " [2673.693 ]\n",
      " [2726.101 ]\n",
      " [2674.883 ]\n",
      " [2679.0337]\n",
      " [2726.1128]\n",
      " [2692.534 ]\n",
      " [2731.4395]\n",
      " [2694.067 ]\n",
      " [2732.6294]\n",
      " [2683.268 ]\n",
      " [2686.0806]\n",
      " [2733.3945]\n",
      " [2718.224 ]\n",
      " [2731.1895]\n",
      " [2728.998 ]\n",
      " [2694.3667]\n",
      " [2730.188 ]\n",
      " [2737.96  ]\n",
      " [2736.2153]\n",
      " [2731.973 ]\n",
      " [2740.0986]\n",
      " [2737.2432]\n",
      " [2684.6523]\n",
      " [2699.1262]\n",
      " [2688.0815]\n",
      " [2739.3486]\n",
      " [2681.3555]\n",
      " [2702.6982]\n",
      " [2702.101 ]\n",
      " [2680.1995]\n",
      " [2703.291 ]\n",
      " [2703.886 ]\n",
      " [2696.9521]\n",
      " [2685.52  ]\n",
      " [2696.622 ]\n",
      " [2725.3916]\n",
      " [2713.7097]\n",
      " [2738.8804]\n",
      " [2689.2197]\n",
      " [2701.1172]\n",
      " [2751.668 ]\n",
      " [2690.2798]\n",
      " [2728.2832]\n",
      " [2749.038 ]\n",
      " [2697.7417]\n",
      " [2754.399 ]\n",
      " [2753.0625]\n",
      " [2746.4204]\n",
      " [2713.2114]\n",
      " [2700.7163]\n",
      " [2703.5508]\n",
      " [2707.5916]\n",
      " [2742.0222]\n",
      " [2707.9263]\n",
      " [2703.691 ]\n",
      " [2695.6682]\n",
      " [2761.244 ]\n",
      " [2752.3699]\n",
      " [2762.2485]\n",
      " [2763.0288]\n",
      " [2752.7817]\n",
      " [2760.3987]\n",
      " [2717.018 ]\n",
      " [2707.226 ]\n",
      " [2762.552 ]\n",
      " [2762.233 ]\n",
      " [2766.2239]\n",
      " [2765.324 ]\n",
      " [2758.9146]\n",
      " [2764.785 ]\n",
      " [2733.9382]\n",
      " [2770.0874]\n",
      " [2727.4902]\n",
      " [2706.417 ]\n",
      " [2770.6162]\n",
      " [2770.128 ]\n",
      " [2770.7227]\n",
      " [2774.2944]\n",
      " [2716.1504]\n",
      " [2729.3342]\n",
      " [2751.682 ]\n",
      " [2772.2976]\n",
      " [2722.5894]\n",
      " [2777.3076]\n",
      " [2775.4382]\n",
      " [2778.1973]\n",
      " [2768.0332]\n",
      " [2741.6633]\n",
      " [2767.302 ]\n",
      " [2735.284 ]\n",
      " [2738.9883]\n",
      " [2725.7046]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2521.9463]\n",
      " [2522.5764]\n",
      " [2523.2227]\n",
      " [2522.6965]\n",
      " [2561.1487]\n",
      " [2523.3877]\n",
      " [2515.9172]\n",
      " [2526.093 ]\n",
      " [2525.269 ]\n",
      " [2526.9722]\n",
      " [2512.8594]\n",
      " [2527.165 ]\n",
      " [2549.962 ]\n",
      " [2528.1475]\n",
      " [2529.3628]\n",
      " [2530.3896]\n",
      " [2513.2249]\n",
      " [2530.8225]\n",
      " [2531.611 ]\n",
      " [2533.2502]\n",
      " [2533.9165]\n",
      " [2523.0918]\n",
      " [2519.0483]\n",
      " [2529.3276]\n",
      " [2535.592 ]\n",
      " [2524.6116]\n",
      " [2535.627 ]\n",
      " [2516.9272]\n",
      " [2538.2417]\n",
      " [2523.369 ]\n",
      " [2539.2275]\n",
      " [2539.6836]\n",
      " [2539.9058]\n",
      " [2540.6895]\n",
      " [2540.3613]\n",
      " [2541.867 ]\n",
      " [2533.7659]\n",
      " [2543.9807]\n",
      " [2543.664 ]\n",
      " [2537.3494]\n",
      " [2535.5115]\n",
      " [2545.2761]\n",
      " [2539.4912]\n",
      " [2547.601 ]\n",
      " [2547.881 ]\n",
      " [2547.2827]\n",
      " [2588.804 ]\n",
      " [2548.856 ]\n",
      " [2549.4146]\n",
      " [2549.2676]\n",
      " [2545.7903]\n",
      " [2550.8818]\n",
      " [2539.4421]\n",
      " [2603.086 ]\n",
      " [2547.8625]\n",
      " [2547.051 ]\n",
      " [2553.887 ]\n",
      " [2555.9307]\n",
      " [2570.2048]\n",
      " [2534.1628]\n",
      " [2557.0168]\n",
      " [2549.087 ]\n",
      " [2557.3003]\n",
      " [2558.4502]\n",
      " [2560.1008]\n",
      " [2560.6396]\n",
      " [2560.3325]\n",
      " [2560.4827]\n",
      " [2553.2517]\n",
      " [2562.6697]\n",
      " [2547.6064]\n",
      " [2595.265 ]\n",
      " [2564.502 ]\n",
      " [2564.9983]\n",
      " [2565.318 ]\n",
      " [2618.3367]\n",
      " [2565.6294]\n",
      " [2567.1904]\n",
      " [2559.997 ]\n",
      " [2569.2695]\n",
      " [2562.0996]\n",
      " [2569.0535]\n",
      " [2547.8467]\n",
      " [2571.179 ]\n",
      " [2571.974 ]\n",
      " [2561.5525]\n",
      " [2568.1636]\n",
      " [2573.6482]\n",
      " [2573.7659]\n",
      " [2574.9019]\n",
      " [2574.403 ]\n",
      " [2589.8384]\n",
      " [2575.644 ]\n",
      " [2629.0461]\n",
      " [2564.952 ]\n",
      " [2577.0823]\n",
      " [2578.7322]\n",
      " [2579.4329]\n",
      " [2563.2307]\n",
      " [2580.8467]\n",
      " [2581.0986]\n",
      " [2582.0647]\n",
      " [2581.1929]\n",
      " [2570.4453]\n",
      " [2577.5005]\n",
      " [2583.1885]\n",
      " [2574.5515]\n",
      " [2579.703 ]\n",
      " [2586.5977]\n",
      " [2586.6938]\n",
      " [2587.4126]\n",
      " [2586.579 ]\n",
      " [2587.5188]\n",
      " [2588.9329]\n",
      " [2588.3752]\n",
      " [2588.9727]\n",
      " [2590.5813]\n",
      " [2591.084 ]\n",
      " [2578.7092]\n",
      " [2591.5474]\n",
      " [2591.5095]\n",
      " [2594.335 ]\n",
      " [2592.9197]\n",
      " [2594.0632]\n",
      " [2595.237 ]\n",
      " [2596.3308]\n",
      " [2591.1257]\n",
      " [2597.59  ]\n",
      " [2597.2964]\n",
      " [2597.8186]\n",
      " [2598.804 ]\n",
      " [2599.7686]\n",
      " [2598.689 ]\n",
      " [2601.2888]\n",
      " [2599.7747]\n",
      " [2601.181 ]\n",
      " [2602.3555]\n",
      " [2602.1296]\n",
      " [2603.2441]\n",
      " [2603.5535]\n",
      " [2604.3633]\n",
      " [2605.2607]\n",
      " [2605.2766]\n",
      " [2606.8833]\n",
      " [2607.4854]\n",
      " [2606.44  ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2553.2058]\n",
      " [2547.7847]\n",
      " [2552.203 ]\n",
      " [2554.9907]\n",
      " [2571.5154]\n",
      " [2542.255 ]\n",
      " [2547.676 ]\n",
      " [2527.5222]\n",
      " [2570.5547]\n",
      " [2573.3354]\n",
      " [2575.0852]\n",
      " [2572.2366]\n",
      " [2546.4197]\n",
      " [2571.929 ]\n",
      " [2572.524 ]\n",
      " [2548.2043]\n",
      " [2578.3655]\n",
      " [2566.1191]\n",
      " [2567.3723]\n",
      " [2568.219 ]\n",
      " [2568.262 ]\n",
      " [2574.864 ]\n",
      " [2581.1243]\n",
      " [2579.0217]\n",
      " [2558.3853]\n",
      " [2580.2048]\n",
      " [2573.8313]\n",
      " [2576.6782]\n",
      " [2560.7651]\n",
      " [2545.2915]\n",
      " [2585.8838]\n",
      " [2574.8064]\n",
      " [2584.7305]\n",
      " [2581.2212]\n",
      " [2552.0105]\n",
      " [2579.0474]\n",
      " [2591.1953]\n",
      " [2590.8596]\n",
      " [2555.2485]\n",
      " [2584.791 ]\n",
      " [2589.1292]\n",
      " [2589.731 ]\n",
      " [2578.1938]\n",
      " [2583.8071]\n",
      " [2591.5156]\n",
      " [2592.1106]\n",
      " [2560.0083]\n",
      " [2593.758 ]\n",
      " [2593.8955]\n",
      " [2544.686 ]\n",
      " [2562.388 ]\n",
      " [2600.3667]\n",
      " [2562.7197]\n",
      " [2601.5566]\n",
      " [2600.9739]\n",
      " [2589.3857]\n",
      " [2594.9053]\n",
      " [2590.5757]\n",
      " [2585.5205]\n",
      " [2600.44  ]\n",
      " [2601.035 ]\n",
      " [2592.297 ]\n",
      " [2577.298 ]\n",
      " [2553.0151]\n",
      " [2569.8591]\n",
      " [2595.3354]\n",
      " [2592.473 ]\n",
      " [2590.875 ]\n",
      " [2591.47  ]\n",
      " [2569.0894]\n",
      " [2599.8708]\n",
      " [2586.3481]\n",
      " [2590.8066]\n",
      " [2600.095 ]\n",
      " [2614.3958]\n",
      " [2572.6592]\n",
      " [2611.0117]\n",
      " [2607.3994]\n",
      " [2604.769 ]\n",
      " [2603.3643]\n",
      " [2605.8206]\n",
      " [2613.529 ]\n",
      " [2596.7563]\n",
      " [2614.719 ]\n",
      " [2612.3462]\n",
      " [2606.5762]\n",
      " [2579.2036]\n",
      " [2608.124 ]\n",
      " [2618.1514]\n",
      " [2603.964 ]\n",
      " [2609.909 ]\n",
      " [2573.1602]\n",
      " [2623.8716]\n",
      " [2612.2458]\n",
      " [2623.9067]\n",
      " [2618.1084]\n",
      " [2614.0305]\n",
      " [2604.9004]\n",
      " [2628.3296]\n",
      " [2626.9358]\n",
      " [2627.5308]\n",
      " [2628.0713]\n",
      " [2626.4807]\n",
      " [2608.4702]\n",
      " [2631.8992]\n",
      " [2628.2656]\n",
      " [2621.4277]\n",
      " [2628.9978]\n",
      " [2630.0505]\n",
      " [2623.0742]\n",
      " [2593.483 ]\n",
      " [2597.8223]\n",
      " [2637.004 ]\n",
      " [2623.5928]\n",
      " [2636.8013]\n",
      " [2626.7822]\n",
      " [2638.7917]\n",
      " [2639.6338]\n",
      " [2640.2288]\n",
      " [2627.7144]\n",
      " [2632.0093]\n",
      " [2637.3206]\n",
      " [2630.8086]\n",
      " [2642.1558]\n",
      " [2621.7444]\n",
      " [2635.957 ]\n",
      " [2630.9692]\n",
      " [2615.9702]\n",
      " [2634.5168]\n",
      " [2645.5952]\n",
      " [2641.5388]\n",
      " [2638.5537]\n",
      " [2648.903 ]\n",
      " [2648.1055]\n",
      " [2598.7432]\n",
      " [2637.234 ]\n",
      " [2650.0496]\n",
      " [2604.8665]\n",
      " [2621.384 ]\n",
      " [2652.4756]\n",
      " [2641.5178]\n",
      " [2649.2195]\n",
      " [2645.0981]\n",
      " [2624.3586]\n",
      " [2646.288 ]\n",
      " [2609.6262]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2470.905 ]\n",
      " [2473.4624]\n",
      " [2474.8574]\n",
      " [2473.6743]\n",
      " [2476.0474]\n",
      " [2474.377 ]\n",
      " [2477.2373]\n",
      " [2476.5166]\n",
      " [2477.9204]\n",
      " [2485.058 ]\n",
      " [2478.1528]\n",
      " [2481.6743]\n",
      " [2478.2092]\n",
      " [2487.438 ]\n",
      " [2481.472 ]\n",
      " [2481.9597]\n",
      " [2480.9497]\n",
      " [2482.7778]\n",
      " [2483.624 ]\n",
      " [2483.5964]\n",
      " [2484.4314]\n",
      " [2485.2583]\n",
      " [2485.9807]\n",
      " [2486.5854]\n",
      " [2487.2473]\n",
      " [2488.0347]\n",
      " [2488.3835]\n",
      " [2489.2686]\n",
      " [2493.3188]\n",
      " [2496.9573]\n",
      " [2491.8142]\n",
      " [2489.2988]\n",
      " [2490.0583]\n",
      " [2490.6003]\n",
      " [2492.621 ]\n",
      " [2492.1367]\n",
      " [2495.043 ]\n",
      " [2501.0188]\n",
      " [2500.8486]\n",
      " [2496.0586]\n",
      " [2494.8923]\n",
      " [2495.9084]\n",
      " [2498.149 ]\n",
      " [2498.4822]\n",
      " [2501.9949]\n",
      " [2500.2178]\n",
      " [2500.1985]\n",
      " [2506.2031]\n",
      " [2501.3862]\n",
      " [2502.0542]\n",
      " [2501.5818]\n",
      " [2505.4727]\n",
      " [2503.5732]\n",
      " [2502.8604]\n",
      " [2504.2456]\n",
      " [2504.0273]\n",
      " [2508.4478]\n",
      " [2506.5874]\n",
      " [2506.7437]\n",
      " [2507.286 ]\n",
      " [2508.601 ]\n",
      " [2507.62  ]\n",
      " [2509.7537]\n",
      " [2510.9758]\n",
      " [2510.8413]\n",
      " [2513.8022]\n",
      " [2510.4062]\n",
      " [2511.8474]\n",
      " [2511.7063]\n",
      " [2512.454 ]\n",
      " [2512.7861]\n",
      " [2513.4407]\n",
      " [2515.129 ]\n",
      " [2514.526 ]\n",
      " [2516.5562]\n",
      " [2516.3423]\n",
      " [2517.8523]\n",
      " [2518.4106]\n",
      " [2517.4238]\n",
      " [2519.8271]\n",
      " [2520.488 ]\n",
      " [2518.965 ]\n",
      " [2519.775 ]\n",
      " [2520.3481]\n",
      " [2522.041 ]\n",
      " [2521.7703]\n",
      " [2522.236 ]\n",
      " [2524.4375]\n",
      " [2524.955 ]\n",
      " [2524.9365]\n",
      " [2526.4497]\n",
      " [2527.4595]\n",
      " [2525.7556]\n",
      " [2526.2017]\n",
      " [2527.3562]\n",
      " [2529.3872]\n",
      " [2530.1653]\n",
      " [2530.3872]\n",
      " [2533.4355]\n",
      " [2530.79  ]\n",
      " [2530.6946]\n",
      " [2534.1782]\n",
      " [2532.9072]\n",
      " [2534.2085]\n",
      " [2535.0361]\n",
      " [2536.4358]\n",
      " [2534.3647]\n",
      " [2534.8909]\n",
      " [2535.029 ]\n",
      " [2537.5266]\n",
      " [2538.1646]\n",
      " [2539.11  ]\n",
      " [2537.7048]\n",
      " [2538.1196]\n",
      " [2538.8135]\n",
      " [2543.1436]\n",
      " [2542.5083]\n",
      " [2541.8872]\n",
      " [2542.3005]\n",
      " [2543.7988]\n",
      " [2543.2288]\n",
      " [2544.9365]\n",
      " [2545.1167]\n",
      " [2547.9033]\n",
      " [2546.5012]\n",
      " [2546.0305]\n",
      " [2547.6838]\n",
      " [2547.8333]\n",
      " [2546.928 ]\n",
      " [2547.5232]\n",
      " [2548.5747]\n",
      " [2548.7239]\n",
      " [2550.8264]\n",
      " [2551.6013]\n",
      " [2552.7593]\n",
      " [2553.389 ]\n",
      " [2553.7444]\n",
      " [2554.9539]\n",
      " [2555.0723]\n",
      " [2555.54  ]\n",
      " [2560.7925]\n",
      " [2558.4045]\n",
      " [2557.791 ]\n",
      " [2557.3005]\n",
      " [2556.8403]\n",
      " [2557.2861]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2500.0537]\n",
      " [2479.4624]\n",
      " [2501.606 ]\n",
      " [2477.7559]\n",
      " [2491.8547]\n",
      " [2495.9963]\n",
      " [2500.7136]\n",
      " [2504.0369]\n",
      " [2505.8535]\n",
      " [2494.4438]\n",
      " [2495.4246]\n",
      " [2503.54  ]\n",
      " [2508.513 ]\n",
      " [2508.1504]\n",
      " [2502.1587]\n",
      " [2506.0684]\n",
      " [2485.4902]\n",
      " [2510.6516]\n",
      " [2502.016 ]\n",
      " [2500.3933]\n",
      " [2510.6946]\n",
      " [2509.4893]\n",
      " [2502.1782]\n",
      " [2506.7053]\n",
      " [2514.151 ]\n",
      " [2507.768 ]\n",
      " [2506.7756]\n",
      " [2513.8882]\n",
      " [2509.553 ]\n",
      " [2511.169 ]\n",
      " [2505.63  ]\n",
      " [2511.465 ]\n",
      " [2520.1326]\n",
      " [2525.6184]\n",
      " [2526.2134]\n",
      " [2514.7388]\n",
      " [2498.9163]\n",
      " [2497.8018]\n",
      " [2521.6   ]\n",
      " [2528.5034]\n",
      " [2522.5938]\n",
      " [2524.3518]\n",
      " [2507.7761]\n",
      " [2515.058 ]\n",
      " [2526.1367]\n",
      " [2518.0798]\n",
      " [2526.3596]\n",
      " [2533.2632]\n",
      " [2534.5427]\n",
      " [2529.5688]\n",
      " [2528.697 ]\n",
      " [2527.4868]\n",
      " [2529.887 ]\n",
      " [2522.8394]\n",
      " [2514.9158]\n",
      " [2538.0203]\n",
      " [2534.691 ]\n",
      " [2511.4102]\n",
      " [2534.466 ]\n",
      " [2512.6   ]\n",
      " [2529.5266]\n",
      " [2536.8296]\n",
      " [2542.1875]\n",
      " [2537.8982]\n",
      " [2531.9924]\n",
      " [2517.5398]\n",
      " [2515.238 ]\n",
      " [2540.956 ]\n",
      " [2536.5356]\n",
      " [2540.0437]\n",
      " [2540.2344]\n",
      " [2540.0664]\n",
      " [2538.9153]\n",
      " [2539.5103]\n",
      " [2519.9976]\n",
      " [2545.0378]\n",
      " [2534.6917]\n",
      " [2545.6836]\n",
      " [2525.2742]\n",
      " [2524.4993]\n",
      " [2525.0942]\n",
      " [2541.213 ]\n",
      " [2531.682 ]\n",
      " [2526.8792]\n",
      " [2543.8057]\n",
      " [2547.5664]\n",
      " [2551.0383]\n",
      " [2556.0684]\n",
      " [2550.9436]\n",
      " [2549.0295]\n",
      " [2531.0437]\n",
      " [2554.013 ]\n",
      " [2555.83  ]\n",
      " [2559.6382]\n",
      " [2554.875 ]\n",
      " [2535.3884]\n",
      " [2539.9038]\n",
      " [2535.2085]\n",
      " [2551.3271]\n",
      " [2556.454 ]\n",
      " [2558.4448]\n",
      " [2559.9626]\n",
      " [2560.6443]\n",
      " [2560.2297]\n",
      " [2544.7708]\n",
      " [2562.8865]\n",
      " [2564.4387]\n",
      " [2556.5544]\n",
      " [2543.1228]\n",
      " [2563.7993]\n",
      " [2553.2266]\n",
      " [2572.025 ]\n",
      " [2549.423 ]\n",
      " [2568.324 ]\n",
      " [2559.1318]\n",
      " [2574.4048]\n",
      " [2570.3882]\n",
      " [2558.699 ]\n",
      " [2567.7583]\n",
      " [2568.353 ]\n",
      " [2550.262 ]\n",
      " [2549.4873]\n",
      " [2573.6787]\n",
      " [2566.0737]\n",
      " [2575.148 ]\n",
      " [2550.3403]\n",
      " [2567.8586]\n",
      " [2558.3474]\n",
      " [2567.4612]\n",
      " [2555.617 ]\n",
      " [2574.4883]\n",
      " [2575.0833]\n",
      " [2576.0876]\n",
      " [2566.9106]\n",
      " [2572.7456]\n",
      " [2579.1145]\n",
      " [2574.7434]\n",
      " [2578.653 ]\n",
      " [2576.019 ]\n",
      " [2582.6575]\n",
      " [2576.188 ]\n",
      " [2579.9673]\n",
      " [2582.308 ]\n",
      " [2586.4521]\n",
      " [2573.455 ]\n",
      " [2585.064 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2535.0186]\n",
      " [2523.1929]\n",
      " [2536.8914]\n",
      " [2530.4558]\n",
      " [2528.3894]\n",
      " [2525.0352]\n",
      " [2526.5   ]\n",
      " [2537.4746]\n",
      " [2540.7778]\n",
      " [2531.622 ]\n",
      " [2541.0164]\n",
      " [2528.7837]\n",
      " [2528.9883]\n",
      " [2529.7434]\n",
      " [2532.1738]\n",
      " [2530.24  ]\n",
      " [2546.2783]\n",
      " [2531.8848]\n",
      " [2548.1438]\n",
      " [2539.892 ]\n",
      " [2533.5288]\n",
      " [2536.0066]\n",
      " [2550.363 ]\n",
      " [2553.856 ]\n",
      " [2550.0002]\n",
      " [2543.545 ]\n",
      " [2556.3276]\n",
      " [2550.8206]\n",
      " [2553.8984]\n",
      " [2550.5637]\n",
      " [2539.2415]\n",
      " [2540.5117]\n",
      " [2541.6077]\n",
      " [2563.3777]\n",
      " [2549.1074]\n",
      " [2544.034 ]\n",
      " [2558.0117]\n",
      " [2544.9565]\n",
      " [2563.976 ]\n",
      " [2558.692 ]\n",
      " [2547.0085]\n",
      " [2567.3445]\n",
      " [2547.1172]\n",
      " [2562.1763]\n",
      " [2547.9487]\n",
      " [2549.342 ]\n",
      " [2565.576 ]\n",
      " [2565.8892]\n",
      " [2565.832 ]\n",
      " [2552.9973]\n",
      " [2552.352 ]\n",
      " [2559.0137]\n",
      " [2566.0046]\n",
      " [2555.5557]\n",
      " [2558.7197]\n",
      " [2561.312 ]\n",
      " [2570.1816]\n",
      " [2562.3584]\n",
      " [2557.979 ]\n",
      " [2556.9512]\n",
      " [2559.153 ]\n",
      " [2573.196 ]\n",
      " [2579.9758]\n",
      " [2564.0747]\n",
      " [2564.6694]\n",
      " [2560.8252]\n",
      " [2576.1282]\n",
      " [2563.3335]\n",
      " [2562.9229]\n",
      " [2563.6306]\n",
      " [2565.1184]\n",
      " [2564.954 ]\n",
      " [2569.901 ]\n",
      " [2565.5713]\n",
      " [2567.466 ]\n",
      " [2582.371 ]\n",
      " [2567.4558]\n",
      " [2576.9375]\n",
      " [2572.7163]\n",
      " [2569.5928]\n",
      " [2570.5269]\n",
      " [2576.601 ]\n",
      " [2571.589 ]\n",
      " [2579.6904]\n",
      " [2572.098 ]\n",
      " [2579.1055]\n",
      " [2574.6787]\n",
      " [2575.1963]\n",
      " [2587.4229]\n",
      " [2575.3052]\n",
      " [2577.0786]\n",
      " [2576.8347]\n",
      " [2577.673 ]\n",
      " [2577.935 ]\n",
      " [2596.7327]\n",
      " [2578.868 ]\n",
      " [2579.735 ]\n",
      " [2581.211 ]\n",
      " [2580.545 ]\n",
      " [2595.6597]\n",
      " [2596.1958]\n",
      " [2598.4275]\n",
      " [2589.2734]\n",
      " [2584.2126]\n",
      " [2583.991 ]\n",
      " [2598.7046]\n",
      " [2599.497 ]\n",
      " [2598.5037]\n",
      " [2587.8188]\n",
      " [2591.1597]\n",
      " [2587.3674]\n",
      " [2588.1084]\n",
      " [2589.2659]\n",
      " [2610.1812]\n",
      " [2589.7473]\n",
      " [2606.575 ]\n",
      " [2591.1436]\n",
      " [2591.2046]\n",
      " [2600.5137]\n",
      " [2594.3123]\n",
      " [2594.3738]\n",
      " [2593.3823]\n",
      " [2599.1768]\n",
      " [2596.1912]\n",
      " [2608.8413]\n",
      " [2612.5247]\n",
      " [2611.3938]\n",
      " [2613.3086]\n",
      " [2601.97  ]\n",
      " [2620.0566]\n",
      " [2600.6035]\n",
      " [2601.5027]\n",
      " [2601.0938]\n",
      " [2607.4268]\n",
      " [2616.1536]\n",
      " [2621.6868]\n",
      " [2617.7512]\n",
      " [2604.712 ]\n",
      " [2611.12  ]\n",
      " [2611.2883]\n",
      " [2613.9949]\n",
      " [2611.4785]\n",
      " [2613.7961]\n",
      " [2608.6528]\n",
      " [2627.0068]\n",
      " [2623.13  ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2860.8164]\n",
      " [2863.385 ]\n",
      " [2859.5718]\n",
      " [2864.5752]\n",
      " [2852.9307]\n",
      " [2862.3691]\n",
      " [2865.148 ]\n",
      " [2858.2878]\n",
      " [2867.2708]\n",
      " [2861.2195]\n",
      " [2847.5034]\n",
      " [2869.4192]\n",
      " [2855.8293]\n",
      " [2860.1982]\n",
      " [2864.1023]\n",
      " [2870.376 ]\n",
      " [2869.3774]\n",
      " [2870.0137]\n",
      " [2866.1848]\n",
      " [2857.4683]\n",
      " [2873.0496]\n",
      " [2878.804 ]\n",
      " [2872.644 ]\n",
      " [2872.4763]\n",
      " [2873.6733]\n",
      " [2865.8843]\n",
      " [2864.4478]\n",
      " [2867.9658]\n",
      " [2878.2932]\n",
      " [2874.2346]\n",
      " [2877.243 ]\n",
      " [2846.188 ]\n",
      " [2871.822 ]\n",
      " [2880.4155]\n",
      " [2873.0193]\n",
      " [2872.3096]\n",
      " [2867.6177]\n",
      " [2882.7954]\n",
      " [2875.3992]\n",
      " [2877.9639]\n",
      " [2876.4082]\n",
      " [2879.1538]\n",
      " [2867.299 ]\n",
      " [2874.273 ]\n",
      " [2883.651 ]\n",
      " [2887.4011]\n",
      " [2887.9995]\n",
      " [2891.6243]\n",
      " [2891.348 ]\n",
      " [2882.177 ]\n",
      " [2891.3823]\n",
      " [2891.0034]\n",
      " [2892.8696]\n",
      " [2867.2244]\n",
      " [2889.704 ]\n",
      " [2861.5037]\n",
      " [2885.3044]\n",
      " [2889.8113]\n",
      " [2896.142 ]\n",
      " [2891.1716]\n",
      " [2890.691 ]\n",
      " [2899.0825]\n",
      " [2897.5188]\n",
      " [2895.217 ]\n",
      " [2893.553 ]\n",
      " [2890.5742]\n",
      " [2894.4302]\n",
      " [2902.6523]\n",
      " [2901.0847]\n",
      " [2905.379 ]\n",
      " [2896.187 ]\n",
      " [2903.335 ]\n",
      " [2889.0005]\n",
      " [2904.0598]\n",
      " [2868.4849]\n",
      " [2910.3667]\n",
      " [2902.793 ]\n",
      " [2889.2644]\n",
      " [2884.5913]\n",
      " [2902.7986]\n",
      " [2895.2344]\n",
      " [2904.861 ]\n",
      " [2908.677 ]\n",
      " [2895.7231]\n",
      " [2897.5144]\n",
      " [2913.2747]\n",
      " [2897.33  ]\n",
      " [2912.686 ]\n",
      " [2911.7678]\n",
      " [2910.6477]\n",
      " [2909.4448]\n",
      " [2909.1106]\n",
      " [2902.023 ]\n",
      " [2916.1475]\n",
      " [2904.6157]\n",
      " [2920.8215]\n",
      " [2910.744 ]\n",
      " [2877.753 ]\n",
      " [2922.2275]\n",
      " [2913.849 ]\n",
      " [2920.2776]\n",
      " [2911.9219]\n",
      " [2922.5945]\n",
      " [2890.0618]\n",
      " [2922.692 ]\n",
      " [2921.6465]\n",
      " [2917.0256]\n",
      " [2926.8853]\n",
      " [2915.7412]\n",
      " [2926.5342]\n",
      " [2927.5867]\n",
      " [2919.335 ]\n",
      " [2928.9165]\n",
      " [2929.5115]\n",
      " [2929.7568]\n",
      " [2924.4495]\n",
      " [2929.6753]\n",
      " [2905.0908]\n",
      " [2928.5864]\n",
      " [2894.1655]\n",
      " [2924.847 ]\n",
      " [2900.5078]\n",
      " [2900.3289]\n",
      " [2934.0872]\n",
      " [2932.9067]\n",
      " [2934.7603]\n",
      " [2936.427 ]\n",
      " [2894.8096]\n",
      " [2928.1414]\n",
      " [2938.9287]\n",
      " [2934.3252]\n",
      " [2933.0142]\n",
      " [2931.7812]\n",
      " [2934.994 ]\n",
      " [2934.799 ]\n",
      " [2940.485 ]\n",
      " [2932.5493]\n",
      " [2943.4407]\n",
      " [2936.2322]\n",
      " [2935.6174]\n",
      " [2937.2542]\n",
      " [2945.4988]\n",
      " [2944.9255]\n",
      " [2941.7483]\n",
      " [2948.499 ]\n",
      " [2906.3105]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2735.6729]\n",
      " [2769.4153]\n",
      " [2732.4639]\n",
      " [2770.6753]\n",
      " [2766.3154]\n",
      " [2767.3582]\n",
      " [2731.8262]\n",
      " [2773.0083]\n",
      " [2733.016 ]\n",
      " [2761.448 ]\n",
      " [2773.4932]\n",
      " [2764.016 ]\n",
      " [2753.547 ]\n",
      " [2775.278 ]\n",
      " [2758.2842]\n",
      " [2777.7446]\n",
      " [2768.8706]\n",
      " [2776.2346]\n",
      " [2763.538 ]\n",
      " [2779.697 ]\n",
      " [2731.4766]\n",
      " [2770.611 ]\n",
      " [2763.044 ]\n",
      " [2785.4243]\n",
      " [2785.847 ]\n",
      " [2770.9673]\n",
      " [2758.348 ]\n",
      " [2766.0186]\n",
      " [2763.0664]\n",
      " [2768.7969]\n",
      " [2764.2563]\n",
      " [2738.021 ]\n",
      " [2773.2947]\n",
      " [2790.7468]\n",
      " [2789.072 ]\n",
      " [2769.169 ]\n",
      " [2757.091 ]\n",
      " [2757.686 ]\n",
      " [2735.7163]\n",
      " [2794.3167]\n",
      " [2791.342 ]\n",
      " [2767.2722]\n",
      " [2797.438 ]\n",
      " [2796.0117]\n",
      " [2772.5898]\n",
      " [2795.1658]\n",
      " [2794.017 ]\n",
      " [2775.6272]\n",
      " [2774.9656]\n",
      " [2775.565 ]\n",
      " [2794.1313]\n",
      " [2801.456 ]\n",
      " [2794.8733]\n",
      " [2777.413 ]\n",
      " [2778.5354]\n",
      " [2797.1062]\n",
      " [2746.1982]\n",
      " [2769.5852]\n",
      " [2755.639 ]\n",
      " [2806.6702]\n",
      " [2804.0903]\n",
      " [2787.8354]\n",
      " [2765.1436]\n",
      " [2768.756 ]\n",
      " [2769.351 ]\n",
      " [2809.7854]\n",
      " [2803.2024]\n",
      " [2810.9753]\n",
      " [2798.5737]\n",
      " [2791.0068]\n",
      " [2812.0754]\n",
      " [2785.1208]\n",
      " [2771.0933]\n",
      " [2791.0962]\n",
      " [2812.921 ]\n",
      " [2807.4878]\n",
      " [2798.0452]\n",
      " [2793.476 ]\n",
      " [2800.6628]\n",
      " [2803.0952]\n",
      " [2801.6133]\n",
      " [2786.46  ]\n",
      " [2821.2363]\n",
      " [2803.6377]\n",
      " [2821.5442]\n",
      " [2809.9229]\n",
      " [2799.5115]\n",
      " [2777.087 ]\n",
      " [2822.7847]\n",
      " [2795.8298]\n",
      " [2784.82  ]\n",
      " [2804.0955]\n",
      " [2816.671 ]\n",
      " [2801.7385]\n",
      " [2794.1943]\n",
      " [2810.5376]\n",
      " [2816.4673]\n",
      " [2795.979 ]\n",
      " [2817.6572]\n",
      " [2830.4685]\n",
      " [2823.8792]\n",
      " [2795.7634]\n",
      " [2831.7988]\n",
      " [2830.124 ]\n",
      " [2808.283 ]\n",
      " [2793.7441]\n",
      " [2835.5151]\n",
      " [2821.777 ]\n",
      " [2818.5115]\n",
      " [2835.9634]\n",
      " [2811.857 ]\n",
      " [2830.4236]\n",
      " [2835.4785]\n",
      " [2813.1104]\n",
      " [2832.2085]\n",
      " [2832.3552]\n",
      " [2782.123 ]\n",
      " [2797.8662]\n",
      " [2783.0857]\n",
      " [2828.2715]\n",
      " [2799.6514]\n",
      " [2840.3826]\n",
      " [2825.413 ]\n",
      " [2845.6294]\n",
      " [2833.126 ]\n",
      " [2832.4863]\n",
      " [2845.3928]\n",
      " [2811.2322]\n",
      " [2840.0896]\n",
      " [2839.6152]\n",
      " [2836.6958]\n",
      " [2845.4832]\n",
      " [2791.415 ]\n",
      " [2792.2373]\n",
      " [2800.8552]\n",
      " [2827.9834]\n",
      " [2844.8494]\n",
      " [2844.375 ]\n",
      " [2838.1975]\n",
      " [2851.5425]\n",
      " [2836.1223]\n",
      " [2831.5532]\n",
      " [2840.5774]\n",
      " [2856.8188]\n",
      " [2805.251 ]\n",
      " [2855.1626]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2811.9902]\n",
      " [2789.9475]\n",
      " [2812.7417]\n",
      " [2793.131 ]\n",
      " [2814.0303]\n",
      " [2801.5715]\n",
      " [2807.8953]\n",
      " [2724.4297]\n",
      " [2812.3906]\n",
      " [2817.0322]\n",
      " [2818.6772]\n",
      " [2812.3884]\n",
      " [2815.813 ]\n",
      " [2820.3096]\n",
      " [2795.1243]\n",
      " [2816.5762]\n",
      " [2821.8167]\n",
      " [2735.3337]\n",
      " [2817.355 ]\n",
      " [2743.5386]\n",
      " [2730.4238]\n",
      " [2819.1396]\n",
      " [2815.9219]\n",
      " [2825.2358]\n",
      " [2779.132 ]\n",
      " [2818.9238]\n",
      " [2734.849 ]\n",
      " [2828.8477]\n",
      " [2821.8096]\n",
      " [2737.0574]\n",
      " [2742.1538]\n",
      " [2738.8252]\n",
      " [2825.8933]\n",
      " [2740.6245]\n",
      " [2832.8015]\n",
      " [2832.1448]\n",
      " [2816.0117]\n",
      " [2833.6636]\n",
      " [2826.439 ]\n",
      " [2824.879 ]\n",
      " [2741.847 ]\n",
      " [2786.0203]\n",
      " [2746.1123]\n",
      " [2801.9067]\n",
      " [2820.7715]\n",
      " [2812.069 ]\n",
      " [2839.941 ]\n",
      " [2749.2522]\n",
      " [2746.9062]\n",
      " [2820.499 ]\n",
      " [2841.336 ]\n",
      " [2791.9695]\n",
      " [2834.3364]\n",
      " [2763.767 ]\n",
      " [2754.749 ]\n",
      " [2835.9556]\n",
      " [2834.9932]\n",
      " [2845.9028]\n",
      " [2766.7417]\n",
      " [2847.629 ]\n",
      " [2839.1108]\n",
      " [2839.6912]\n",
      " [2846.8213]\n",
      " [2841.8076]\n",
      " [2761.8765]\n",
      " [2851.1987]\n",
      " [2761.2227]\n",
      " [2845.7058]\n",
      " [2758.5251]\n",
      " [2797.2234]\n",
      " [2850.0735]\n",
      " [2801.7283]\n",
      " [2767.6533]\n",
      " [2767.2437]\n",
      " [2855.6465]\n",
      " [2856.1736]\n",
      " [2764.327 ]\n",
      " [2852.6013]\n",
      " [2854.1855]\n",
      " [2768.0754]\n",
      " [2857.5132]\n",
      " [2859.7617]\n",
      " [2769.7773]\n",
      " [2767.906 ]\n",
      " [2848.5732]\n",
      " [2860.5571]\n",
      " [2863.776 ]\n",
      " [2776.5776]\n",
      " [2777.1726]\n",
      " [2844.7097]\n",
      " [2773.2043]\n",
      " [2825.5864]\n",
      " [2786.97  ]\n",
      " [2861.1748]\n",
      " [2774.1667]\n",
      " [2864.9475]\n",
      " [2789.3499]\n",
      " [2864.3564]\n",
      " [2784.439 ]\n",
      " [2832.1877]\n",
      " [2780.4863]\n",
      " [2871.9941]\n",
      " [2792.9197]\n",
      " [2868.3232]\n",
      " [2833.3208]\n",
      " [2783.334 ]\n",
      " [2869.267 ]\n",
      " [2828.5134]\n",
      " [2876.1296]\n",
      " [2785.5059]\n",
      " [2861.4387]\n",
      " [2784.84  ]\n",
      " [2879.3628]\n",
      " [2879.9575]\n",
      " [2786.119 ]\n",
      " [2865.562 ]\n",
      " [2787.3723]\n",
      " [2882.7527]\n",
      " [2877.5227]\n",
      " [2862.5583]\n",
      " [2790.4668]\n",
      " [2885.1326]\n",
      " [2875.4998]\n",
      " [2877.2773]\n",
      " [2798.3945]\n",
      " [2877.423 ]\n",
      " [2884.5486]\n",
      " [2884.6858]\n",
      " [2807.2532]\n",
      " [2797.7402]\n",
      " [2875.9412]\n",
      " [2889.4458]\n",
      " [2804.1245]\n",
      " [2838.6155]\n",
      " [2799.3823]\n",
      " [2798.613 ]\n",
      " [2799.5352]\n",
      " [2802.5   ]\n",
      " [2890.7773]\n",
      " [2803.823 ]\n",
      " [2804.1575]\n",
      " [2836.2905]\n",
      " [2875.8298]\n",
      " [2885.3416]\n",
      " [2804.5603]\n",
      " [2804.6257]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2463.941 ]\n",
      " [2460.1755]\n",
      " [2449.0266]\n",
      " [2488.005 ]\n",
      " [2486.3738]\n",
      " [2486.9688]\n",
      " [2480.906 ]\n",
      " [2485.5588]\n",
      " [2453.3796]\n",
      " [2478.171 ]\n",
      " [2489.7212]\n",
      " [2465.3918]\n",
      " [2470.5374]\n",
      " [2492.9734]\n",
      " [2459.634 ]\n",
      " [2473.2793]\n",
      " [2500.2732]\n",
      " [2496.9124]\n",
      " [2459.2778]\n",
      " [2471.0706]\n",
      " [2495.7256]\n",
      " [2461.0627]\n",
      " [2472.9124]\n",
      " [2462.569 ]\n",
      " [2468.8506]\n",
      " [2487.4993]\n",
      " [2484.1443]\n",
      " [2473.4417]\n",
      " [2476.4822]\n",
      " [2495.1929]\n",
      " [2481.631 ]\n",
      " [2500.1165]\n",
      " [2490.3171]\n",
      " [2483.4343]\n",
      " [2505.4675]\n",
      " [2508.9922]\n",
      " [2511.3752]\n",
      " [2495.8022]\n",
      " [2505.8005]\n",
      " [2472.89  ]\n",
      " [2501.168 ]\n",
      " [2497.0186]\n",
      " [2494.9236]\n",
      " [2511.8032]\n",
      " [2514.6436]\n",
      " [2484.8828]\n",
      " [2491.723 ]\n",
      " [2511.1553]\n",
      " [2517.0662]\n",
      " [2481.3008]\n",
      " [2507.084 ]\n",
      " [2520.026 ]\n",
      " [2512.6106]\n",
      " [2500.2083]\n",
      " [2495.4856]\n",
      " [2520.2463]\n",
      " [2510.6538]\n",
      " [2504.094 ]\n",
      " [2516.1804]\n",
      " [2483.8113]\n",
      " [2484.3777]\n",
      " [2493.6094]\n",
      " [2487.898 ]\n",
      " [2521.4763]\n",
      " [2497.0793]\n",
      " [2487.2407]\n",
      " [2528.4387]\n",
      " [2513.7166]\n",
      " [2517.7512]\n",
      " [2507.897 ]\n",
      " [2494.1843]\n",
      " [2506.5422]\n",
      " [2513.5925]\n",
      " [2515.4292]\n",
      " [2525.421 ]\n",
      " [2518.727 ]\n",
      " [2509.0173]\n",
      " [2503.1895]\n",
      " [2505.0125]\n",
      " [2512.2595]\n",
      " [2497.2832]\n",
      " [2522.1702]\n",
      " [2512.7273]\n",
      " [2509.6475]\n",
      " [2508.8235]\n",
      " [2507.9492]\n",
      " [2527.7617]\n",
      " [2516.4167]\n",
      " [2516.297 ]\n",
      " [2525.0864]\n",
      " [2500.2156]\n",
      " [2535.992 ]\n",
      " [2532.0723]\n",
      " [2531.2344]\n",
      " [2539.8286]\n",
      " [2517.9524]\n",
      " [2539.7192]\n",
      " [2509.0154]\n",
      " [2547.9888]\n",
      " [2506.7373]\n",
      " [2545.7935]\n",
      " [2533.7456]\n",
      " [2534.7212]\n",
      " [2544.4727]\n",
      " [2537.7788]\n",
      " [2549.2686]\n",
      " [2539.0693]\n",
      " [2538.7754]\n",
      " [2513.942 ]\n",
      " [2551.1482]\n",
      " [2514.0137]\n",
      " [2529.1814]\n",
      " [2539.2751]\n",
      " [2519.765 ]\n",
      " [2526.827 ]\n",
      " [2554.7178]\n",
      " [2553.009 ]\n",
      " [2542.505 ]\n",
      " [2552.056 ]\n",
      " [2517.4695]\n",
      " [2544.3782]\n",
      " [2531.8132]\n",
      " [2522.2712]\n",
      " [2537.8352]\n",
      " [2545.91  ]\n",
      " [2538.9417]\n",
      " [2523.6733]\n",
      " [2539.11  ]\n",
      " [2549.3098]\n",
      " [2568.9543]\n",
      " [2526.2292]\n",
      " [2537.674 ]\n",
      " [2529.8389]\n",
      " [2551.7693]\n",
      " [2550.4797]\n",
      " [2554.108 ]\n",
      " [2566.1528]\n",
      " [2571.2307]\n",
      " [2557.913 ]\n",
      " [2568.9968]\n",
      " [2556.189 ]\n",
      " [2572.3542]\n",
      " [2572.9924]\n",
      " [2567.7678]\n",
      " [2560.7615]\n",
      " [2545.2708]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2575.9045]\n",
      " [2576.4995]\n",
      " [2578.753 ]\n",
      " [2580.0444]\n",
      " [2576.8247]\n",
      " [2586.703 ]\n",
      " [2581.1328]\n",
      " [2578.6096]\n",
      " [2584.7651]\n",
      " [2589.0828]\n",
      " [2588.1648]\n",
      " [2582.449 ]\n",
      " [2581.5845]\n",
      " [2591.4626]\n",
      " [2586.6436]\n",
      " [2587.1838]\n",
      " [2587.8335]\n",
      " [2587.6772]\n",
      " [2593.895 ]\n",
      " [2589.6184]\n",
      " [2587.8037]\n",
      " [2588.8167]\n",
      " [2591.617 ]\n",
      " [2590.0066]\n",
      " [2597.4648]\n",
      " [2589.3188]\n",
      " [2589.9138]\n",
      " [2590.5088]\n",
      " [2592.9814]\n",
      " [2597.259 ]\n",
      " [2597.854 ]\n",
      " [2596.7031]\n",
      " [2595.3613]\n",
      " [2595.538 ]\n",
      " [2598.7566]\n",
      " [2600.8289]\n",
      " [2601.4238]\n",
      " [2596.7012]\n",
      " [2597.0532]\n",
      " [2597.891 ]\n",
      " [2602.1125]\n",
      " [2607.5793]\n",
      " [2606.239 ]\n",
      " [2600.028 ]\n",
      " [2608.3936]\n",
      " [2601.218 ]\n",
      " [2605.8958]\n",
      " [2606.491 ]\n",
      " [2608.5632]\n",
      " [2610.4038]\n",
      " [2604.1926]\n",
      " [2608.6023]\n",
      " [2607.2603]\n",
      " [2615.2607]\n",
      " [2606.5725]\n",
      " [2611.2502]\n",
      " [2608.0054]\n",
      " [2612.2268]\n",
      " [2616.723 ]\n",
      " [2617.3179]\n",
      " [2611.6018]\n",
      " [2620.0205]\n",
      " [2615.2014]\n",
      " [2618.7332]\n",
      " [2612.5222]\n",
      " [2622.4004]\n",
      " [2622.4531]\n",
      " [2618.1763]\n",
      " [2624.185 ]\n",
      " [2615.4968]\n",
      " [2616.3345]\n",
      " [2620.5015]\n",
      " [2620.4   ]\n",
      " [2619.3362]\n",
      " [2621.5898]\n",
      " [2624.6272]\n",
      " [2623.531 ]\n",
      " [2625.817 ]\n",
      " [2623.9697]\n",
      " [2625.2612]\n",
      " [2623.9192]\n",
      " [2625.7546]\n",
      " [2627.3142]\n",
      " [2632.5674]\n",
      " [2628.2358]\n",
      " [2634.2993]\n",
      " [2629.694 ]\n",
      " [2635.4893]\n",
      " [2635.5422]\n",
      " [2629.2737]\n",
      " [2634.797 ]\n",
      " [2631.704 ]\n",
      " [2637.922 ]\n",
      " [2631.6536]\n",
      " [2630.3708]\n",
      " [2634.084 ]\n",
      " [2635.6438]\n",
      " [2636.025 ]\n",
      " [2636.8337]\n",
      " [2633.5884]\n",
      " [2635.4001]\n",
      " [2640.096 ]\n",
      " [2642.9011]\n",
      " [2645.0085]\n",
      " [2640.135 ]\n",
      " [2644.686 ]\n",
      " [2646.7935]\n",
      " [2638.1052]\n",
      " [2645.506 ]\n",
      " [2648.5784]\n",
      " [2649.1733]\n",
      " [2641.9446]\n",
      " [2650.3633]\n",
      " [2643.1345]\n",
      " [2642.5127]\n",
      " [2646.6794]\n",
      " [2647.329 ]\n",
      " [2644.0547]\n",
      " [2647.768 ]\n",
      " [2653.0154]\n",
      " [2649.709 ]\n",
      " [2653.2407]\n",
      " [2650.8442]\n",
      " [2651.494 ]\n",
      " [2650.0972]\n",
      " [2657.5557]\n",
      " [2650.869 ]\n",
      " [2651.4639]\n",
      " [2652.0588]\n",
      " [2658.9648]\n",
      " [2655.604 ]\n",
      " [2656.2534]\n",
      " [2652.979 ]\n",
      " [2653.817 ]\n",
      " [2654.169 ]\n",
      " [2658.847 ]\n",
      " [2655.359 ]\n",
      " [2659.072 ]\n",
      " [2656.7915]\n",
      " [2661.0132]\n",
      " [2659.1982]\n",
      " [2662.2031]\n",
      " [2667.67  ]\n",
      " [2661.4014]\n",
      " [2665.679 ]\n",
      " [2664.5828]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2506.3228]\n",
      " [2554.6091]\n",
      " [2555.204 ]\n",
      " [2550.6538]\n",
      " [2540.195 ]\n",
      " [2501.438 ]\n",
      " [2549.738 ]\n",
      " [2550.333 ]\n",
      " [2523.7192]\n",
      " [2563.65  ]\n",
      " [2561.9172]\n",
      " [2559.9297]\n",
      " [2567.944 ]\n",
      " [2561.1196]\n",
      " [2562.3438]\n",
      " [2555.0925]\n",
      " [2535.2253]\n",
      " [2562.426 ]\n",
      " [2566.6768]\n",
      " [2564.6892]\n",
      " [2570.1943]\n",
      " [2527.7227]\n",
      " [2566.474 ]\n",
      " [2567.6982]\n",
      " [2570.2466]\n",
      " [2540.5798]\n",
      " [2564.338 ]\n",
      " [2558.4893]\n",
      " [2531.8872]\n",
      " [2532.482 ]\n",
      " [2560.274 ]\n",
      " [2583.4033]\n",
      " [2556.8538]\n",
      " [2545.3394]\n",
      " [2581.033 ]\n",
      " [2573.1353]\n",
      " [2586.3782]\n",
      " [2564.4387]\n",
      " [2562.6685]\n",
      " [2569.3716]\n",
      " [2585.0918]\n",
      " [2570.5615]\n",
      " [2573.8572]\n",
      " [2551.289 ]\n",
      " [2579.5632]\n",
      " [2525.236 ]\n",
      " [2592.3276]\n",
      " [2576.8318]\n",
      " [2593.5176]\n",
      " [2590.4463]\n",
      " [2583.133 ]\n",
      " [2588.6377]\n",
      " [2584.952 ]\n",
      " [2538.2822]\n",
      " [2530.5908]\n",
      " [2591.0176]\n",
      " [2594.122 ]\n",
      " [2532.3757]\n",
      " [2560.2134]\n",
      " [2588.4875]\n",
      " [2600.6572]\n",
      " [2561.9983]\n",
      " [2583.0554]\n",
      " [2591.4966]\n",
      " [2544.4   ]\n",
      " [2576.4873]\n",
      " [2545.5898]\n",
      " [2593.247 ]\n",
      " [2555.6855]\n",
      " [2547.3748]\n",
      " [2606.6067]\n",
      " [2598.2095]\n",
      " [2582.897 ]\n",
      " [2562.3914]\n",
      " [2569.7327]\n",
      " [2598.0068]\n",
      " [2606.0212]\n",
      " [2594.6804]\n",
      " [2552.7292]\n",
      " [2607.806 ]\n",
      " [2566.5562]\n",
      " [2590.6167]\n",
      " [2555.536 ]\n",
      " [2605.3489]\n",
      " [2602.288 ]\n",
      " [2596.7395]\n",
      " [2576.872 ]\n",
      " [2607.7288]\n",
      " [2558.6787]\n",
      " [2611.246 ]\n",
      " [2607.5603]\n",
      " [2600.309 ]\n",
      " [2600.904 ]\n",
      " [2595.3909]\n",
      " [2574.8855]\n",
      " [2617.3254]\n",
      " [2555.5789]\n",
      " [2619.0042]\n",
      " [2564.6284]\n",
      " [2619.705 ]\n",
      " [2574.724 ]\n",
      " [2566.4133]\n",
      " [2609.5544]\n",
      " [2568.03  ]\n",
      " [2560.3386]\n",
      " [2608.6387]\n",
      " [2623.8699]\n",
      " [2617.6746]\n",
      " [2620.223 ]\n",
      " [2623.145 ]\n",
      " [2607.8706]\n",
      " [2614.909 ]\n",
      " [2624.9302]\n",
      " [2565.693 ]\n",
      " [2623.7925]\n",
      " [2610.8452]\n",
      " [2575.3376]\n",
      " [2568.073 ]\n",
      " [2595.9106]\n",
      " [2623.1116]\n",
      " [2569.858 ]\n",
      " [2578.7393]\n",
      " [2630.88  ]\n",
      " [2631.4746]\n",
      " [2580.5242]\n",
      " [2600.0754]\n",
      " [2581.714 ]\n",
      " [2617.9849]\n",
      " [2629.5396]\n",
      " [2638.0427]\n",
      " [2638.6377]\n",
      " [2617.9993]\n",
      " [2639.3386]\n",
      " [2594.3574]\n",
      " [2617.5393]\n",
      " [2595.5474]\n",
      " [2599.8735]\n",
      " [2588.2585]\n",
      " [2642.9084]\n",
      " [2628.867 ]\n",
      " [2636.679 ]\n",
      " [2630.057 ]\n",
      " [2630.6519]\n",
      " [2583.5417]\n",
      " [2631.8418]\n",
      " [2601.497 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2463.9385]\n",
      " [2433.7275]\n",
      " [2444.2212]\n",
      " [2468.6226]\n",
      " [2447.125 ]\n",
      " [2447.72  ]\n",
      " [2441.6323]\n",
      " [2449.3667]\n",
      " [2443.3164]\n",
      " [2443.417 ]\n",
      " [2472.4497]\n",
      " [2433.359 ]\n",
      " [2440.2695]\n",
      " [2463.048 ]\n",
      " [2452.4927]\n",
      " [2459.404 ]\n",
      " [2442.6519]\n",
      " [2452.045 ]\n",
      " [2453.7405]\n",
      " [2454.4944]\n",
      " [2445.0317]\n",
      " [2456.337 ]\n",
      " [2459.4119]\n",
      " [2480.5217]\n",
      " [2456.2097]\n",
      " [2442.9868]\n",
      " [2457.3994]\n",
      " [2486.6814]\n",
      " [2459.8489]\n",
      " [2455.8105]\n",
      " [2457.9763]\n",
      " [2470.2744]\n",
      " [2454.061 ]\n",
      " [2474.9473]\n",
      " [2470.7083]\n",
      " [2484.762 ]\n",
      " [2467.7412]\n",
      " [2443.3997]\n",
      " [2481.086 ]\n",
      " [2458.2256]\n",
      " [2490.2983]\n",
      " [2457.5232]\n",
      " [2463.545 ]\n",
      " [2446.0667]\n",
      " [2465.251 ]\n",
      " [2477.2527]\n",
      " [2455.4807]\n",
      " [2473.6245]\n",
      " [2487.0354]\n",
      " [2467.7097]\n",
      " [2451.134 ]\n",
      " [2482.699 ]\n",
      " [2474.7808]\n",
      " [2474.723 ]\n",
      " [2496.0662]\n",
      " [2499.2227]\n",
      " [2479.6404]\n",
      " [2466.456 ]\n",
      " [2455.8938]\n",
      " [2479.2656]\n",
      " [2480.8992]\n",
      " [2474.355 ]\n",
      " [2470.02  ]\n",
      " [2512.7139]\n",
      " [2483.7388]\n",
      " [2480.6025]\n",
      " [2484.0122]\n",
      " [2460.3455]\n",
      " [2479.53  ]\n",
      " [2487.3748]\n",
      " [2508.4846]\n",
      " [2475.3745]\n",
      " [2495.193 ]\n",
      " [2489.0933]\n",
      " [2472.1396]\n",
      " [2477.165 ]\n",
      " [2493.2764]\n",
      " [2491.4731]\n",
      " [2512.9065]\n",
      " [2510.94  ]\n",
      " [2498.0762]\n",
      " [2514.6914]\n",
      " [2503.2925]\n",
      " [2501.2122]\n",
      " [2528.9758]\n",
      " [2496.894 ]\n",
      " [2505.6724]\n",
      " [2484.891 ]\n",
      " [2507.6697]\n",
      " [2531.9507]\n",
      " [2509.4475]\n",
      " [2492.2036]\n",
      " [2510.0493]\n",
      " [2503.3906]\n",
      " [2493.9883]\n",
      " [2519.964 ]\n",
      " [2509.472 ]\n",
      " [2521.6492]\n",
      " [2528.923 ]\n",
      " [2499.0283]\n",
      " [2492.6255]\n",
      " [2530.708 ]\n",
      " [2543.3025]\n",
      " [2531.898 ]\n",
      " [2500.9482]\n",
      " [2505.6604]\n",
      " [2496.1953]\n",
      " [2491.773 ]\n",
      " [2540.2002]\n",
      " [2510.052 ]\n",
      " [2503.5078]\n",
      " [2499.1729]\n",
      " [2521.141 ]\n",
      " [2500.3599]\n",
      " [2510.8562]\n",
      " [2526.8975]\n",
      " [2512.858 ]\n",
      " [2515.9326]\n",
      " [2524.711 ]\n",
      " [2513.99  ]\n",
      " [2509.4575]\n",
      " [2516.1528]\n",
      " [2516.7478]\n",
      " [2555.7966]\n",
      " [2517.6177]\n",
      " [2528.8755]\n",
      " [2553.964 ]\n",
      " [2539.0027]\n",
      " [2542.6543]\n",
      " [2511.7717]\n",
      " [2516.4172]\n",
      " [2525.9988]\n",
      " [2533.8477]\n",
      " [2523.8743]\n",
      " [2523.8872]\n",
      " [2525.0642]\n",
      " [2522.8447]\n",
      " [2523.4395]\n",
      " [2552.7214]\n",
      " [2529.0217]\n",
      " [2516.4238]\n",
      " [2550.7266]\n",
      " [2547.927 ]\n",
      " [2523.6355]\n",
      " [2543.9983]\n",
      " [2524.8254]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2657.2986]\n",
      " [2650.218 ]\n",
      " [2603.709 ]\n",
      " [2630.21  ]\n",
      " [2675.0674]\n",
      " [2678.9817]\n",
      " [2681.166 ]\n",
      " [2673.3206]\n",
      " [2612.773 ]\n",
      " [2633.7798]\n",
      " [2666.633 ]\n",
      " [2679.2188]\n",
      " [2612.8594]\n",
      " [2680.9124]\n",
      " [2681.017 ]\n",
      " [2684.5427]\n",
      " [2666.8179]\n",
      " [2676.8247]\n",
      " [2683.8872]\n",
      " [2666.8286]\n",
      " [2684.9   ]\n",
      " [2688.6482]\n",
      " [2668.6135]\n",
      " [2621.697 ]\n",
      " [2690.286 ]\n",
      " [2687.2659]\n",
      " [2662.1306]\n",
      " [2690.4292]\n",
      " [2689.0508]\n",
      " [2628.5   ]\n",
      " [2623.5686]\n",
      " [2629.69  ]\n",
      " [2691.5688]\n",
      " [2627.6467]\n",
      " [2692.9163]\n",
      " [2694.5   ]\n",
      " [2697.1135]\n",
      " [2695.69  ]\n",
      " [2655.305 ]\n",
      " [2625.7224]\n",
      " [2643.3313]\n",
      " [2698.7842]\n",
      " [2627.5073]\n",
      " [2698.9675]\n",
      " [2703.7742]\n",
      " [2653.8184]\n",
      " [2655.7932]\n",
      " [2667.918 ]\n",
      " [2701.2322]\n",
      " [2644.1877]\n",
      " [2687.0464]\n",
      " [2697.4248]\n",
      " [2633.48  ]\n",
      " [2704.207 ]\n",
      " [2640.1409]\n",
      " [2705.253 ]\n",
      " [2705.7095]\n",
      " [2636.4548]\n",
      " [2698.27  ]\n",
      " [2667.799 ]\n",
      " [2710.0884]\n",
      " [2639.304 ]\n",
      " [2638.9365]\n",
      " [2711.1587]\n",
      " [2657.61  ]\n",
      " [2711.3599]\n",
      " [2705.9775]\n",
      " [2714.253 ]\n",
      " [2712.8489]\n",
      " [2712.071 ]\n",
      " [2714.0388]\n",
      " [2699.5405]\n",
      " [2706.5994]\n",
      " [2649.1516]\n",
      " [2707.7893]\n",
      " [2713.7776]\n",
      " [2672.2393]\n",
      " [2721.9656]\n",
      " [2713.1172]\n",
      " [2719.8005]\n",
      " [2723.1418]\n",
      " [2676.6165]\n",
      " [2651.798 ]\n",
      " [2722.5593]\n",
      " [2707.275 ]\n",
      " [2723.3704]\n",
      " [2653.7085]\n",
      " [2654.2803]\n",
      " [2701.979 ]\n",
      " [2728.6462]\n",
      " [2714.2297]\n",
      " [2656.6602]\n",
      " [2728.1204]\n",
      " [2726.3499]\n",
      " [2731.55  ]\n",
      " [2732.5012]\n",
      " [2732.7341]\n",
      " [2686.1357]\n",
      " [2725.3877]\n",
      " [2678.4338]\n",
      " [2662.5073]\n",
      " [2697.5078]\n",
      " [2731.1282]\n",
      " [2735.6458]\n",
      " [2664.887 ]\n",
      " [2738.1658]\n",
      " [2674.3115]\n",
      " [2683.1936]\n",
      " [2675.5015]\n",
      " [2737.2422]\n",
      " [2712.1067]\n",
      " [2729.8027]\n",
      " [2713.2966]\n",
      " [2669.7722]\n",
      " [2687.3582]\n",
      " [2676.433 ]\n",
      " [2671.534 ]\n",
      " [2742.7878]\n",
      " [2745.7502]\n",
      " [2743.4873]\n",
      " [2747.013 ]\n",
      " [2732.673 ]\n",
      " [2712.5396]\n",
      " [2700.2249]\n",
      " [2748.1655]\n",
      " [2751.831 ]\n",
      " [2682.9775]\n",
      " [2749.9578]\n",
      " [2736.8381]\n",
      " [2679.761 ]\n",
      " [2753.4983]\n",
      " [2679.9883]\n",
      " [2751.0645]\n",
      " [2734.6536]\n",
      " [2755.4192]\n",
      " [2751.3381]\n",
      " [2744.6768]\n",
      " [2752.528 ]\n",
      " [2709.1492]\n",
      " [2755.6995]\n",
      " [2755.429 ]\n",
      " [2689.6086]\n",
      " [2757.2827]\n",
      " [2760.697 ]\n",
      " [2712.6963]\n",
      " [2726.2236]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2469.5557]\n",
      " [2572.2126]\n",
      " [2569.915 ]\n",
      " [2583.2488]\n",
      " [2571.346 ]\n",
      " [2569.1501]\n",
      " [2481.1477]\n",
      " [2468.6956]\n",
      " [2586.502 ]\n",
      " [2571.6548]\n",
      " [2469.395 ]\n",
      " [2578.56  ]\n",
      " [2580.0588]\n",
      " [2579.064 ]\n",
      " [2576.3987]\n",
      " [2510.2263]\n",
      " [2493.0237]\n",
      " [2494.1055]\n",
      " [2583.502 ]\n",
      " [2581.0999]\n",
      " [2583.54  ]\n",
      " [2490.072 ]\n",
      " [2497.3193]\n",
      " [2587.0159]\n",
      " [2499.9197]\n",
      " [2492.5234]\n",
      " [2597.0503]\n",
      " [2510.4028]\n",
      " [2495.3328]\n",
      " [2480.1216]\n",
      " [2554.328 ]\n",
      " [2590.4592]\n",
      " [2581.3154]\n",
      " [2553.8682]\n",
      " [2562.1018]\n",
      " [2504.3276]\n",
      " [2486.268 ]\n",
      " [2563.8867]\n",
      " [2580.5813]\n",
      " [2594.821 ]\n",
      " [2489.8997]\n",
      " [2560.8784]\n",
      " [2605.5938]\n",
      " [2589.8726]\n",
      " [2493.5312]\n",
      " [2507.8403]\n",
      " [2511.4768]\n",
      " [2489.5002]\n",
      " [2597.9211]\n",
      " [2492.0208]\n",
      " [2512.2734]\n",
      " [2588.3157]\n",
      " [2598.1804]\n",
      " [2501.4048]\n",
      " [2599.8281]\n",
      " [2596.892 ]\n",
      " [2607.598 ]\n",
      " [2513.3032]\n",
      " [2511.6206]\n",
      " [2536.4043]\n",
      " [2512.5054]\n",
      " [2605.2583]\n",
      " [2613.8047]\n",
      " [2601.4495]\n",
      " [2606.501 ]\n",
      " [2508.599 ]\n",
      " [2602.8647]\n",
      " [2608.371 ]\n",
      " [2517.2651]\n",
      " [2504.1086]\n",
      " [2513.0837]\n",
      " [2614.645 ]\n",
      " [2614.4546]\n",
      " [2506.6475]\n",
      " [2508.6943]\n",
      " [2608.5396]\n",
      " [2524.6519]\n",
      " [2610.0862]\n",
      " [2618.0242]\n",
      " [2613.1768]\n",
      " [2617.2805]\n",
      " [2521.1401]\n",
      " [2615.0986]\n",
      " [2614.7656]\n",
      " [2612.253 ]\n",
      " [2623.2422]\n",
      " [2514.1763]\n",
      " [2593.6345]\n",
      " [2518.4575]\n",
      " [2535.1194]\n",
      " [2527.886 ]\n",
      " [2617.7388]\n",
      " [2626.0273]\n",
      " [2536.6077]\n",
      " [2519.2632]\n",
      " [2526.4482]\n",
      " [2535.791 ]\n",
      " [2532.2256]\n",
      " [2622.1365]\n",
      " [2520.8674]\n",
      " [2632.415 ]\n",
      " [2543.4685]\n",
      " [2527.0525]\n",
      " [2524.359 ]\n",
      " [2626.9026]\n",
      " [2546.29  ]\n",
      " [2527.9148]\n",
      " [2553.876 ]\n",
      " [2546.4236]\n",
      " [2632.093 ]\n",
      " [2543.6267]\n",
      " [2634.7344]\n",
      " [2634.8228]\n",
      " [2551.0493]\n",
      " [2542.165 ]\n",
      " [2535.269 ]\n",
      " [2643.0615]\n",
      " [2633.8845]\n",
      " [2547.7468]\n",
      " [2634.7178]\n",
      " [2651.7415]\n",
      " [2636.159 ]\n",
      " [2638.8848]\n",
      " [2536.2578]\n",
      " [2629.2285]\n",
      " [2645.028 ]\n",
      " [2645.5024]\n",
      " [2540.409 ]\n",
      " [2542.0176]\n",
      " [2642.9246]\n",
      " [2559.9592]\n",
      " [2557.23  ]\n",
      " [2642.212 ]\n",
      " [2556.8003]\n",
      " [2561.8923]\n",
      " [2614.5532]\n",
      " [2558.492 ]\n",
      " [2548.3582]\n",
      " [2659.0215]\n",
      " [2555.6477]\n",
      " [2549.395 ]\n",
      " [2652.0764]\n",
      " [2658.4036]\n",
      " [2548.6465]\n",
      " [2657.6892]\n",
      " [2659.6006]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2485.054 ]\n",
      " [2485.649 ]\n",
      " [2490.664 ]\n",
      " [2487.7888]\n",
      " [2486.8315]\n",
      " [2486.6497]\n",
      " [2487.7463]\n",
      " [2489.7395]\n",
      " [2493.9177]\n",
      " [2490.122 ]\n",
      " [2490.1338]\n",
      " [2490.1113]\n",
      " [2492.7144]\n",
      " [2484.53  ]\n",
      " [2494.5994]\n",
      " [2500.6033]\n",
      " [2495.505 ]\n",
      " [2499.6135]\n",
      " [2503.4888]\n",
      " [2497.6914]\n",
      " [2501.3733]\n",
      " [2504.5676]\n",
      " [2496.6562]\n",
      " [2502.9612]\n",
      " [2496.1409]\n",
      " [2500.8867]\n",
      " [2501.506 ]\n",
      " [2501.9548]\n",
      " [2506.821 ]\n",
      " [2501.3198]\n",
      " [2502.6719]\n",
      " [2501.0413]\n",
      " [2502.1648]\n",
      " [2508.9905]\n",
      " [2509.3865]\n",
      " [2507.1113]\n",
      " [2506.2415]\n",
      " [2507.4153]\n",
      " [2515.3909]\n",
      " [2505.333 ]\n",
      " [2501.161 ]\n",
      " [2510.322 ]\n",
      " [2513.6726]\n",
      " [2511.4688]\n",
      " [2517.2686]\n",
      " [2512.271 ]\n",
      " [2511.4072]\n",
      " [2515.9497]\n",
      " [2518.565 ]\n",
      " [2514.808 ]\n",
      " [2521.8215]\n",
      " [2511.7927]\n",
      " [2516.8286]\n",
      " [2520.6516]\n",
      " [2520.473 ]\n",
      " [2519.7422]\n",
      " [2526.9258]\n",
      " [2524.8826]\n",
      " [2520.4363]\n",
      " [2523.4478]\n",
      " [2524.047 ]\n",
      " [2517.272 ]\n",
      " [2530.6274]\n",
      " [2523.486 ]\n",
      " [2518.218 ]\n",
      " [2522.347 ]\n",
      " [2524.9895]\n",
      " [2522.829 ]\n",
      " [2531.5476]\n",
      " [2531.5652]\n",
      " [2518.6062]\n",
      " [2525.8274]\n",
      " [2519.9941]\n",
      " [2537.4165]\n",
      " [2533.1846]\n",
      " [2532.171 ]\n",
      " [2522.579 ]\n",
      " [2531.4668]\n",
      " [2538.0393]\n",
      " [2537.662 ]\n",
      " [2532.9985]\n",
      " [2540.3213]\n",
      " [2540.402 ]\n",
      " [2539.5093]\n",
      " [2541.7693]\n",
      " [2539.8992]\n",
      " [2545.8926]\n",
      " [2541.2324]\n",
      " [2529.5593]\n",
      " [2535.918 ]\n",
      " [2544.3076]\n",
      " [2537.267 ]\n",
      " [2540.6719]\n",
      " [2546.6555]\n",
      " [2539.5603]\n",
      " [2542.414 ]\n",
      " [2545.1025]\n",
      " [2551.6956]\n",
      " [2548.8613]\n",
      " [2539.6196]\n",
      " [2545.723 ]\n",
      " [2546.7603]\n",
      " [2550.247 ]\n",
      " [2547.2493]\n",
      " [2554.6548]\n",
      " [2550.82  ]\n",
      " [2550.6726]\n",
      " [2554.9849]\n",
      " [2558.24  ]\n",
      " [2550.7861]\n",
      " [2553.0525]\n",
      " [2560.0137]\n",
      " [2544.4805]\n",
      " [2552.9207]\n",
      " [2561.8098]\n",
      " [2552.459 ]\n",
      " [2558.7693]\n",
      " [2550.6995]\n",
      " [2561.2954]\n",
      " [2564.0046]\n",
      " [2562.3823]\n",
      " [2563.6687]\n",
      " [2563.098 ]\n",
      " [2563.8752]\n",
      " [2559.7874]\n",
      " [2563.4592]\n",
      " [2560.8   ]\n",
      " [2568.9414]\n",
      " [2556.8733]\n",
      " [2565.0989]\n",
      " [2561.521 ]\n",
      " [2567.5005]\n",
      " [2561.3237]\n",
      " [2572.3674]\n",
      " [2569.731 ]\n",
      " [2570.7095]\n",
      " [2565.6108]\n",
      " [2567.352 ]\n",
      " [2573.3572]\n",
      " [2567.7737]\n",
      " [2560.4756]\n",
      " [2565.3972]\n",
      " [2579.4438]\n",
      " [2572.9543]\n",
      " [2570.743 ]\n",
      " [2581.2288]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2437.5254]\n",
      " [2444.397 ]\n",
      " [2446.8694]\n",
      " [2446.0862]\n",
      " [2446.6812]\n",
      " [2447.6484]\n",
      " [2451.0613]\n",
      " [2442.4658]\n",
      " [2454.5676]\n",
      " [2450.0283]\n",
      " [2441.0657]\n",
      " [2452.2239]\n",
      " [2456.1475]\n",
      " [2452.0356]\n",
      " [2443.752 ]\n",
      " [2444.0403]\n",
      " [2447.0444]\n",
      " [2453.9163]\n",
      " [2462.8115]\n",
      " [2451.7976]\n",
      " [2452.9468]\n",
      " [2460.7344]\n",
      " [2454.1367]\n",
      " [2457.9275]\n",
      " [2458.5225]\n",
      " [2449.99  ]\n",
      " [2459.77  ]\n",
      " [2459.0044]\n",
      " [2461.3325]\n",
      " [2461.555 ]\n",
      " [2453.9902]\n",
      " [2453.8662]\n",
      " [2466.53  ]\n",
      " [2471.7358]\n",
      " [2464.9019]\n",
      " [2466.637 ]\n",
      " [2465.6619]\n",
      " [2469.505 ]\n",
      " [2463.6558]\n",
      " [2471.616 ]\n",
      " [2464.8457]\n",
      " [2476.4956]\n",
      " [2462.5132]\n",
      " [2463.8843]\n",
      " [2474.5906]\n",
      " [2475.781 ]\n",
      " [2471.6692]\n",
      " [2470.9033]\n",
      " [2476.0496]\n",
      " [2474.832 ]\n",
      " [2468.0488]\n",
      " [2468.644 ]\n",
      " [2476.617 ]\n",
      " [2475.3347]\n",
      " [2467.55  ]\n",
      " [2467.8386]\n",
      " [2481.5576]\n",
      " [2479.5918]\n",
      " [2477.4478]\n",
      " [2472.6274]\n",
      " [2485.5054]\n",
      " [2485.3003]\n",
      " [2485.8953]\n",
      " [2486.49  ]\n",
      " [2477.699 ]\n",
      " [2478.294 ]\n",
      " [2485.0806]\n",
      " [2484.5356]\n",
      " [2488.8696]\n",
      " [2477.1936]\n",
      " [2481.2686]\n",
      " [2477.6643]\n",
      " [2478.9785]\n",
      " [2489.111 ]\n",
      " [2479.4492]\n",
      " [2490.435 ]\n",
      " [2484.8384]\n",
      " [2494.224 ]\n",
      " [2483.9316]\n",
      " [2491.245 ]\n",
      " [2482.7124]\n",
      " [2485.7168]\n",
      " [2494.5999]\n",
      " [2493.1833]\n",
      " [2498.2163]\n",
      " [2496.2505]\n",
      " [2495.4675]\n",
      " [2486.8772]\n",
      " [2499.8477]\n",
      " [2505.0537]\n",
      " [2501.9587]\n",
      " [2498.3845]\n",
      " [2495.2295]\n",
      " [2492.856 ]\n",
      " [2498.8662]\n",
      " [2502.2   ]\n",
      " [2501.417 ]\n",
      " [2498.2043]\n",
      " [2499.3535]\n",
      " [2499.9482]\n",
      " [2509.3035]\n",
      " [2504.7642]\n",
      " [2504.929 ]\n",
      " [2505.954 ]\n",
      " [2506.119 ]\n",
      " [2498.612 ]\n",
      " [2506.8672]\n",
      " [2506.6006]\n",
      " [2510.0686]\n",
      " [2500.2725]\n",
      " [2505.939 ]\n",
      " [2518.1428]\n",
      " [2507.1287]\n",
      " [2510.1704]\n",
      " [2503.2476]\n",
      " [2511.3604]\n",
      " [2517.4275]\n",
      " [2515.289 ]\n",
      " [2520.0127]\n",
      " [2505.9155]\n",
      " [2523.4973]\n",
      " [2521.7976]\n",
      " [2520.0762]\n",
      " [2516.1199]\n",
      " [2522.7825]\n",
      " [2524.1775]\n",
      " [2511.106 ]\n",
      " [2511.701 ]\n",
      " [2524.567 ]\n",
      " [2517.7969]\n",
      " [2523.1577]\n",
      " [2523.6184]\n",
      " [2526.774 ]\n",
      " [2514.5513]\n",
      " [2522.6646]\n",
      " [2515.435 ]\n",
      " [2517.0557]\n",
      " [2525.81  ]\n",
      " [2522.5977]\n",
      " [2525.6392]\n",
      " [2521.5947]\n",
      " [2524.9365]\n",
      " [2525.5312]\n",
      " [2520.501 ]\n",
      " [2533.9136]\n",
      " [2523.794 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2617.7468]\n",
      " [2618.3423]\n",
      " [2618.9675]\n",
      " [2619.563 ]\n",
      " [2620.17  ]\n",
      " [2620.7222]\n",
      " [2621.3237]\n",
      " [2621.9114]\n",
      " [2622.538 ]\n",
      " [2623.1665]\n",
      " [2623.751 ]\n",
      " [2624.322 ]\n",
      " [2624.918 ]\n",
      " [2625.5232]\n",
      " [2626.1184]\n",
      " [2626.695 ]\n",
      " [2627.3083]\n",
      " [2627.8616]\n",
      " [2628.5107]\n",
      " [2629.093 ]\n",
      " [2629.646 ]\n",
      " [2630.241 ]\n",
      " [2630.8677]\n",
      " [2631.474 ]\n",
      " [2632.0312]\n",
      " [2632.652 ]\n",
      " [2633.2725]\n",
      " [2633.8105]\n",
      " [2634.4062]\n",
      " [2635.0012]\n",
      " [2635.6008]\n",
      " [2636.196 ]\n",
      " [2636.786 ]\n",
      " [2637.3994]\n",
      " [2638.0405]\n",
      " [2638.6138]\n",
      " [2639.1968]\n",
      " [2639.8125]\n",
      " [2640.3557]\n",
      " [2640.9814]\n",
      " [2641.6018]\n",
      " [2642.1833]\n",
      " [2642.7917]\n",
      " [2643.3298]\n",
      " [2643.967 ]\n",
      " [2644.5251]\n",
      " [2645.1565]\n",
      " [2645.7102]\n",
      " [2646.3354]\n",
      " [2646.9236]\n",
      " [2647.5017]\n",
      " [2648.1548]\n",
      " [2648.7368]\n",
      " [2649.3228]\n",
      " [2649.9312]\n",
      " [2650.4749]\n",
      " [2651.065 ]\n",
      " [2651.7026]\n",
      " [2652.2976]\n",
      " [2652.8547]\n",
      " [2653.5093]\n",
      " [2654.0938]\n",
      " [2654.6658]\n",
      " [2655.2363]\n",
      " [2655.8787]\n",
      " [2656.4497]\n",
      " [2657.033 ]\n",
      " [2657.6096]\n",
      " [2658.2585]\n",
      " [2658.8535]\n",
      " [2659.4485]\n",
      " [2660.041 ]\n",
      " [2660.589 ]\n",
      " [2661.2354]\n",
      " [2661.7742]\n",
      " [2662.3684]\n",
      " [2662.9707]\n",
      " [2663.6   ]\n",
      " [2664.1968]\n",
      " [2664.7673]\n",
      " [2665.398 ]\n",
      " [2665.97  ]\n",
      " [2666.5981]\n",
      " [2667.1335]\n",
      " [2667.747 ]\n",
      " [2668.3833]\n",
      " [2668.9553]\n",
      " [2669.5627]\n",
      " [2670.1335]\n",
      " [2670.7053]\n",
      " [2671.3245]\n",
      " [2671.9194]\n",
      " [2672.4902]\n",
      " [2673.1301]\n",
      " [2673.7378]\n",
      " [2674.2683]\n",
      " [2674.8816]\n",
      " [2675.4998]\n",
      " [2676.0764]\n",
      " [2676.7021]\n",
      " [2677.2664]\n",
      " [2677.838 ]\n",
      " [2678.4639]\n",
      " [2679.051 ]\n",
      " [2679.6277]\n",
      " [2680.2178]\n",
      " [2680.869 ]\n",
      " [2681.4487]\n",
      " [2682.0337]\n",
      " [2682.6494]\n",
      " [2683.2354]\n",
      " [2683.8186]\n",
      " [2684.3826]\n",
      " [2685.0186]\n",
      " [2685.6033]\n",
      " [2686.2234]\n",
      " [2686.767 ]\n",
      " [2687.3987]\n",
      " [2687.9824]\n",
      " [2688.5886]\n",
      " [2689.1963]\n",
      " [2689.744 ]\n",
      " [2690.3738]\n",
      " [2690.9338]\n",
      " [2691.5864]\n",
      " [2692.1355]\n",
      " [2692.7166]\n",
      " [2693.3608]\n",
      " [2693.932 ]\n",
      " [2694.5015]\n",
      " [2695.0984]\n",
      " [2695.6934]\n",
      " [2696.3333]\n",
      " [2696.9075]\n",
      " [2697.4763]\n",
      " [2698.1206]\n",
      " [2698.6924]\n",
      " [2699.2559]\n",
      " [2699.8582]\n",
      " [2700.4873]\n",
      " [2701.0723]\n",
      " [2701.6902]\n",
      " [2702.2544]\n",
      " [2702.8801]\n",
      " [2703.4258]\n",
      " [2704.0571]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2696.1567]\n",
      " [2691.1257]\n",
      " [2665.402 ]\n",
      " [2665.997 ]\n",
      " [2675.4973]\n",
      " [2653.8013]\n",
      " [2650.8694]\n",
      " [2694.3408]\n",
      " [2652.0593]\n",
      " [2656.1812]\n",
      " [2695.3506]\n",
      " [2695.9456]\n",
      " [2696.547 ]\n",
      " [2694.4363]\n",
      " [2697.8887]\n",
      " [2699.4548]\n",
      " [2705.676 ]\n",
      " [2701.0278]\n",
      " [2700.1104]\n",
      " [2698.9646]\n",
      " [2701.3003]\n",
      " [2703.4077]\n",
      " [2663.9155]\n",
      " [2709.8406]\n",
      " [2661.5786]\n",
      " [2681.1538]\n",
      " [2704.8699]\n",
      " [2712.8806]\n",
      " [2709.2683]\n",
      " [2707.43  ]\n",
      " [2682.061 ]\n",
      " [2665.7434]\n",
      " [2706.699 ]\n",
      " [2685.9136]\n",
      " [2710.4048]\n",
      " [2711.7368]\n",
      " [2711.5945]\n",
      " [2711.5728]\n",
      " [2719.425 ]\n",
      " [2713.7341]\n",
      " [2720.615 ]\n",
      " [2713.8008]\n",
      " [2698.1057]\n",
      " [2716.4966]\n",
      " [2677.0044]\n",
      " [2714.4333]\n",
      " [2717.5442]\n",
      " [2692.175 ]\n",
      " [2694.838 ]\n",
      " [2693.365 ]\n",
      " [2716.45  ]\n",
      " [2721.1445]\n",
      " [2717.64  ]\n",
      " [2724.1423]\n",
      " [2724.737 ]\n",
      " [2723.5242]\n",
      " [2724.1191]\n",
      " [2707.03  ]\n",
      " [2724.6836]\n",
      " [2725.2786]\n",
      " [2725.808 ]\n",
      " [2723.9526]\n",
      " [2713.1238]\n",
      " [2734.299 ]\n",
      " [2724.779 ]\n",
      " [2735.489 ]\n",
      " [2730.1807]\n",
      " [2730.3928]\n",
      " [2716.6936]\n",
      " [2733.6614]\n",
      " [2717.8835]\n",
      " [2728.9436]\n",
      " [2719.0735]\n",
      " [2734.7593]\n",
      " [2734.1375]\n",
      " [2735.4233]\n",
      " [2736.13  ]\n",
      " [2696.638 ]\n",
      " [2719.5242]\n",
      " [2743.1582]\n",
      " [2744.4133]\n",
      " [2721.309 ]\n",
      " [2699.6128]\n",
      " [2738.7825]\n",
      " [2741.3037]\n",
      " [2714.7834]\n",
      " [2740.5737]\n",
      " [2741.1687]\n",
      " [2725.4736]\n",
      " [2749.1077]\n",
      " [2744.8735]\n",
      " [2750.2976]\n",
      " [2746.0635]\n",
      " [2746.1326]\n",
      " [2745.3333]\n",
      " [2732.7576]\n",
      " [2746.5168]\n",
      " [2747.8215]\n",
      " [2747.7068]\n",
      " [2732.018 ]\n",
      " [2725.7756]\n",
      " [2749.65  ]\n",
      " [2747.3875]\n",
      " [2725.4927]\n",
      " [2758.6921]\n",
      " [2753.0012]\n",
      " [2749.7673]\n",
      " [2714.4866]\n",
      " [2753.815 ]\n",
      " [2731.1301]\n",
      " [2755.9758]\n",
      " [2755.4475]\n",
      " [2756.0361]\n",
      " [2740.3477]\n",
      " [2757.3843]\n",
      " [2757.8274]\n",
      " [2760.3423]\n",
      " [2759.1694]\n",
      " [2721.0312]\n",
      " [2757.5017]\n",
      " [2762.7222]\n",
      " [2745.1072]\n",
      " [2748.821 ]\n",
      " [2720.4792]\n",
      " [2764.5762]\n",
      " [2763.777 ]\n",
      " [2771.781 ]\n",
      " [2763.2197]\n",
      " [2740.3665]\n",
      " [2767.551 ]\n",
      " [2767.5205]\n",
      " [2768.47  ]\n",
      " [2725.834 ]\n",
      " [2752.2466]\n",
      " [2766.426 ]\n",
      " [2770.8499]\n",
      " [2757.1506]\n",
      " [2772.3105]\n",
      " [2729.4036]\n",
      " [2772.1064]\n",
      " [2734.12  ]\n",
      " [2760.1252]\n",
      " [2775.397 ]\n",
      " [2732.3784]\n",
      " [2776.4753]\n",
      " [2752.5486]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2705.5752]\n",
      " [2709.64  ]\n",
      " [2727.8184]\n",
      " [2724.3206]\n",
      " [2731.1018]\n",
      " [2729.6033]\n",
      " [2732.2917]\n",
      " [2716.8596]\n",
      " [2713.8047]\n",
      " [2687.329 ]\n",
      " [2714.9946]\n",
      " [2698.7827]\n",
      " [2718.5369]\n",
      " [2694.8948]\n",
      " [2733.2275]\n",
      " [2713.9763]\n",
      " [2714.7214]\n",
      " [2715.6895]\n",
      " [2733.1384]\n",
      " [2729.1   ]\n",
      " [2717.1013]\n",
      " [2731.6714]\n",
      " [2705.3271]\n",
      " [2726.9712]\n",
      " [2696.2534]\n",
      " [2741.9387]\n",
      " [2726.8665]\n",
      " [2742.8398]\n",
      " [2734.4546]\n",
      " [2728.477 ]\n",
      " [2710.087 ]\n",
      " [2723.5286]\n",
      " [2738.9543]\n",
      " [2744.3647]\n",
      " [2725.4307]\n",
      " [2743.2527]\n",
      " [2726.9937]\n",
      " [2727.2156]\n",
      " [2746.3901]\n",
      " [2734.6008]\n",
      " [2735.1958]\n",
      " [2743.5703]\n",
      " [2744.1653]\n",
      " [2738.8704]\n",
      " [2742.4478]\n",
      " [2727.1406]\n",
      " [2732.5703]\n",
      " [2747.8792]\n",
      " [2728.5935]\n",
      " [2745.4224]\n",
      " [2756.3762]\n",
      " [2748.1387]\n",
      " [2724.4019]\n",
      " [2756.4307]\n",
      " [2749.7524]\n",
      " [2751.9   ]\n",
      " [2758.2158]\n",
      " [2748.275 ]\n",
      " [2759.2388]\n",
      " [2740.1873]\n",
      " [2735.7332]\n",
      " [2755.4695]\n",
      " [2736.923 ]\n",
      " [2755.1074]\n",
      " [2764.7056]\n",
      " [2761.2078]\n",
      " [2750.4907]\n",
      " [2753.1492]\n",
      " [2745.5417]\n",
      " [2760.968 ]\n",
      " [2728.8074]\n",
      " [2764.7776]\n",
      " [2769.4653]\n",
      " [2772.1536]\n",
      " [2766.456 ]\n",
      " [2757.3167]\n",
      " [2737.4548]\n",
      " [2762.0813]\n",
      " [2751.4915]\n",
      " [2771.733 ]\n",
      " [2760.8835]\n",
      " [2736.4531]\n",
      " [2763.1487]\n",
      " [2773.1636]\n",
      " [2773.7583]\n",
      " [2763.7964]\n",
      " [2767.754 ]\n",
      " [2765.0483]\n",
      " [2765.6433]\n",
      " [2769.2207]\n",
      " [2735.5205]\n",
      " [2770.7285]\n",
      " [2784.4766]\n",
      " [2773.1267]\n",
      " [2768.6208]\n",
      " [2756.5564]\n",
      " [2779.6514]\n",
      " [2781.6125]\n",
      " [2782.088 ]\n",
      " [2763.9524]\n",
      " [2747.7573]\n",
      " [2765.1753]\n",
      " [2765.7703]\n",
      " [2772.504 ]\n",
      " [2784.4111]\n",
      " [2744.4448]\n",
      " [2782.2424]\n",
      " [2755.8984]\n",
      " [2776.9502]\n",
      " [2781.1199]\n",
      " [2792.0737]\n",
      " [2788.3027]\n",
      " [2795.3572]\n",
      " [2779.9248]\n",
      " [2772.8772]\n",
      " [2782.7822]\n",
      " [2796.7864]\n",
      " [2761.8481]\n",
      " [2784.5671]\n",
      " [2775.8518]\n",
      " [2798.0232]\n",
      " [2784.6846]\n",
      " [2783.808 ]\n",
      " [2800.2444]\n",
      " [2755.749 ]\n",
      " [2802.1409]\n",
      " [2768.4287]\n",
      " [2793.3552]\n",
      " [2785.1992]\n",
      " [2768.9875]\n",
      " [2788.5679]\n",
      " [2766.201 ]\n",
      " [2800.7969]\n",
      " [2796.9248]\n",
      " [2799.64  ]\n",
      " [2785.3708]\n",
      " [2773.152 ]\n",
      " [2786.5938]\n",
      " [2806.0059]\n",
      " [2805.2346]\n",
      " [2796.5808]\n",
      " [2797.1758]\n",
      " [2806.7466]\n",
      " [2804.9949]\n",
      " [2809.5754]\n",
      " [2806.1848]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2550.6394]\n",
      " [2580.0308]\n",
      " [2580.3796]\n",
      " [2569.594 ]\n",
      " [2580.6992]\n",
      " [2581.2942]\n",
      " [2588.8735]\n",
      " [2571.9739]\n",
      " [2558.0625]\n",
      " [2565.646 ]\n",
      " [2573.7585]\n",
      " [2566.3074]\n",
      " [2557.779 ]\n",
      " [2544.262 ]\n",
      " [2594.1968]\n",
      " [2596.3875]\n",
      " [2597.4185]\n",
      " [2546.6418]\n",
      " [2594.448 ]\n",
      " [2547.8318]\n",
      " [2599.7983]\n",
      " [2572.7854]\n",
      " [2542.4844]\n",
      " [2593.1199]\n",
      " [2601.7422]\n",
      " [2594.3096]\n",
      " [2544.8643]\n",
      " [2594.3833]\n",
      " [2553.1863]\n",
      " [2595.573 ]\n",
      " [2596.168 ]\n",
      " [2569.0833]\n",
      " [2604.3423]\n",
      " [2603.3723]\n",
      " [2598.5479]\n",
      " [2608.2866]\n",
      " [2582.0303]\n",
      " [2609.4766]\n",
      " [2610.0715]\n",
      " [2607.877 ]\n",
      " [2610.702 ]\n",
      " [2575.0327]\n",
      " [2603.3076]\n",
      " [2585.8745]\n",
      " [2609.917 ]\n",
      " [2605.9626]\n",
      " [2614.831 ]\n",
      " [2588.5747]\n",
      " [2614.4253]\n",
      " [2608.3425]\n",
      " [2617.647 ]\n",
      " [2617.2463]\n",
      " [2560.3333]\n",
      " [2584.8354]\n",
      " [2615.8665]\n",
      " [2611.9124]\n",
      " [2583.957 ]\n",
      " [2613.102 ]\n",
      " [2620.3748]\n",
      " [2607.4312]\n",
      " [2608.0261]\n",
      " [2572.8198]\n",
      " [2609.2158]\n",
      " [2604.2363]\n",
      " [2604.8313]\n",
      " [2618.108 ]\n",
      " [2575.7947]\n",
      " [2618.1814]\n",
      " [2619.8928]\n",
      " [2601.664 ]\n",
      " [2620.8367]\n",
      " [2630.141 ]\n",
      " [2615.1655]\n",
      " [2622.8674]\n",
      " [2631.4897]\n",
      " [2632.521 ]\n",
      " [2623.536 ]\n",
      " [2606.103 ]\n",
      " [2633.3103]\n",
      " [2606.7644]\n",
      " [2634.5002]\n",
      " [2612.6365]\n",
      " [2636.2495]\n",
      " [2637.2808]\n",
      " [2629.166 ]\n",
      " [2615.016 ]\n",
      " [2618.9753]\n",
      " [2616.206 ]\n",
      " [2612.6475]\n",
      " [2620.76  ]\n",
      " [2625.8748]\n",
      " [2614.753 ]\n",
      " [2615.0273]\n",
      " [2634.7666]\n",
      " [2615.6887]\n",
      " [2628.8494]\n",
      " [2636.3054]\n",
      " [2622.1558]\n",
      " [2646.205 ]\n",
      " [2638.0903]\n",
      " [2637.815 ]\n",
      " [2613.393 ]\n",
      " [2620.4482]\n",
      " [2648.184 ]\n",
      " [2634.204 ]\n",
      " [2650.3696]\n",
      " [2623.6772]\n",
      " [2623.9517]\n",
      " [2593.6506]\n",
      " [2594.2456]\n",
      " [2632.1995]\n",
      " [2626.6519]\n",
      " [2634.444 ]\n",
      " [2596.6255]\n",
      " [2597.2205]\n",
      " [2635.174 ]\n",
      " [2647.3342]\n",
      " [2630.2217]\n",
      " [2630.496 ]\n",
      " [2658.6992]\n",
      " [2643.7234]\n",
      " [2622.6292]\n",
      " [2650.904 ]\n",
      " [2659.0469]\n",
      " [2657.5134]\n",
      " [2634.1323]\n",
      " [2639.4094]\n",
      " [2647.888 ]\n",
      " [2648.483 ]\n",
      " [2637.0408]\n",
      " [2665.2437]\n",
      " [2645.7483]\n",
      " [2639.146 ]\n",
      " [2646.9382]\n",
      " [2616.2515]\n",
      " [2630.9585]\n",
      " [2641.526 ]\n",
      " [2668.9722]\n",
      " [2648.8582]\n",
      " [2670.5981]\n",
      " [2662.4834]\n",
      " [2613.2842]\n",
      " [2651.238 ]\n",
      " [2668.8174]\n",
      " [2670.9775]\n",
      " [2664.588 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2476.6904]\n",
      " [2478.7014]\n",
      " [2480.787 ]\n",
      " [2484.6582]\n",
      " [2478.9827]\n",
      " [2485.7944]\n",
      " [2480.054 ]\n",
      " [2480.7217]\n",
      " [2485.3713]\n",
      " [2484.096 ]\n",
      " [2483.3274]\n",
      " [2486.7136]\n",
      " [2489.8965]\n",
      " [2490.4912]\n",
      " [2484.9429]\n",
      " [2487.8281]\n",
      " [2486.626 ]\n",
      " [2491.9197]\n",
      " [2487.5   ]\n",
      " [2488.1875]\n",
      " [2494.5044]\n",
      " [2492.0156]\n",
      " [2492.3103]\n",
      " [2497.6753]\n",
      " [2491.3857]\n",
      " [2491.999 ]\n",
      " [2492.568 ]\n",
      " [2496.233 ]\n",
      " [2493.384 ]\n",
      " [2494.2153]\n",
      " [2494.3132]\n",
      " [2495.5503]\n",
      " [2496.4163]\n",
      " [2501.1355]\n",
      " [2504.5547]\n",
      " [2497.9656]\n",
      " [2498.1436]\n",
      " [2499.083 ]\n",
      " [2502.2056]\n",
      " [2499.639 ]\n",
      " [2506.5552]\n",
      " [2508.1343]\n",
      " [2506.49  ]\n",
      " [2506.9072]\n",
      " [2510.2395]\n",
      " [2505.6768]\n",
      " [2504.3105]\n",
      " [2505.1052]\n",
      " [2508.727 ]\n",
      " [2507.0938]\n",
      " [2506.6838]\n",
      " [2507.197 ]\n",
      " [2508.92  ]\n",
      " [2509.1633]\n",
      " [2515.5696]\n",
      " [2515.542 ]\n",
      " [2513.2344]\n",
      " [2513.5903]\n",
      " [2511.2327]\n",
      " [2511.5278]\n",
      " [2512.5518]\n",
      " [2515.7397]\n",
      " [2513.9863]\n",
      " [2515.423 ]\n",
      " [2515.1467]\n",
      " [2516.1394]\n",
      " [2516.3926]\n",
      " [2516.8013]\n",
      " [2517.4885]\n",
      " [2519.0435]\n",
      " [2520.9866]\n",
      " [2525.983 ]\n",
      " [2519.6243]\n",
      " [2520.393 ]\n",
      " [2523.5225]\n",
      " [2522.7095]\n",
      " [2521.9868]\n",
      " [2523.3855]\n",
      " [2523.8125]\n",
      " [2523.9556]\n",
      " [2524.7217]\n",
      " [2525.2905]\n",
      " [2526.8647]\n",
      " [2526.172 ]\n",
      " [2533.9553]\n",
      " [2528.3098]\n",
      " [2530.3162]\n",
      " [2533.0854]\n",
      " [2529.6162]\n",
      " [2533.774 ]\n",
      " [2529.9817]\n",
      " [2531.1726]\n",
      " [2531.69  ]\n",
      " [2532.1587]\n",
      " [2538.5308]\n",
      " [2533.5383]\n",
      " [2534.6895]\n",
      " [2534.8528]\n",
      " [2535.2483]\n",
      " [2540.4026]\n",
      " [2536.3215]\n",
      " [2537.8918]\n",
      " [2537.628 ]\n",
      " [2539.3167]\n",
      " [2540.5254]\n",
      " [2542.0676]\n",
      " [2546.8064]\n",
      " [2541.6519]\n",
      " [2542.6492]\n",
      " [2543.5583]\n",
      " [2541.8706]\n",
      " [2543.8413]\n",
      " [2543.192 ]\n",
      " [2544.0566]\n",
      " [2549.0166]\n",
      " [2546.4563]\n",
      " [2552.994 ]\n",
      " [2546.0352]\n",
      " [2547.1472]\n",
      " [2547.2642]\n",
      " [2549.7888]\n",
      " [2549.1147]\n",
      " [2549.4375]\n",
      " [2553.0964]\n",
      " [2551.513 ]\n",
      " [2558.1104]\n",
      " [2552.071 ]\n",
      " [2554.2139]\n",
      " [2555.058 ]\n",
      " [2556.1082]\n",
      " [2554.8928]\n",
      " [2554.876 ]\n",
      " [2555.2246]\n",
      " [2556.2659]\n",
      " [2556.4292]\n",
      " [2557.171 ]\n",
      " [2558.182 ]\n",
      " [2565.25  ]\n",
      " [2561.6255]\n",
      " [2560.5647]\n",
      " [2567.2852]\n",
      " [2560.7148]\n",
      " [2565.6753]\n",
      " [2563.1035]\n",
      " [2562.8699]\n",
      " [2563.1428]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2577.335 ]\n",
      " [2602.9834]\n",
      " [2574.79  ]\n",
      " [2600.4092]\n",
      " [2597.567 ]\n",
      " [2543.0386]\n",
      " [2604.7256]\n",
      " [2582.5574]\n",
      " [2583.341 ]\n",
      " [2601.1748]\n",
      " [2602.9585]\n",
      " [2586.1382]\n",
      " [2608.2954]\n",
      " [2597.7954]\n",
      " [2589.8728]\n",
      " [2598.9854]\n",
      " [2601.0093]\n",
      " [2589.3977]\n",
      " [2592.5774]\n",
      " [2551.368 ]\n",
      " [2596.7117]\n",
      " [2558.1343]\n",
      " [2558.7292]\n",
      " [2612.547 ]\n",
      " [2580.4985]\n",
      " [2610.694 ]\n",
      " [2602.094 ]\n",
      " [2590.1184]\n",
      " [2598.2021]\n",
      " [2568.5151]\n",
      " [2604.7246]\n",
      " [2601.8992]\n",
      " [2605.6636]\n",
      " [2618.4966]\n",
      " [2622.617 ]\n",
      " [2607.6992]\n",
      " [2620.9368]\n",
      " [2603.5566]\n",
      " [2624.3208]\n",
      " [2601.7844]\n",
      " [2623.3167]\n",
      " [2626.1057]\n",
      " [2626.7007]\n",
      " [2621.4033]\n",
      " [2604.759 ]\n",
      " [2610.2285]\n",
      " [2623.1882]\n",
      " [2609.5063]\n",
      " [2605.8928]\n",
      " [2608.5886]\n",
      " [2634.0796]\n",
      " [2609.6262]\n",
      " [2609.091 ]\n",
      " [2596.6116]\n",
      " [2572.1914]\n",
      " [2614.2659]\n",
      " [2633.8423]\n",
      " [2579.5527]\n",
      " [2612.661 ]\n",
      " [2630.9226]\n",
      " [2595.4875]\n",
      " [2631.6382]\n",
      " [2623.5122]\n",
      " [2627.5432]\n",
      " [2639.7898]\n",
      " [2616.8254]\n",
      " [2644.2014]\n",
      " [2619.1455]\n",
      " [2593.4756]\n",
      " [2619.4446]\n",
      " [2631.708 ]\n",
      " [2643.9543]\n",
      " [2629.713 ]\n",
      " [2617.0317]\n",
      " [2628.1714]\n",
      " [2634.6829]\n",
      " [2636.7065]\n",
      " [2624.2043]\n",
      " [2606.1968]\n",
      " [2626.5952]\n",
      " [2641.9966]\n",
      " [2601.21  ]\n",
      " [2594.4265]\n",
      " [2615.6008]\n",
      " [2602.9949]\n",
      " [2616.7908]\n",
      " [2634.6216]\n",
      " [2630.3425]\n",
      " [2647.702 ]\n",
      " [2655.0615]\n",
      " [2630.8809]\n",
      " [2636.009 ]\n",
      " [2636.2793]\n",
      " [2646.8208]\n",
      " [2640.7385]\n",
      " [2652.341 ]\n",
      " [2643.741 ]\n",
      " [2644.587 ]\n",
      " [2643.1184]\n",
      " [2637.4817]\n",
      " [2645.159 ]\n",
      " [2611.352 ]\n",
      " [2647.3108]\n",
      " [2659.9048]\n",
      " [2614.894 ]\n",
      " [2663.6265]\n",
      " [2661.002 ]\n",
      " [2665.3728]\n",
      " [2647.4946]\n",
      " [2643.2424]\n",
      " [2642.78  ]\n",
      " [2640.095 ]\n",
      " [2640.2349]\n",
      " [2618.4915]\n",
      " [2632.9038]\n",
      " [2659.91  ]\n",
      " [2650.883 ]\n",
      " [2649.2031]\n",
      " [2648.5974]\n",
      " [2675.1316]\n",
      " [2622.6562]\n",
      " [2650.571 ]\n",
      " [2646.6394]\n",
      " [2675.29  ]\n",
      " [2633.5647]\n",
      " [2627.388 ]\n",
      " [2677.353 ]\n",
      " [2659.704 ]\n",
      " [2671.3413]\n",
      " [2660.894 ]\n",
      " [2664.2202]\n",
      " [2637.7295]\n",
      " [2677.1587]\n",
      " [2657.5217]\n",
      " [2674.9111]\n",
      " [2679.182 ]\n",
      " [2659.3064]\n",
      " [2671.57  ]\n",
      " [2660.4963]\n",
      " [2647.7778]\n",
      " [2688.2283]\n",
      " [2668.0334]\n",
      " [2683.3467]\n",
      " [2683.0151]\n",
      " [2664.2546]\n",
      " [2664.4219]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2549.631 ]\n",
      " [2567.6606]\n",
      " [2575.56  ]\n",
      " [2569.1572]\n",
      " [2549.7087]\n",
      " [2574.766 ]\n",
      " [2568.3574]\n",
      " [2575.8462]\n",
      " [2579.13  ]\n",
      " [2574.6128]\n",
      " [2539.18  ]\n",
      " [2571.3323]\n",
      " [2584.2188]\n",
      " [2568.197 ]\n",
      " [2549.0288]\n",
      " [2585.3018]\n",
      " [2552.318 ]\n",
      " [2587.2593]\n",
      " [2575.4968]\n",
      " [2554.3406]\n",
      " [2581.1572]\n",
      " [2559.823 ]\n",
      " [2570.2031]\n",
      " [2542.5422]\n",
      " [2547.713 ]\n",
      " [2581.9802]\n",
      " [2587.1504]\n",
      " [2586.8115]\n",
      " [2591.029 ]\n",
      " [2560.29  ]\n",
      " [2588.805 ]\n",
      " [2585.816 ]\n",
      " [2587.4092]\n",
      " [2591.4248]\n",
      " [2575.8767]\n",
      " [2552.505 ]\n",
      " [2578.5325]\n",
      " [2564.8123]\n",
      " [2589.7146]\n",
      " [2590.5757]\n",
      " [2600.9434]\n",
      " [2593.6514]\n",
      " [2553.8464]\n",
      " [2590.3708]\n",
      " [2603.2573]\n",
      " [2597.5208]\n",
      " [2571.721 ]\n",
      " [2602.333 ]\n",
      " [2604.9353]\n",
      " [2591.4016]\n",
      " [2604.2595]\n",
      " [2604.8545]\n",
      " [2600.1958]\n",
      " [2566.9744]\n",
      " [2603.0837]\n",
      " [2607.2344]\n",
      " [2601.1272]\n",
      " [2581.2415]\n",
      " [2610.885 ]\n",
      " [2601.854 ]\n",
      " [2576.3967]\n",
      " [2608.0835]\n",
      " [2603.9531]\n",
      " [2608.2297]\n",
      " [2605.1838]\n",
      " [2609.6282]\n",
      " [2608.5254]\n",
      " [2616.6877]\n",
      " [2612.1382]\n",
      " [2608.8616]\n",
      " [2602.1096]\n",
      " [2618.1885]\n",
      " [2618.5305]\n",
      " [2590.7607]\n",
      " [2599.675 ]\n",
      " [2618.992 ]\n",
      " [2600.865 ]\n",
      " [2620.3235]\n",
      " [2593.7354]\n",
      " [2602.6497]\n",
      " [2614.662 ]\n",
      " [2625.017 ]\n",
      " [2624.4631]\n",
      " [2592.4177]\n",
      " [2581.6577]\n",
      " [2584.0054]\n",
      " [2582.8477]\n",
      " [2607.4094]\n",
      " [2614.6047]\n",
      " [2595.9873]\n",
      " [2621.3557]\n",
      " [2594.8403]\n",
      " [2623.1067]\n",
      " [2590.7725]\n",
      " [2603.2546]\n",
      " [2627.2686]\n",
      " [2627.8633]\n",
      " [2624.7764]\n",
      " [2623.0933]\n",
      " [2594.3423]\n",
      " [2602.2944]\n",
      " [2634.6023]\n",
      " [2621.1482]\n",
      " [2638.3596]\n",
      " [2597.317 ]\n",
      " [2629.5361]\n",
      " [2612.6965]\n",
      " [2596.8906]\n",
      " [2629.043 ]\n",
      " [2640.5266]\n",
      " [2608.4814]\n",
      " [2630.8276]\n",
      " [2606.8174]\n",
      " [2643.6074]\n",
      " [2644.9697]\n",
      " [2635.1714]\n",
      " [2624.663 ]\n",
      " [2609.792 ]\n",
      " [2603.435 ]\n",
      " [2642.481 ]\n",
      " [2636.1824]\n",
      " [2641.248 ]\n",
      " [2639.957 ]\n",
      " [2650.0051]\n",
      " [2640.526 ]\n",
      " [2639.1572]\n",
      " [2651.3418]\n",
      " [2643.369 ]\n",
      " [2619.1907]\n",
      " [2643.815 ]\n",
      " [2651.856 ]\n",
      " [2645.005 ]\n",
      " [2643.3218]\n",
      " [2634.7773]\n",
      " [2622.523 ]\n",
      " [2657.1445]\n",
      " [2652.5952]\n",
      " [2616.9504]\n",
      " [2658.4812]\n",
      " [2654.4902]\n",
      " [2660.3728]\n",
      " [2631.2173]\n",
      " [2646.7327]\n",
      " [2616.7603]\n",
      " [2650.4614]\n",
      " [2660.7803]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2605.9753]\n",
      " [2599.2043]\n",
      " [2602.502 ]\n",
      " [2596.5107]\n",
      " [2616.099 ]\n",
      " [2605.1545]\n",
      " [2614.131 ]\n",
      " [2620.2654]\n",
      " [2602.144 ]\n",
      " [2619.194 ]\n",
      " [2621.121 ]\n",
      " [2612.52  ]\n",
      " [2609.3193]\n",
      " [2622.906 ]\n",
      " [2623.501 ]\n",
      " [2619.4858]\n",
      " [2622.565 ]\n",
      " [2627.7   ]\n",
      " [2621.9688]\n",
      " [2621.8655]\n",
      " [2623.1587]\n",
      " [2613.806 ]\n",
      " [2626.9285]\n",
      " [2625.4832]\n",
      " [2624.9944]\n",
      " [2630.0454]\n",
      " [2631.5696]\n",
      " [2614.673 ]\n",
      " [2634.2446]\n",
      " [2618.5657]\n",
      " [2628.564 ]\n",
      " [2632.163 ]\n",
      " [2632.444 ]\n",
      " [2618.243 ]\n",
      " [2634.847 ]\n",
      " [2622.1355]\n",
      " [2635.1377]\n",
      " [2636.6316]\n",
      " [2623.9202]\n",
      " [2613.4348]\n",
      " [2639.899 ]\n",
      " [2638.1123]\n",
      " [2623.5974]\n",
      " [2637.5173]\n",
      " [2632.1533]\n",
      " [2641.9448]\n",
      " [2625.9773]\n",
      " [2644.0637]\n",
      " [2625.9424]\n",
      " [2643.2573]\n",
      " [2641.682 ]\n",
      " [2646.1208]\n",
      " [2641.3396]\n",
      " [2646.7043]\n",
      " [2643.3875]\n",
      " [2644.6565]\n",
      " [2644.033 ]\n",
      " [2644.4739]\n",
      " [2636.6873]\n",
      " [2646.362 ]\n",
      " [2634.3066]\n",
      " [2650.397 ]\n",
      " [2654.473 ]\n",
      " [2655.0679]\n",
      " [2635.4614]\n",
      " [2649.2336]\n",
      " [2655.368 ]\n",
      " [2654.4802]\n",
      " [2641.7688]\n",
      " [2654.8914]\n",
      " [2655.7515]\n",
      " [2653.5017]\n",
      " [2656.2422]\n",
      " [2644.7437]\n",
      " [2654.4287]\n",
      " [2655.183 ]\n",
      " [2659.3213]\n",
      " [2660.9834]\n",
      " [2658.2058]\n",
      " [2660.0474]\n",
      " [2661.4358]\n",
      " [2664.2922]\n",
      " [2659.348 ]\n",
      " [2660.6409]\n",
      " [2666.0771]\n",
      " [2668.157 ]\n",
      " [2652.478 ]\n",
      " [2649.1455]\n",
      " [2666.0752]\n",
      " [2654.263 ]\n",
      " [2671.1318]\n",
      " [2669.3127]\n",
      " [2670.8367]\n",
      " [2666.5906]\n",
      " [2672.0266]\n",
      " [2667.236 ]\n",
      " [2654.5   ]\n",
      " [2669.51  ]\n",
      " [2659.6174]\n",
      " [2673.5188]\n",
      " [2649.7273]\n",
      " [2671.89  ]\n",
      " [2658.0698]\n",
      " [2663.4602]\n",
      " [2673.135 ]\n",
      " [2659.8545]\n",
      " [2676.7847]\n",
      " [2679.4385]\n",
      " [2677.301 ]\n",
      " [2667.03  ]\n",
      " [2667.625 ]\n",
      " [2679.7593]\n",
      " [2678.4343]\n",
      " [2679.029 ]\n",
      " [2679.0847]\n",
      " [2684.5205]\n",
      " [2682.8542]\n",
      " [2685.7104]\n",
      " [2684.0442]\n",
      " [2676.7754]\n",
      " [2689.0503]\n",
      " [2682.3916]\n",
      " [2685.6304]\n",
      " [2687.7979]\n",
      " [2684.49  ]\n",
      " [2671.754 ]\n",
      " [2688.0103]\n",
      " [2690.1777]\n",
      " [2688.0881]\n",
      " [2688.5486]\n",
      " [2678.656 ]\n",
      " [2680.119 ]\n",
      " [2694.3123]\n",
      " [2676.5132]\n",
      " [2690.4395]\n",
      " [2677.7031]\n",
      " [2682.2258]\n",
      " [2676.2346]\n",
      " [2695.8232]\n",
      " [2694.4978]\n",
      " [2694.0093]\n",
      " [2701.4746]\n",
      " [2697.5295]\n",
      " [2696.3381]\n",
      " [2686.9854]\n",
      " [2700.373 ]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2622.1484]\n",
      " [2623.1528]\n",
      " [2621.5127]\n",
      " [2623.0222]\n",
      " [2622.789 ]\n",
      " [2625.1143]\n",
      " [2625.823 ]\n",
      " [2623.4597]\n",
      " [2627.041 ]\n",
      " [2627.8416]\n",
      " [2628.089 ]\n",
      " [2608.3499]\n",
      " [2626.8633]\n",
      " [2627.0295]\n",
      " [2629.0886]\n",
      " [2598.3706]\n",
      " [2628.3293]\n",
      " [2613.8975]\n",
      " [2615.8984]\n",
      " [2630.476 ]\n",
      " [2634.5479]\n",
      " [2631.011 ]\n",
      " [2634.7886]\n",
      " [2607.087 ]\n",
      " [2620.626 ]\n",
      " [2635.86  ]\n",
      " [2634.5706]\n",
      " [2635.1008]\n",
      " [2634.5527]\n",
      " [2612.937 ]\n",
      " [2635.667 ]\n",
      " [2639.43  ]\n",
      " [2637.9438]\n",
      " [2631.8745]\n",
      " [2617.5942]\n",
      " [2640.4106]\n",
      " [2613.3228]\n",
      " [2641.185 ]\n",
      " [2633.435 ]\n",
      " [2623.9333]\n",
      " [2642.4233]\n",
      " [2639.5125]\n",
      " [2646.6804]\n",
      " [2639.2754]\n",
      " [2639.2866]\n",
      " [2649.4614]\n",
      " [2647.0562]\n",
      " [2647.5503]\n",
      " [2630.3633]\n",
      " [2648.7053]\n",
      " [2651.602 ]\n",
      " [2648.1616]\n",
      " [2648.832 ]\n",
      " [2651.0503]\n",
      " [2650.2798]\n",
      " [2650.6714]\n",
      " [2651.1362]\n",
      " [2655.6562]\n",
      " [2654.0315]\n",
      " [2657.9385]\n",
      " [2654.7988]\n",
      " [2632.4685]\n",
      " [2658.6846]\n",
      " [2657.1704]\n",
      " [2656.3105]\n",
      " [2628.5088]\n",
      " [2661.1797]\n",
      " [2662.1924]\n",
      " [2663.5737]\n",
      " [2663.888 ]\n",
      " [2649.4033]\n",
      " [2661.5369]\n",
      " [2661.462 ]\n",
      " [2661.2505]\n",
      " [2658.8818]\n",
      " [2651.7263]\n",
      " [2664.7693]\n",
      " [2653.568 ]\n",
      " [2659.1113]\n",
      " [2665.8118]\n",
      " [2651.3794]\n",
      " [2669.6545]\n",
      " [2642.6636]\n",
      " [2661.644 ]\n",
      " [2664.8315]\n",
      " [2673.22  ]\n",
      " [2645.1997]\n",
      " [2672.379 ]\n",
      " [2672.5068]\n",
      " [2676.0676]\n",
      " [2672.171 ]\n",
      " [2666.4036]\n",
      " [2672.8855]\n",
      " [2652.6963]\n",
      " [2677.6252]\n",
      " [2667.3474]\n",
      " [2678.8152]\n",
      " [2675.5293]\n",
      " [2677.0984]\n",
      " [2658.141 ]\n",
      " [2660.3767]\n",
      " [2669.7026]\n",
      " [2682.745 ]\n",
      " [2682.3528]\n",
      " [2683.6191]\n",
      " [2665.1707]\n",
      " [2683.8816]\n",
      " [2664.3904]\n",
      " [2685.2415]\n",
      " [2687.2185]\n",
      " [2684.431 ]\n",
      " [2675.652 ]\n",
      " [2660.5122]\n",
      " [2686.817 ]\n",
      " [2689.6792]\n",
      " [2691.2559]\n",
      " [2679.6187]\n",
      " [2692.7266]\n",
      " [2660.0415]\n",
      " [2693.5625]\n",
      " [2667.0781]\n",
      " [2690.904 ]\n",
      " [2693.556 ]\n",
      " [2691.151 ]\n",
      " [2669.458 ]\n",
      " [2695.7876]\n",
      " [2693.8616]\n",
      " [2686.0273]\n",
      " [2689.8464]\n",
      " [2696.2734]\n",
      " [2669.2485]\n",
      " [2697.5234]\n",
      " [2700.2336]\n",
      " [2697.7156]\n",
      " [2699.311 ]\n",
      " [2689.931 ]\n",
      " [2681.1748]\n",
      " [2690.4326]\n",
      " [2702.261 ]\n",
      " [2703.515 ]\n",
      " [2704.6785]\n",
      " [2696.9124]\n",
      " [2706.1833]\n",
      " [2706.3162]\n",
      " [2698.3784]\n",
      " [2706.6777]]\n",
      "number of patient data is:  146\n",
      "pred_fvc is:  [[2635.5112]\n",
      " [2617.8735]\n",
      " [2620.178 ]\n",
      " [2636.3037]\n",
      " [2614.6543]\n",
      " [2612.4548]\n",
      " [2595.8938]\n",
      " [2615.3616]\n",
      " [2631.8203]\n",
      " [2642.1382]\n",
      " [2629.4463]\n",
      " [2623.823 ]\n",
      " [2594.98  ]\n",
      " [2620.0088]\n",
      " [2643.3157]\n",
      " [2639.9045]\n",
      " [2620.118 ]\n",
      " [2635.1936]\n",
      " [2629.6973]\n",
      " [2647.1926]\n",
      " [2638.8174]\n",
      " [2598.513 ]\n",
      " [2619.8867]\n",
      " [2606.008 ]\n",
      " [2649.2651]\n",
      " [2632.1523]\n",
      " [2652.7275]\n",
      " [2646.5728]\n",
      " [2652.0151]\n",
      " [2636.9053]\n",
      " [2646.0347]\n",
      " [2625.2415]\n",
      " [2628.5186]\n",
      " [2655.522 ]\n",
      " [2627.0264]\n",
      " [2657.607 ]\n",
      " [2644.3496]\n",
      " [2616.9343]\n",
      " [2628.297 ]\n",
      " [2632.683 ]\n",
      " [2658.7844]\n",
      " [2661.1768]\n",
      " [2659.8372]\n",
      " [2660.9395]\n",
      " [2649.1094]\n",
      " [2662.1294]\n",
      " [2663.2563]\n",
      " [2633.6516]\n",
      " [2663.914 ]\n",
      " [2635.9504]\n",
      " [2656.8086]\n",
      " [2665.5657]\n",
      " [2653.869 ]\n",
      " [2665.385 ]\n",
      " [2668.016 ]\n",
      " [2668.0789]\n",
      " [2658.397 ]\n",
      " [2669.4238]\n",
      " [2664.9998]\n",
      " [2672.6782]\n",
      " [2655.3489]\n",
      " [2673.5962]\n",
      " [2660.3838]\n",
      " [2674.7412]\n",
      " [2672.5962]\n",
      " [2674.5605]\n",
      " [2650.4636]\n",
      " [2659.5134]\n",
      " [2675.68  ]\n",
      " [2678.3105]\n",
      " [2669.833 ]\n",
      " [2647.9307]\n",
      " [2673.346 ]\n",
      " [2654.0303]\n",
      " [2650.8245]\n",
      " [2671.6826]\n",
      " [2679.7356]\n",
      " [2651.5005]\n",
      " [2681.3928]\n",
      " [2641.3633]\n",
      " [2685.1724]\n",
      " [2643.1125]\n",
      " [2676.9727]\n",
      " [2686.1648]\n",
      " [2685.1992]\n",
      " [2687.875 ]\n",
      " [2687.9497]\n",
      " [2682.741 ]\n",
      " [2689.6602]\n",
      " [2688.4624]\n",
      " [2690.8047]\n",
      " [2691.7168]\n",
      " [2688.5884]\n",
      " [2669.7368]\n",
      " [2650.2876]\n",
      " [2692.032 ]\n",
      " [2691.701 ]\n",
      " [2694.9697]\n",
      " [2670.58  ]\n",
      " [2653.8215]\n",
      " [2676.7742]\n",
      " [2683.587 ]\n",
      " [2695.2708]\n",
      " [2684.7769]\n",
      " [2699.4512]\n",
      " [2648.4893]\n",
      " [2650.9058]\n",
      " [2698.5093]\n",
      " [2698.8403]\n",
      " [2691.7683]\n",
      " [2682.7236]\n",
      " [2688.9714]\n",
      " [2689.5664]\n",
      " [2695.416 ]\n",
      " [2687.4766]\n",
      " [2695.4805]\n",
      " [2703.6   ]\n",
      " [2685.4834]\n",
      " [2662.5288]\n",
      " [2697.8604]\n",
      " [2659.235 ]\n",
      " [2694.921 ]\n",
      " [2706.7876]\n",
      " [2708.536 ]\n",
      " [2707.9775]\n",
      " [2688.7754]\n",
      " [2662.805 ]\n",
      " [2692.838 ]\n",
      " [2699.0857]\n",
      " [2685.7349]\n",
      " [2714.603 ]\n",
      " [2689.1357]\n",
      " [2715.793 ]\n",
      " [2713.332 ]\n",
      " [2674.645 ]\n",
      " [2696.1926]\n",
      " [2709.1   ]\n",
      " [2712.0012]\n",
      " [2715.9563]\n",
      " [2713.191 ]\n",
      " [2713.8027]\n",
      " [2721.4646]\n",
      " [2707.9802]\n",
      " [2711.9968]\n",
      " [2680.5947]\n",
      " [2714.4546]]\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "subs = [] \n",
    "q = 0.5\n",
    "#weeks = list(range(-12, 134))\n",
    "predictions = []\n",
    "for model in models:\n",
    "    \n",
    "    for p in test.Patient.unique():\n",
    "        x = [] \n",
    "        tab = [] \n",
    "        ldir = os.listdir(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "        data_to_be_fed = process_test_data(p, test.loc[test.Patient == p, :])\n",
    "        for i in range(len(data_to_be_fed)):\n",
    "            tab.append(data_to_be_fed[i])\n",
    "            max_index = len(ldir)\n",
    "            maxi = math.floor(0.8*max_index)\n",
    "            mini = math.floor(0.15*max_index)\n",
    "            chosen_index = random.randint(mini, maxi)\n",
    "            #if int(i[:-4]) / len(ldir) < 0.8 and int(i[:-4]) / len(ldir) > 0.15: #0.8, 0.15\n",
    "            x.append(get_img(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/{chosen_index}.dcm'))  \n",
    "\n",
    "        tab = np.array(tab) \n",
    "        print(\"number of patient data is: \", len(tab))\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        pred_fvc = model.predict([x, tab]) # Predict from all image data and tabular data.\n",
    "        print(\"pred_fvc is: \", pred_fvc)\n",
    "        for w in range(len(pred_fvc)):\n",
    "            patient_prediction = {}\n",
    "            patient_prediction = {\n",
    "                'baselined_week': w,\n",
    "                'Patient': p,\n",
    "                'FVC': pred_fvc[w][0]\n",
    "            }\n",
    "            predictions.append(patient_prediction)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:29:03.706132Z",
     "iopub.status.busy": "2020-10-30T17:29:03.690678Z",
     "iopub.status.idle": "2020-10-30T17:29:03.875323Z",
     "shell.execute_reply": "2020-10-30T17:29:03.875927Z"
    },
    "papermill": {
     "duration": 7.797212,
     "end_time": "2020-10-30T17:29:03.876079",
     "exception": false,
     "start_time": "2020-10-30T17:28:56.078867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'baselined_week': 0,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2437.406},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2430.0708},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2435.531},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2470.1152},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2446.9492},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2432.4507},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2433.0454},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2479.3652},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2453.0056},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2453.6003},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2484.449},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2481.4026},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2436.6152},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2481.9426},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2437.8052},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2483.1326},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2454.0884},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2432.151},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2484.0774},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2468.458},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2469.0527},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2486.7021},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2450.4949},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2436.3142},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2489.4795},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2490.0745},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2484.7283},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2453.4697},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2439.2888},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2485.6973},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2461.4124},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2447.9194},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2476.1924},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2457.0396},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2489.488},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2465.3926},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2427.726},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2490.4568},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2452.084},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2491.5334},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2498.6562},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2497.7612},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2447.6182},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2499.7913},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2494.5083},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2449.403},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2501.5762},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2497.2224},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2472.1216},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2472.7166},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2451.7844},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2452.3794},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2460.4136},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2461.0083},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2454.7578},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2467.0635},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2508.518},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2455.949},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2478.0713},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2464.5781},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2504.9568},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2458.3289},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2443.1948},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2481.046},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2472.4182},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2512.0403},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2487.513},\n",
       " {'baselined_week': 67,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2518.3616},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2514.665},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2509.4956},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2520.1462},\n",
       " {'baselined_week': 71,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2486.811},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2491.0828},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2511.8755},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2488.5962},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2482.0276},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2488.7803},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2515.071},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2475.8823},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2495.2473},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2470.2266},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2523.0496},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2497.032},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2506.5352},\n",
       " {'baselined_week': 84,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2487.3823},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2507.725},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2519.6099},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2474.3914},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2527.5566},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2522.2107},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2510.6997},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2498.7104},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2492.1418},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2461.6384},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2525.1853},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2478.5574},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2501.685},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2479.7473},\n",
       " {'baselined_week': 98,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2531.6738},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2507.1462},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2528.7551},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2535.2913},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2505.255},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2534.6487},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2531.135},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2530.8005},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2537.9233},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2537.8684},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2532.5854},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2539.0583},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2540.3032},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2472.3477},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2534.965},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2489.86},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2536.155},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2511.984},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2517.2605},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2543.8179},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2514.774},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2514.3638},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2539.8384},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2494.6199},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2541.0283},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2495.216},\n",
       " {'baselined_week': 124,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2508.1155},\n",
       " {'baselined_week': 125,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2543.629},\n",
       " {'baselined_week': 126,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2549.1726},\n",
       " {'baselined_week': 127,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2505.0352},\n",
       " {'baselined_week': 128,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2545.4138},\n",
       " {'baselined_week': 129,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2550.9573},\n",
       " {'baselined_week': 130,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2545.7878},\n",
       " {'baselined_week': 131,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2553.14},\n",
       " {'baselined_week': 132,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2547.7937},\n",
       " {'baselined_week': 133,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2513.4702},\n",
       " {'baselined_week': 134,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2554.9246},\n",
       " {'baselined_week': 135,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2528.5647},\n",
       " {'baselined_week': 136,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2554.282},\n",
       " {'baselined_week': 137,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2504.1392},\n",
       " {'baselined_week': 138,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2504.7341},\n",
       " {'baselined_week': 139,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2556.907},\n",
       " {'baselined_week': 140,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2489.6013},\n",
       " {'baselined_week': 141,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2552.3323},\n",
       " {'baselined_week': 142,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2558.692},\n",
       " {'baselined_week': 143,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2558.4468},\n",
       " {'baselined_week': 144,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2554.933},\n",
       " {'baselined_week': 145,\n",
       "  'Patient': 'ID00023637202179104603099',\n",
       "  'FVC': 2561.1267},\n",
       " {'baselined_week': 0,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2548.2183},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2598.0674},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2605.8745},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2554.9336},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2562.2021},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2599.5488},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2603.4463},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2604.9172},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2595.8267},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2558.1006},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2591.5806},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2603.1187},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2580.8062},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2609.8435},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2609.007},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2603.6982},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2596.41},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2566.3003},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2606.7075},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2616.5168},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2598.525},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2580.7385},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2612.983},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2573.0183},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2611.438},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2560.8276},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2614.5906},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2611.7202},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2615.6025},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2596.1536},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2615.3203},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2593.478},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2585.228},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2621.7424},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2605.5435},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2604.4353},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2620.393},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2598.8215},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2619.6697},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2624.9954},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2624.7798},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2623.8545},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2593.0193},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2617.8833},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2571.9463},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2627.499},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2624.9055},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2629.398},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2632.6702},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2624.8093},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2634.9607},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2627.4019},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2623.9614},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2632.0642},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2631.56},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2615.541},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2581.9568},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2626.3828},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2631.569},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2634.3823},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2607.7993},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2611.3267},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2639.9768},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2591.2632},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2632.9917},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2636.1445},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2638.7515},\n",
       " {'baselined_week': 67,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2640.029},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2640.7463},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2635.8262},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2640.3071},\n",
       " {'baselined_week': 71,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2591.8079},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2595.583},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2638.1658},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2636.327},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2645.371},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2646.3975},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2647.3774},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2599.1528},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2647.5332},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2593.5503},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2651.3923},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2647.4465},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2635.478},\n",
       " {'baselined_week': 84, 'Patient': 'ID00027637202179689871102', 'FVC': 2643.0},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2651.4602},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2655.6633},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2656.4702},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2599.9465},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2655.992},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2657.0388},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2654.0251},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2628.4023},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2652.39},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2656.6035},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2657.7017},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2645.5925},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2643.64},\n",
       " {'baselined_week': 98,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2662.803},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2654.8862},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2616.4941},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2660.8167},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2609.3245},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2647.3772},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2621.725},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2667.1794},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2659.2603},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2660.7192},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2658.8787},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2663.794},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2665.3293},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2617.9255},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2667.5347},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2668.13},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2655.306},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2619.139},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2666.0764},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2667.0823},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2656.835},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2654.4504},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2630.729},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2672.8894},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2664.364},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2651.1655},\n",
       " {'baselined_week': 124,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2673.0269},\n",
       " {'baselined_week': 125,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2679.0176},\n",
       " {'baselined_week': 126,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2674.1963},\n",
       " {'baselined_week': 127,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2675.2463},\n",
       " {'baselined_week': 128,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2643.4167},\n",
       " {'baselined_week': 129,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2663.1118},\n",
       " {'baselined_week': 130,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2678.022},\n",
       " {'baselined_week': 131,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2681.432},\n",
       " {'baselined_week': 132,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2663.694},\n",
       " {'baselined_week': 133,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2684.3418},\n",
       " {'baselined_week': 134,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2665.3552},\n",
       " {'baselined_week': 135,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2667.3877},\n",
       " {'baselined_week': 136,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2676.9126},\n",
       " {'baselined_week': 137,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2672.4553},\n",
       " {'baselined_week': 138,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2679.263},\n",
       " {'baselined_week': 139,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2668.6282},\n",
       " {'baselined_week': 140,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2679.8613},\n",
       " {'baselined_week': 141,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2678.157},\n",
       " {'baselined_week': 142,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2675.5508},\n",
       " {'baselined_week': 143,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2666.5674},\n",
       " {'baselined_week': 144,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2685.5674},\n",
       " {'baselined_week': 145,\n",
       "  'Patient': 'ID00027637202179689871102',\n",
       "  'FVC': 2632.1191},\n",
       " {'baselined_week': 0,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2556.3176},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2567.1067},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2544.7024},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2565.5886},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2638.949},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2558.568},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2607.0667},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2568.0056},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2568.5637},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2618.4045},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2563.0696},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2644.5015},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2553.2046},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2548.3176},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2653.1873},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2637.214},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2578.2888},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2566.9272},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2561.6587},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2643.8293},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2569.6252},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2649.0632},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2644.567},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2591.7988},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2560.5007},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2602.4814},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2573.7495},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2645.8147},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2561.9382},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2662.3325},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2662.9275},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2581.1238},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2661.7424},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2582.7566},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2618.302},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2588.382},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2585.238},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2585.9473},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2580.5237},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2590.7617},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2660.7173},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2603.0103},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2570.139},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2663.9717},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2668.2544},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2655.0627},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2587.4302},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2585.156},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2569.381},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2581.309},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2674.9822},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2582.8643},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2587.3076},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2651.7788},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2632.2737},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2581.2517},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2594.9512},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2665.3906},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2577.9607},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2617.2537},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2660.8032},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2593.3816},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2588.241},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2637.693},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2598.0217},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2582.1255},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2617.2415},\n",
       " {'baselined_week': 67,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2678.5312},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2584.3887},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2584.5645},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2605.5603},\n",
       " {'baselined_week': 71,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2684.037},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2681.3525},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2590.677},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2686.2715},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2608.4204},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2645.6123},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2673.5137},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2659.4568},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2644.9421},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2690.8328},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2636.9697},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2681.4546},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2681.1768},\n",
       " {'baselined_week': 84,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2647.917},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2613.8086},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2626.65},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2690.131},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2634.3154},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2697.7222},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2636.3467},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2699.3755},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2685.689},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2601.396},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2597.4587},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2608.0447},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2693.0159},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2602.9558},\n",
       " {'baselined_week': 98,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2698.0784},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2615.887},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2617.4397},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2621.8264},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2676.9348},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2681.5266},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2663.9775},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2662.3486},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2703.0173},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2640.665},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2701.9194},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2608.6633},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2654.2234},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2613.6462},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2622.164},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2631.0896},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2699.3027},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2632.3374},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2707.3848},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2669.8108},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2633.8452},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2634.2283},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2630.9412},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2710.3035},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2648.0684},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2709.7485},\n",
       " {'baselined_week': 124,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2630.5874},\n",
       " {'baselined_week': 125,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2620.5913},\n",
       " {'baselined_week': 126,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2637.8008},\n",
       " {'baselined_week': 127,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2628.7402},\n",
       " {'baselined_week': 128,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2640.0884},\n",
       " {'baselined_week': 129,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2654.7234},\n",
       " {'baselined_week': 130,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2684.5486},\n",
       " {'baselined_week': 131,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2658.657},\n",
       " {'baselined_week': 132,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2660.6853},\n",
       " {'baselined_week': 133,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2628.0603},\n",
       " {'baselined_week': 134,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2643.5142},\n",
       " {'baselined_week': 135,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2627.564},\n",
       " {'baselined_week': 136,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2715.1333},\n",
       " {'baselined_week': 137,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2645.3076},\n",
       " {'baselined_week': 138,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2718.6729},\n",
       " {'baselined_week': 139,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2639.6853},\n",
       " {'baselined_week': 140,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2626.8125},\n",
       " {'baselined_week': 141,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2715.1733},\n",
       " {'baselined_week': 142,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2627.717},\n",
       " {'baselined_week': 143,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2631.3003},\n",
       " {'baselined_week': 144,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2634.7043},\n",
       " {'baselined_week': 145,\n",
       "  'Patient': 'ID00035637202182204917484',\n",
       "  'FVC': 2717.7466},\n",
       " {'baselined_week': 0,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2775.1816},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2771.4783},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2779.8708},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2782.2654},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2750.6113},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2777.5872},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2786.7998},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2776.0845},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2722.4973},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2789.0151},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2785.2563},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2733.441},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2728.5337},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2788.49},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2790.9053},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2770.5908},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2754.7646},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2771.7808},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2788.9648},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2775.6768},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2791.3267},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2793.777},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2728.603},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2754.6482},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2764.1382},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2740.7356},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2734.1938},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2795.4604},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2796.114},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2797.151},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2799.7305},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2796.656},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2797.52},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2794.7646},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2788.1575},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2800.6497},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2772.9116},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2787.752},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2800.507},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2772.4653},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2802.0762},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2808.8928},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2798.6877},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2807.7388},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2790.0059},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2811.192},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2772.6133},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2771.0627},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2805.78},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2811.5955},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2749.1821},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2809.128},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2811.5352},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2763.1455},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2759.024},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2762.913},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2752.752},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2779.1582},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2766.1206},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2817.4932},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2816.178},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2804.0464},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2815.3867},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2815.8486},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2817.9744},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2761.3801},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2821.6318},\n",
       " {'baselined_week': 67,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2824.2466},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2772.0698},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2804.8796},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2805.3408},\n",
       " {'baselined_week': 71, 'Patient': 'ID00038637202182690843176', 'FVC': 2820.6},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2820.4543},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2781.7295},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2797.4258},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2828.769},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2824.512},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2825.7087},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2825.0874},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2821.6135},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2777.7869},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2829.6555},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2828.2415},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2778.7961},\n",
       " {'baselined_week': 84,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2831.2593},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2828.5085},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2768.3335},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2830.0168},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2830.834},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2831.3516},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2838.1477},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2816.8438},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2837.9656},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2839.75},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2796.0288},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2790.726},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2819.8186},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2781.8794},\n",
       " {'baselined_week': 98,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2812.424},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2838.9465},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2834.3125},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2809.3525},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2812.1787},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2839.647},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2844.945},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2841.7117},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2843.4297},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2825.3267},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2790.117},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2821.9},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2843.7231},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2804.204},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2851.0542},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2850.5645},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2839.7449},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2846.3186},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2852.3494},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2844.7407},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2844.0002},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2849.012},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2835.0886},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2806.1948},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2850.2021},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2845.955},\n",
       " {'baselined_week': 124,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2857.435},\n",
       " {'baselined_week': 125,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2852.5818},\n",
       " {'baselined_week': 126,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2856.5647},\n",
       " {'baselined_week': 127,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2855.4565},\n",
       " {'baselined_week': 128,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2855.553},\n",
       " {'baselined_week': 129,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2855.081},\n",
       " {'baselined_week': 130,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2854.9617},\n",
       " {'baselined_week': 131,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2856.1516},\n",
       " {'baselined_week': 132,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2863.11},\n",
       " {'baselined_week': 133,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2859.6902},\n",
       " {'baselined_week': 134,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2853.34},\n",
       " {'baselined_week': 135,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2860.3535},\n",
       " {'baselined_week': 136,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2855.2876},\n",
       " {'baselined_week': 137,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2864.5786},\n",
       " {'baselined_week': 138,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2864.9482},\n",
       " {'baselined_week': 139,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2856.275},\n",
       " {'baselined_week': 140,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2866.6282},\n",
       " {'baselined_week': 141,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2862.3704},\n",
       " {'baselined_week': 142,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2865.9478},\n",
       " {'baselined_week': 143,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2864.486},\n",
       " {'baselined_week': 144,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2870.058},\n",
       " {'baselined_week': 145,\n",
       "  'Patient': 'ID00038637202182690843176',\n",
       "  'FVC': 2864.6006},\n",
       " {'baselined_week': 0,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2711.0244},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2706.9556},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2675.3843},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2689.6143},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2712.6726},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2701.7515},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2713.3054},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2712.0835},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2711.688},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2716.3792},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2689.6826},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2717.569},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2711.593},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2719.2458},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2711.2007},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2717.8093},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2712.3906},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2717.0425},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2717.0698},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2676.1377},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2707.7795},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2720.504},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2724.6003},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2686.524},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2680.1445},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2713.6506},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2696.058},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2690.2583},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2723.0193},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2727.1953},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2705.8367},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2725.322},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2717.8152},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2731.145},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2719.0051},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2731.8481},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2719.452},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2728.8914},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2728.5083},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2708.1013},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2693.8774},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2730.7537},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2705.5774},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2699.743},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2726.0464},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2737.0657},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2737.3096},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2737.6455},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2733.03},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2725.0334},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2716.003},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2715.241},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2737.1882},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2743.0498},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2739.0562},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2734.5112},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2737.92},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2742.7976},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2737.379},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2729.7622},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2736.2136},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2712.9138},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2746.829},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2707.5615},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2709.8745},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2734.5527},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2741.3252},\n",
       " {'baselined_week': 67, 'Patient': 'ID00047637202184938901501', 'FVC': 2731.6},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2750.1926},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2752.9275},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2714.4868},\n",
       " {'baselined_week': 71,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2730.0713},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2715.6768},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2735.17},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2755.5437},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2754.7527},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2728.9497},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2756.4265},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2734.3347},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2752.9016},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2759.472},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2755.041},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2757.6936},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2758.2769},\n",
       " {'baselined_week': 84,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2749.8445},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2755.1736},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2761.108},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2723.5583},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2764.2317},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2757.4045},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2765.4214},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2733.4724},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2759.1895},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2743.3186},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2740.824},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2763.708},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2731.31},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2767.4465},\n",
       " {'baselined_week': 98, 'Patient': 'ID00047637202184938901501', 'FVC': 2732.5},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2759.4172},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2747.4236},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2768.9756},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2761.202},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2765.9006},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2769.885},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2769.3484},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2770.9841},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2773.7913},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2764.9854},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2770.0762},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2769.9172},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2775.776},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2739.4749},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2777.9185},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2774.6746},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2778.5874},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2763.6748},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2780.8105},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2739.0356},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2771.5298},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2775.8481},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2782.2825},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2753.1738},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2784.691},\n",
       " {'baselined_week': 124,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2746.6143},\n",
       " {'baselined_week': 125,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2746.1667},\n",
       " {'baselined_week': 126,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2785.989},\n",
       " {'baselined_week': 127,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2780.1797},\n",
       " {'baselined_week': 128,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2785.105},\n",
       " {'baselined_week': 129,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2775.5261},\n",
       " {'baselined_week': 130,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2781.8162},\n",
       " {'baselined_week': 131,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2783.8394},\n",
       " {'baselined_week': 132,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2752.6938},\n",
       " {'baselined_week': 133,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2780.9175},\n",
       " {'baselined_week': 134,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2760.7239},\n",
       " {'baselined_week': 135,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2784.7913},\n",
       " {'baselined_week': 136,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2785.5164},\n",
       " {'baselined_week': 137,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2793.0203},\n",
       " {'baselined_week': 138,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2784.162},\n",
       " {'baselined_week': 139,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2781.4756},\n",
       " {'baselined_week': 140,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2792.2444},\n",
       " {'baselined_week': 141,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2784.619},\n",
       " {'baselined_week': 142,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2794.4253},\n",
       " {'baselined_week': 143,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2768.8118},\n",
       " {'baselined_week': 144,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2790.8994},\n",
       " {'baselined_week': 145,\n",
       "  'Patient': 'ID00047637202184938901501',\n",
       "  'FVC': 2782.1492},\n",
       " {'baselined_week': 0,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2441.8499},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2437.2698},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2443.0398},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2449.9277},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2417.9556},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2432.5046},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2446.3386},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2463.458},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2420.2642},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2420.8594},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2442.6243},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2426.6506},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2459.9534},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2467.0276},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2428.4407},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2450.7742},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2457.4902},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2439.644},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2471.725},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2426.88},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2459.87},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2460.637},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2432.7925},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2472.9773},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2467.0928},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2467.0117},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2476.4846},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2435.767},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2436.765},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2446.7834},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2465.8196},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2466.5864},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2461.4246},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2471.7715},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2449.7583},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2463.2092},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2473.5564},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2474.1514},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2474.7463},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2465.589},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2460.473},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2483.6865},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2444.6914},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2468.3523},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2441.6826},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2487.7888},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2479.5059},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2488.9785},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2458.0876},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2449.259},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2477.8906},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2483.1567},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2491.9534},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2492.5483},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2461.6575},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2475.1086},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2492.6108},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2481.8833},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2454.211},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2476.9521},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2472.372},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2451.7969},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2484.8582},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2489.0745},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2458.547},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2490.2644},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2487.41},\n",
       " {'baselined_week': 67,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2499.1553},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2460.9268},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2477.7268},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2484.033},\n",
       " {'baselined_week': 71,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2484.0916},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2503.8525},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2485.8176},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2486.4128},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2487.0076},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2497.3545},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2461.3872},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2461.9822},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2489.3875},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2495.7393},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2507.4846},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2469.256},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2469.085},\n",
       " {'baselined_week': 84,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2502.1143},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2511.587},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2470.8696},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2467.2656},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2481.886},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2482.481},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2506.3599},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2502.1118},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2475.2058},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2470.9065},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2508.7397},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2498.3706},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2472.6912},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2517.004},\n",
       " {'baselined_week': 98,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2478.0093},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2518.1938},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2479.6067},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2489.6204},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2490.2153},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2520.5737},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2477.38},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2510.4412},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2483.1765},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2516.474},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2500.93},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2480.355},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2524.7383},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2508.426},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2518.2273},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2515.3728},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2528.8406},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2505.0947},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2521.8289},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2521.2021},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2518.3477},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2486.3042},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2513.7805},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2492.4595},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2520.5554},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2515.5657},\n",
       " {'baselined_week': 124,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2525.9126},\n",
       " {'baselined_week': 125,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2516.2192},\n",
       " {'baselined_week': 126,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2517.7336},\n",
       " {'baselined_week': 127,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2523.7024},\n",
       " {'baselined_week': 128,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2496.624},\n",
       " {'baselined_week': 129,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2524.7202},\n",
       " {'baselined_week': 130,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2519.194},\n",
       " {'baselined_week': 131,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2519.789},\n",
       " {'baselined_week': 132,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2494.1096},\n",
       " {'baselined_week': 133,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2530.7214},\n",
       " {'baselined_week': 134,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2531.8623},\n",
       " {'baselined_week': 135,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2528.462},\n",
       " {'baselined_week': 136,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2522.7637},\n",
       " {'baselined_week': 137,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2523.8948},\n",
       " {'baselined_week': 138,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2497.6794},\n",
       " {'baselined_week': 139,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2525.468},\n",
       " {'baselined_week': 140,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2535.432},\n",
       " {'baselined_week': 141,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2499.4644},\n",
       " {'baselined_week': 142,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2532.4546},\n",
       " {'baselined_week': 143,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2527.4646},\n",
       " {'baselined_week': 144,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2533.8164},\n",
       " {'baselined_week': 145,\n",
       "  'Patient': 'ID00048637202185016727717',\n",
       "  'FVC': 2537.8608},\n",
       " {'baselined_week': 0,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2590.0825},\n",
       " {'baselined_week': 1,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2559.725},\n",
       " {'baselined_week': 2,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2587.9739},\n",
       " {'baselined_week': 3,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2594.8066},\n",
       " {'baselined_week': 4,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2577.714},\n",
       " {'baselined_week': 5,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2596.581},\n",
       " {'baselined_week': 6,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2601.077},\n",
       " {'baselined_week': 7,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2563.2947},\n",
       " {'baselined_week': 8,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2587.7798},\n",
       " {'baselined_week': 9,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2598.961},\n",
       " {'baselined_week': 10,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2581.284},\n",
       " {'baselined_week': 11,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2600.5164},\n",
       " {'baselined_week': 12,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2593.2373},\n",
       " {'baselined_week': 13,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2593.8323},\n",
       " {'baselined_week': 14,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2599.2964},\n",
       " {'baselined_week': 15,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2568.0544},\n",
       " {'baselined_week': 16,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2603.9224},\n",
       " {'baselined_week': 17,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2596.2122},\n",
       " {'baselined_week': 18,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2596.8071},\n",
       " {'baselined_week': 19,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2590.5925},\n",
       " {'baselined_week': 20,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2594.9192},\n",
       " {'baselined_week': 21,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2595.5142},\n",
       " {'baselined_week': 22,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2599.5107},\n",
       " {'baselined_week': 23,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2577.0344},\n",
       " {'baselined_week': 24,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2611.7861},\n",
       " {'baselined_week': 25,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2578.2244},\n",
       " {'baselined_week': 26,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2609.0752},\n",
       " {'baselined_week': 27,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2595.3523},\n",
       " {'baselined_week': 28,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2609.4788},\n",
       " {'baselined_week': 29,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2592.5881},\n",
       " {'baselined_week': 30,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2610.8704},\n",
       " {'baselined_week': 31,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2604.8655},\n",
       " {'baselined_week': 32,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2602.0586},\n",
       " {'baselined_week': 33,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2614.0366},\n",
       " {'baselined_week': 34,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2614.6313},\n",
       " {'baselined_week': 35,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2574.3032},\n",
       " {'baselined_week': 36,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2615.3904},\n",
       " {'baselined_week': 37,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2612.096},\n",
       " {'baselined_week': 38,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2594.6313},\n",
       " {'baselined_week': 39,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2613.2856},\n",
       " {'baselined_week': 40,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2585.0862},\n",
       " {'baselined_week': 41,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2577.8728},\n",
       " {'baselined_week': 42,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2617.8083},\n",
       " {'baselined_week': 43,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2618.403},\n",
       " {'baselined_week': 44,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2579.6577},\n",
       " {'baselined_week': 45,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2620.233},\n",
       " {'baselined_week': 46,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2620.828},\n",
       " {'baselined_week': 47,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2620.9846},\n",
       " {'baselined_week': 48,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2600.5808},\n",
       " {'baselined_week': 49,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2619.2354},\n",
       " {'baselined_week': 50,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2591.036},\n",
       " {'baselined_week': 51,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2616.4407},\n",
       " {'baselined_week': 52,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2624.9097},\n",
       " {'baselined_week': 53,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2606.867},\n",
       " {'baselined_week': 54,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2626.5303},\n",
       " {'baselined_week': 55,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2612.011},\n",
       " {'baselined_week': 56,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2619.4153},\n",
       " {'baselined_week': 57,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2626.7327},\n",
       " {'baselined_week': 58,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2606.5305},\n",
       " {'baselined_week': 59,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2626.0693},\n",
       " {'baselined_week': 60,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2629.3037},\n",
       " {'baselined_week': 61,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2623.076},\n",
       " {'baselined_week': 62,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2596.0173},\n",
       " {'baselined_week': 63,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2600.8328},\n",
       " {'baselined_week': 64,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2630.8972},\n",
       " {'baselined_week': 65,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2610.695},\n",
       " {'baselined_week': 66,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2618.5554},\n",
       " {'baselined_week': 67,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2633.4683},\n",
       " {'baselined_week': 68,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2599.587},\n",
       " {'baselined_week': 69,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2635.024},\n",
       " {'baselined_week': 70,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2631.7295},\n",
       " {'baselined_week': 71,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2625.262},\n",
       " {'baselined_week': 72,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2604.1248},\n",
       " {'baselined_week': 73,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2633.5142},\n",
       " {'baselined_week': 74,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2603.1567},\n",
       " {'baselined_week': 75,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2603.7517},\n",
       " {'baselined_week': 76,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2635.299},\n",
       " {'baselined_week': 77,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2632.2334},\n",
       " {'baselined_week': 78,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2644.2612},\n",
       " {'baselined_week': 79,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2640.608},\n",
       " {'baselined_week': 80,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2630.6165},\n",
       " {'baselined_week': 81,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2607.3215},\n",
       " {'baselined_week': 82,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2635.2083},\n",
       " {'baselined_week': 83,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2612.7317},\n",
       " {'baselined_week': 84,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2613.327},\n",
       " {'baselined_week': 85,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2611.8591},\n",
       " {'baselined_week': 86,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2644.7725},\n",
       " {'baselined_week': 87,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2642.728},\n",
       " {'baselined_week': 88,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2627.6904},\n",
       " {'baselined_week': 89,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2647.354},\n",
       " {'baselined_week': 90,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2651.4006},\n",
       " {'baselined_week': 91,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2617.4915},\n",
       " {'baselined_week': 92,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2641.5198},\n",
       " {'baselined_week': 93,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2614.461},\n",
       " {'baselined_week': 94,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2650.3286},\n",
       " {'baselined_week': 95,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2639.5408},\n",
       " {'baselined_week': 96,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2651.5186},\n",
       " {'baselined_week': 97,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2644.4944},\n",
       " {'baselined_week': 98,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2619.5935},\n",
       " {'baselined_week': 99,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2622.2512},\n",
       " {'baselined_week': 100,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2657.35},\n",
       " {'baselined_week': 101,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2623.4412},\n",
       " {'baselined_week': 102,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2653.7073},\n",
       " {'baselined_week': 103,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2636.6147},\n",
       " {'baselined_week': 104,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2625.2258},\n",
       " {'baselined_week': 105,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2652.553},\n",
       " {'baselined_week': 106,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2656.5251},\n",
       " {'baselined_week': 107,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2657.2666},\n",
       " {'baselined_week': 108,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2655.2222},\n",
       " {'baselined_week': 109,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2658.4565},\n",
       " {'baselined_week': 110,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2651.543},\n",
       " {'baselined_week': 111,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2663.5474},\n",
       " {'baselined_week': 112,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2645.9236},\n",
       " {'baselined_week': 113,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2653.6519},\n",
       " {'baselined_week': 114,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2643.1592},\n",
       " {'baselined_week': 115,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2654.5178},\n",
       " {'baselined_week': 116,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2630.303},\n",
       " {'baselined_week': 117,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2632.9602},\n",
       " {'baselined_week': 118,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2664.6074},\n",
       " {'baselined_week': 119,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2653.8196},\n",
       " {'baselined_week': 120,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2665.3665},\n",
       " {'baselined_week': 121,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2635.34},\n",
       " {'baselined_week': 122,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2666.191},\n",
       " {'baselined_week': 123,\n",
       "  'Patient': 'ID00062637202188654068490',\n",
       "  'FVC': 2667.582},\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:29:17.984064Z",
     "iopub.status.busy": "2020-10-30T17:29:17.971615Z",
     "iopub.status.idle": "2020-10-30T17:29:17.987793Z",
     "shell.execute_reply": "2020-10-30T17:29:17.987239Z"
    },
    "papermill": {
     "duration": 7.232377,
     "end_time": "2020-10-30T17:29:17.987929",
     "exception": false,
     "start_time": "2020-10-30T17:29:10.755552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GET RESULTS INTO A DATAFRAME\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "#predictions_df.to_csv(\"test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:29:32.611916Z",
     "iopub.status.busy": "2020-10-30T17:29:32.610668Z",
     "iopub.status.idle": "2020-10-30T17:29:32.615812Z",
     "shell.execute_reply": "2020-10-30T17:29:32.616480Z"
    },
    "papermill": {
     "duration": 7.351636,
     "end_time": "2020-10-30T17:29:32.616644",
     "exception": false,
     "start_time": "2020-10-30T17:29:25.265008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baselined_week</th>\n",
       "      <th>Patient</th>\n",
       "      <th>FVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2437.406006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2430.070801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2435.531006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2470.115234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2446.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>141</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2721.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>142</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2707.980225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>143</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2711.996826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>144</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2680.594727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>145</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2714.454590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5256 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      baselined_week                    Patient          FVC\n",
       "0                  0  ID00023637202179104603099  2437.406006\n",
       "1                  1  ID00023637202179104603099  2430.070801\n",
       "2                  2  ID00023637202179104603099  2435.531006\n",
       "3                  3  ID00023637202179104603099  2470.115234\n",
       "4                  4  ID00023637202179104603099  2446.949219\n",
       "...              ...                        ...          ...\n",
       "5251             141  ID00421637202311550012437  2721.464600\n",
       "5252             142  ID00421637202311550012437  2707.980225\n",
       "5253             143  ID00421637202311550012437  2711.996826\n",
       "5254             144  ID00421637202311550012437  2680.594727\n",
       "5255             145  ID00421637202311550012437  2714.454590\n",
       "\n",
       "[5256 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.488333,
     "end_time": "2020-10-30T17:29:48.309176",
     "exception": false,
     "start_time": "2020-10-30T17:29:40.820843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "pred_patients are unique patientID of patients in the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:30:02.386548Z",
     "iopub.status.busy": "2020-10-30T17:30:02.385475Z",
     "iopub.status.idle": "2020-10-30T17:30:02.392631Z",
     "shell.execute_reply": "2020-10-30T17:30:02.391959Z"
    },
    "papermill": {
     "duration": 7.212192,
     "end_time": "2020-10-30T17:30:02.392758",
     "exception": false,
     "start_time": "2020-10-30T17:29:55.180566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_patients  = predictions_df.Patient.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:30:16.973499Z",
     "iopub.status.busy": "2020-10-30T17:30:16.972277Z",
     "iopub.status.idle": "2020-10-30T17:30:17.000181Z",
     "shell.execute_reply": "2020-10-30T17:30:16.999556Z"
    },
    "papermill": {
     "duration": 6.942774,
     "end_time": "2020-10-30T17:30:17.000309",
     "exception": false,
     "start_time": "2020-10-30T17:30:10.057535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = pd.merge(predictions_df, test, on = ['Patient', 'baselined_week'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:30:31.370492Z",
     "iopub.status.busy": "2020-10-30T17:30:31.369388Z",
     "iopub.status.idle": "2020-10-30T17:30:31.402949Z",
     "shell.execute_reply": "2020-10-30T17:30:31.402265Z"
    },
    "papermill": {
     "duration": 7.212484,
     "end_time": "2020-10-30T17:30:31.403080",
     "exception": false,
     "start_time": "2020-10-30T17:30:24.190596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baselined_week</th>\n",
       "      <th>Patient</th>\n",
       "      <th>FVC_x</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC_y</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>min_week</th>\n",
       "      <th>base_FVC</th>\n",
       "      <th>Percent_scld</th>\n",
       "      <th>Age_scld</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Ex-smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2437.406006</td>\n",
       "      <td>-3</td>\n",
       "      <td>1536</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>71</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-3</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.351707</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2433.045410</td>\n",
       "      <td>3</td>\n",
       "      <td>1368</td>\n",
       "      <td>58.163265</td>\n",
       "      <td>71</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-3</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.282745</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2453.005615</td>\n",
       "      <td>5</td>\n",
       "      <td>1361</td>\n",
       "      <td>57.865646</td>\n",
       "      <td>71</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-3</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.279872</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2484.448975</td>\n",
       "      <td>7</td>\n",
       "      <td>1465</td>\n",
       "      <td>62.287415</td>\n",
       "      <td>71</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-3</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.322563</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>ID00023637202179104603099</td>\n",
       "      <td>2436.615234</td>\n",
       "      <td>9</td>\n",
       "      <td>1681</td>\n",
       "      <td>71.471088</td>\n",
       "      <td>71</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>-3</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.411228</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>6</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2595.893799</td>\n",
       "      <td>21</td>\n",
       "      <td>2820</td>\n",
       "      <td>84.471603</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.536745</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>8</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2631.820312</td>\n",
       "      <td>23</td>\n",
       "      <td>2853</td>\n",
       "      <td>85.460101</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.546288</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>14</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2643.315674</td>\n",
       "      <td>29</td>\n",
       "      <td>2716</td>\n",
       "      <td>81.356338</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.506668</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>26</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2652.727539</td>\n",
       "      <td>41</td>\n",
       "      <td>2833</td>\n",
       "      <td>84.861011</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.540504</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>39</td>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>2632.683105</td>\n",
       "      <td>54</td>\n",
       "      <td>2771</td>\n",
       "      <td>83.003834</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.522574</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     baselined_week                    Patient        FVC_x  Weeks  FVC_y  \\\n",
       "0                 0  ID00023637202179104603099  2437.406006     -3   1536   \n",
       "1                 6  ID00023637202179104603099  2433.045410      3   1368   \n",
       "2                 8  ID00023637202179104603099  2453.005615      5   1361   \n",
       "3                10  ID00023637202179104603099  2484.448975      7   1465   \n",
       "4                12  ID00023637202179104603099  2436.615234      9   1681   \n",
       "..              ...                        ...          ...    ...    ...   \n",
       "307               6  ID00421637202311550012437  2595.893799     21   2820   \n",
       "308               8  ID00421637202311550012437  2631.820312     23   2853   \n",
       "309              14  ID00421637202311550012437  2643.315674     29   2716   \n",
       "310              26  ID00421637202311550012437  2652.727539     41   2833   \n",
       "311              39  ID00421637202311550012437  2632.683105     54   2771   \n",
       "\n",
       "       Percent  Age     Sex SmokingStatus  min_week  base_FVC  Percent_scld  \\\n",
       "0    65.306122   71  Female     Ex-smoker        -3      1536      0.351707   \n",
       "1    58.163265   71  Female     Ex-smoker        -3      1536      0.282745   \n",
       "2    57.865646   71  Female     Ex-smoker        -3      1536      0.279872   \n",
       "3    62.287415   71  Female     Ex-smoker        -3      1536      0.322563   \n",
       "4    71.471088   71  Female     Ex-smoker        -3      1536      0.411228   \n",
       "..         ...  ...     ...           ...       ...       ...           ...   \n",
       "307  84.471603   68    Male     Ex-smoker        15      2739      0.536745   \n",
       "308  85.460101   68    Male     Ex-smoker        15      2739      0.546288   \n",
       "309  81.356338   68    Male     Ex-smoker        15      2739      0.506668   \n",
       "310  84.861011   68    Male     Ex-smoker        15      2739      0.540504   \n",
       "311  83.003834   68    Male     Ex-smoker        15      2739      0.522574   \n",
       "\n",
       "     Age_scld  Female  Male  Ex-smoker  Never smoked  Currently smokes  \n",
       "0    0.540541       1     0          1             0                 0  \n",
       "1    0.540541       1     0          1             0                 0  \n",
       "2    0.540541       1     0          1             0                 0  \n",
       "3    0.540541       1     0          1             0                 0  \n",
       "4    0.540541       1     0          1             0                 0  \n",
       "..        ...     ...   ...        ...           ...               ...  \n",
       "307  0.459459       0     1          1             0                 0  \n",
       "308  0.459459       0     1          1             0                 0  \n",
       "309  0.459459       0     1          1             0                 0  \n",
       "310  0.459459       0     1          1             0                 0  \n",
       "311  0.459459       0     1          1             0                 0  \n",
       "\n",
       "[312 rows x 18 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:30:46.826799Z",
     "iopub.status.busy": "2020-10-30T17:30:46.825591Z",
     "iopub.status.idle": "2020-10-30T17:30:46.830341Z",
     "shell.execute_reply": "2020-10-30T17:30:46.829507Z"
    },
    "papermill": {
     "duration": 7.198359,
     "end_time": "2020-10-30T17:30:46.830482",
     "exception": false,
     "start_time": "2020-10-30T17:30:39.632123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt((1/len(merged_data)) * sum(np.square(merged_data.FVC_x - merged_data.FVC_y)))  #change this part for non_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T17:31:00.857454Z",
     "iopub.status.busy": "2020-10-30T17:31:00.856527Z",
     "iopub.status.idle": "2020-10-30T17:31:00.860193Z",
     "shell.execute_reply": "2020-10-30T17:31:00.860764Z"
    },
    "papermill": {
     "duration": 6.853432,
     "end_time": "2020-10-30T17:31:00.860926",
     "exception": false,
     "start_time": "2020-10-30T17:30:54.007494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699.6737348844028"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 8310.005315,
   "end_time": "2020-10-30T17:31:10.162833",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-30T15:12:40.157518",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "000d96c7b62244eb95bfea588f3ebc46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2ab246e4bf284221b7867692cf9ebf1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5000c12182504f4ca2ddc91ebc41edde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2ab246e4bf284221b7867692cf9ebf1d",
       "placeholder": "​",
       "style": "IPY_MODEL_b12feafd959b429cb9164468910aa2af",
       "value": " 140/? [00:00&lt;00:00, 172.87it/s]"
      }
     },
     "5e01e65f81c34b59893c0d7ce0e187d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f013358d95244efb0438604039f0069": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88de7d907f0a4690b9ef433d17d89270": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e609894f58e34b0c8555bba5359a5007",
        "IPY_MODEL_5000c12182504f4ca2ddc91ebc41edde"
       ],
       "layout": "IPY_MODEL_5e01e65f81c34b59893c0d7ce0e187d6"
      }
     },
     "b12feafd959b429cb9164468910aa2af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e609894f58e34b0c8555bba5359a5007": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6f013358d95244efb0438604039f0069",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_000d96c7b62244eb95bfea588f3ebc46",
       "value": 1.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
